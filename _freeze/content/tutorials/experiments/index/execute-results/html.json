{
  "hash": "709249145330313068ea580444bfe986",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Experiments # Also check out line 43\nauthor: Claudius Gr√§bner-Radkowitsch\ndate: '2025-06-13'\ndocumentclass: scrartcl\nexecute: \n  freeze: auto\nformat: \n  html:\n    theme: readable\n    highlight: tango\n    toc: true\n    toc_depth: 2\n    number_sections: true\n    message: false\n    warnig: false\n  pdf:\n    papersize: a4\n    toc: true\n    toc-depth: 2\n    number-sections: true\n    include-in-header: \n      text: |\n        \\usepackage{lmodern} \n        \\usepackage{graphicx}\n        \\usepackage{hyperref}\n        \\usepackage{url}                \n        \\usepackage{xcolor}\n        \\usepackage{booktabs}\n        \\usepackage{listings}\n        \\lstloadlanguages{R}\n        \n        \\definecolor{eufblue}{RGB}{0,57,91}\n        \\definecolor{eufgrey}{RGB}{111,111,111}\n        \\definecolor{euflightblue}{RGB}{105,170,205}\n        \n        \\hypersetup{\n        pdfauthor={Claudius Graebner-Radkowitsch}\n        colorlinks=true,\n        linkcolor=euflightblue,\n        urlcolor=euflightblue\n        }\n        \\usepackage[includehead,includefoot,top=2cm, bottom=1.5cm]{geometry}\n        \\usepackage[headsepline, footsepline]{scrlayer-scrpage}\n        \\pagestyle{scrheadings}\n        \\clearpairofpagestyles\n        \\ihead{Tutorial: Experiments}\n        %\\chead{Kopfzeile Mitte}\n        \\ohead{\\pagemark} %\n        \\ifoot{}\n        \\cfoot{\\href{https://researchmethodology25spring.netlify.app}{Research Methodology - Spring Semester 2025}} % Fu√üzeile Mitte\n        \\ofoot{} \n        \\setkomafont{disposition}{\\color{eufblue}\\bfseries}\n---\n\n# Introduction\n\nIn this lab we will learn how to analyze data obtained from experiments. We will\ncomplement the lecture by also introducing some additiona, practically relevant\nconcepts.\n\nMore precisely, we focus on the following aspects:\n\n- Import and explore datasets as typically produced by experiments\n- Conduct t-tests for simple experimental comparisons\n- Perform ANOVA for multi-group comparisons\n- Analyze factorial experimental designs\n- Calculate and interpret effect sizes\n- Create professional visualizations of experimental results\n- Understand how ANOVA is a special case of linear regression\n\nThrouout the tutorial we will use the following packages:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)        # Data manipulation\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'dplyr'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)      # Data visualization\nlibrary(ggdist)       # More visualization options\nlibrary(readr)        # Simple data import\nlibrary(broom)        # Extract model data\nlibrary(effectsize)   # Effect size calculations\nlibrary(car)          # Advanced ANOVA functions\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: carData\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'car'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:dplyr':\n\n    recode\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(emmeans)      # Post-hoc comparisons\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(knitr)        # For nice tables\nlibrary(kableExtra)   # For enhanced table formatting\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'kableExtra'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(patchwork)    # For aligning multiple plots\nlibrary(pwr)          # For power analysis and sample size planning\n```\n:::\n\n\nWe will use the following data sets, which are available for download from the\nlab webpage.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nleadership_study_between <- read_csv(\"leadership_study_between.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 60 Columns: 3\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (1): group\ndbl (2): participant_id, team_performance\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nleadership_study_within <- read_csv(\"leadership_study_within.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 30 Columns: 5\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (1): group\ndbl (4): participant_id, team_performance, pre_performance, post_performance\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\ncommunication_study <- read_csv(\"communication_study.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 90 Columns: 4\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (1): communication_method\ndbl (3): participant_id, satisfaction_score, task_completion_time\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nfactorial_study <- read_csv(\"factorial_study.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 120 Columns: 4\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (2): feedback_type, experience_level\ndbl (2): participant_id, performance_improvement\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n# Data Exploration\n\nAs usual, it is a good idea to start with looking at the data sets, such that you know what the data looks like:^[I use the function `kable()` for nicer output in the html file. \nWhen you replicate the code in R-Studio its best to skip the part `|> kable()`.]\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(leadership_study_between) |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n| participant_id|group   | team_performance|\n|--------------:|:-------|----------------:|\n|              1|control |         69.39524|\n|              2|control |         72.69823|\n|              3|control |         90.58708|\n|              4|control |         75.70508|\n|              5|control |         76.29288|\n|              6|control |         92.15065|\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(leadership_study_between) |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|   |participant_id |   group         |team_performance |\n|:--|:--------------|:----------------|:----------------|\n|   |Min.   : 1.00  |Length:60        |Min.   : 55.33   |\n|   |1st Qu.:15.75  |Class :character |1st Qu.: 70.71   |\n|   |Median :30.50  |Mode  :character |Median : 79.33   |\n|   |Mean   :30.50  |NA               |Mean   : 79.16   |\n|   |3rd Qu.:45.25  |NA               |3rd Qu.: 87.32   |\n|   |Max.   :60.00  |NA               |Max.   :103.69   |\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(communication_study) |> \n  kable()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 90\nColumns: 4\n$ participant_id       <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15‚Ä¶\n$ communication_method <chr> \"face_to_face\", \"face_to_face\", \"face_to_face\", \"‚Ä¶\n$ satisfaction_score   <dbl> 5.587774, 7.946131, 8.161050, 5.533329, 6.342772,‚Ä¶\n$ task_completion_time <dbl> 22.63382, 21.65397, 31.79263, 32.06459, 21.33613,‚Ä¶\n```\n\n\n:::\n\n::: {.cell-output-display}\n\n\n| participant_id|communication_method | satisfaction_score| task_completion_time|\n|--------------:|:--------------------|------------------:|--------------------:|\n|              1|face_to_face         |           5.587774|             22.63382|\n|              2|face_to_face         |           7.946131|             21.65397|\n|              3|face_to_face         |           8.161050|             31.79263|\n|              4|face_to_face         |           5.533329|             32.06459|\n|              5|face_to_face         |           6.342772|             21.33613|\n|              6|face_to_face         |           6.811127|             24.59724|\n|              7|face_to_face         |           8.028772|             29.05098|\n|              8|face_to_face         |           7.500657|             27.51294|\n|              9|face_to_face         |           8.408823|             30.62011|\n|             10|face_to_face         |           7.887882|             24.14360|\n|             11|face_to_face         |           6.101027|             25.59076|\n|             12|face_to_face         |           8.773317|             29.34951|\n|             13|face_to_face         |           8.386472|             24.54032|\n|             14|face_to_face         |           9.184714|             25.34449|\n|             15|face_to_face         |           5.471034|             16.58787|\n|             16|face_to_face         |           9.536828|             30.58478|\n|             17|face_to_face         |           9.284323|             18.24321|\n|             18|face_to_face         |           7.664980|             22.31417|\n|             19|face_to_face         |           9.936041|             23.14943|\n|             20|face_to_face         |           9.045460|             26.77006|\n|             21|face_to_face         |           6.630475|             20.95087|\n|             22|face_to_face         |           5.139229|             24.10138|\n|             23|face_to_face         |           5.487804|             19.26170|\n|             24|face_to_face         |           7.449883|             25.48121|\n|             25|face_to_face         |           7.156997|             29.07350|\n|             26|face_to_face         |           8.561141|             29.91470|\n|             27|face_to_face         |           6.644574|             29.25422|\n|             28|face_to_face         |           6.805939|             31.03674|\n|             29|face_to_face         |           8.981447|             17.83111|\n|             30|face_to_face         |           5.892747|             19.49527|\n|             31|video_call           |           6.112567|             26.33775|\n|             32|video_call           |           6.028069|             24.15182|\n|             33|video_call           |           4.201410|             33.14125|\n|             34|video_call           |           7.184999|             29.88306|\n|             35|video_call           |           7.021813|             35.33477|\n|             36|video_call           |           9.160348|             21.24203|\n|             37|video_call           |           5.941216|             29.41778|\n|             38|video_call           |           6.617673|             20.36578|\n|             39|video_call           |           6.248827|             29.89410|\n|             40|video_call           |           6.749644|             30.13366|\n|             41|video_call           |           6.762376|             28.02431|\n|             42|video_call           |           7.310949|             34.89517|\n|             43|video_call           |           6.475502|             25.02031|\n|             44|video_call           |           6.908485|             23.51922|\n|             45|video_call           |           9.502537|             20.30340|\n|             46|video_call           |           6.957107|             21.80937|\n|             47|video_call           |           6.953594|             15.56772|\n|             48|video_call           |           7.801070|             25.44360|\n|             49|video_call           |           5.271977|             23.33815|\n|             50|video_call           |           7.331750|             26.90913|\n|             51|video_call           |           5.935564|             22.82616|\n|             52|video_call           |           6.466518|             26.90475|\n|             53|video_call           |           7.682417|             36.22417|\n|             54|video_call           |           7.965898|             36.05631|\n|             55|video_call           |           7.603863|             21.08943|\n|             56|video_call           |           7.750890|             32.49259|\n|             57|video_call           |           6.262873|             37.13289|\n|             58|video_call           |           8.825157|             19.28188|\n|             59|video_call           |           7.504208|             35.26455|\n|             60|video_call           |           7.550296|             22.54393|\n|             61|email                |           2.743407|             43.40287|\n|             62|email                |           4.525116|             33.84209|\n|             63|email                |           5.619205|             31.54055|\n|             64|email                |           7.154302|             24.04801|\n|             65|email                |           5.839037|             32.51943|\n|             66|email                |           8.206231|             27.84625|\n|             67|email                |           8.088619|             43.34264|\n|             68|email                |           3.896070|             36.60520|\n|             69|email                |           5.137568|             26.09195|\n|             70|email                |           4.820245|             39.84311|\n|             71|email                |           5.662017|             34.79872|\n|             72|email                |           5.842933|             27.27318|\n|             73|email                |           3.491244|             27.75308|\n|             74|email                |           7.921749|             35.97967|\n|             75|email                |           5.871980|             39.77910|\n|             76|email                |           6.278325|             27.05108|\n|             77|email                |           5.741893|             47.40781|\n|             78|email                |           4.703157|             34.34252|\n|             79|email                |           4.452763|             18.75168|\n|             80|email                |           6.210837|             36.05728|\n|             81|email                |           4.388725|             30.16197|\n|             82|email                |           5.282076|             40.81300|\n|             83|email                |           8.728889|             43.34819|\n|             84|email                |           6.001999|             37.16937|\n|             85|email                |           6.892344|             24.15431|\n|             86|email                |           7.090713|             32.69167|\n|             87|email                |           3.819324|             25.11418|\n|             88|email                |           7.188742|             28.00168|\n|             89|email                |           6.107660|             18.82483|\n|             90|email                |           5.568385|             41.57033|\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(communication_study) |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|   |participant_id |communication_method |satisfaction_score |task_completion_time |\n|:--|:--------------|:--------------------|:------------------|:--------------------|\n|   |Min.   : 1.00  |Length:90            |Min.   :2.743      |Min.   :15.57        |\n|   |1st Qu.:23.25  |Class :character     |1st Qu.:5.840      |1st Qu.:23.38        |\n|   |Median :45.50  |Mode  :character     |Median :6.784      |Median :27.63        |\n|   |Mean   :45.50  |NA                   |Mean   :6.752      |Mean   :28.43        |\n|   |3rd Qu.:67.75  |NA                   |3rd Qu.:7.789      |3rd Qu.:32.65        |\n|   |Max.   :90.00  |NA                   |Max.   :9.936      |Max.   :47.41        |\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(factorial_study) |> \n  kable()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 120\nColumns: 4\n$ participant_id          <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,‚Ä¶\n$ feedback_type           <chr> \"positive\", \"positive\", \"positive\", \"positive\"‚Ä¶\n$ experience_level        <chr> \"novice\", \"expert\", \"novice\", \"expert\", \"novic‚Ä¶\n$ performance_improvement <dbl> 9.572290, 1.217696, 7.940961, 8.549420, 6.9159‚Ä¶\n```\n\n\n:::\n\n::: {.cell-output-display}\n\n\n| participant_id|feedback_type |experience_level | performance_improvement|\n|--------------:|:-------------|:----------------|-----------------------:|\n|              1|positive      |novice           |               9.5722901|\n|              2|positive      |expert           |               1.2176963|\n|              3|positive      |novice           |               7.9409608|\n|              4|positive      |expert           |               8.5494197|\n|              5|positive      |novice           |               6.9159456|\n|              6|positive      |expert           |               6.5465480|\n|              7|positive      |novice           |               6.0010612|\n|              8|positive      |expert           |               7.4765922|\n|              9|positive      |novice           |               4.9671210|\n|             10|positive      |expert           |              10.2190882|\n|             11|positive      |novice           |               6.7931111|\n|             12|positive      |expert           |               4.9916590|\n|             13|positive      |novice           |               7.4668424|\n|             14|positive      |expert           |               6.5363013|\n|             15|positive      |novice           |              10.7837222|\n|             16|positive      |expert           |               5.6767243|\n|             17|positive      |novice           |               9.2686134|\n|             18|positive      |expert           |               6.1791098|\n|             19|positive      |novice           |               8.6281249|\n|             20|positive      |expert           |               5.6679884|\n|             21|positive      |novice           |               5.8938496|\n|             22|positive      |expert           |              10.0504075|\n|             23|positive      |novice           |               5.4269373|\n|             24|positive      |expert           |               9.1032825|\n|             25|positive      |novice           |               3.7109239|\n|             26|positive      |expert           |               6.4630255|\n|             27|positive      |novice           |               7.1956689|\n|             28|positive      |expert           |               7.4023036|\n|             29|positive      |novice           |              10.5697228|\n|             30|positive      |expert           |               7.4996319|\n|             31|positive      |novice           |               5.0608211|\n|             32|positive      |expert           |               3.1625578|\n|             33|positive      |novice           |               7.5232869|\n|             34|positive      |expert           |               7.4146383|\n|             35|positive      |novice           |               4.1598785|\n|             36|positive      |expert           |               3.3536203|\n|             37|positive      |novice           |               2.7053393|\n|             38|positive      |expert           |               5.4890255|\n|             39|positive      |novice           |               4.4965277|\n|             40|positive      |expert           |               7.6515065|\n|             41|positive      |novice           |               5.5882754|\n|             42|positive      |expert           |              10.3988276|\n|             43|positive      |novice           |              10.0301169|\n|             44|positive      |expert           |               8.0079965|\n|             45|positive      |novice           |               9.1630881|\n|             46|positive      |expert           |               7.2774370|\n|             47|positive      |novice           |              -1.7190502|\n|             48|positive      |expert           |               7.1855728|\n|             49|positive      |novice           |               7.5647350|\n|             50|positive      |expert           |               8.4529416|\n|             51|positive      |novice           |               5.8807253|\n|             52|positive      |expert           |               2.2009629|\n|             53|positive      |novice           |               7.9873411|\n|             54|positive      |expert           |               5.6394187|\n|             55|positive      |novice           |               4.2337552|\n|             56|positive      |expert           |               7.5267812|\n|             57|positive      |novice           |               8.7126541|\n|             58|positive      |expert           |               4.2216269|\n|             59|positive      |novice           |               8.8907201|\n|             60|positive      |expert           |               9.0889070|\n|             61|critical      |novice           |               2.0326341|\n|             62|critical      |expert           |               5.1983262|\n|             63|critical      |novice           |               2.1374135|\n|             64|critical      |expert           |              10.0455398|\n|             65|critical      |novice           |               4.0429921|\n|             66|critical      |expert           |               1.9634775|\n|             67|critical      |novice           |               0.2921397|\n|             68|critical      |expert           |               1.8184332|\n|             69|critical      |novice           |               0.1086236|\n|             70|critical      |expert           |               5.3079254|\n|             71|critical      |novice           |               4.6340587|\n|             72|critical      |expert           |               6.1491606|\n|             73|critical      |novice           |               6.5785096|\n|             74|critical      |expert           |               1.9853834|\n|             75|critical      |novice           |              -0.1735126|\n|             76|critical      |expert           |               2.2069328|\n|             77|critical      |novice           |               7.5052173|\n|             78|critical      |expert           |               5.3630412|\n|             79|critical      |novice           |               4.0040997|\n|             80|critical      |expert           |              -1.8817379|\n|             81|critical      |novice           |               8.5484264|\n|             82|critical      |expert           |               4.4247997|\n|             83|critical      |novice           |               0.0383440|\n|             84|critical      |expert           |               3.7675867|\n|             85|critical      |novice           |              -1.2327570|\n|             86|critical      |expert           |               3.2635254|\n|             87|critical      |novice           |               3.9437810|\n|             88|critical      |expert           |               1.6835458|\n|             89|critical      |novice           |              -1.3500856|\n|             90|critical      |expert           |               6.9711815|\n|             91|critical      |novice           |               7.8052576|\n|             92|critical      |expert           |              11.6313395|\n|             93|critical      |novice           |               6.9572997|\n|             94|critical      |expert           |               6.1576483|\n|             95|critical      |novice           |               2.4506501|\n|             96|critical      |expert           |              11.4644559|\n|             97|critical      |novice           |               9.4960547|\n|             98|critical      |expert           |               7.4417990|\n|             99|critical      |novice           |              10.1250463|\n|            100|critical      |expert           |              12.7480371|\n|            101|critical      |novice           |               7.6358686|\n|            102|critical      |expert           |               8.0025776|\n|            103|critical      |novice           |              10.4634516|\n|            104|critical      |expert           |               9.4096561|\n|            105|critical      |novice           |               9.3525635|\n|            106|critical      |expert           |              10.4294579|\n|            107|critical      |novice           |              10.7682597|\n|            108|critical      |expert           |               6.3096269|\n|            109|critical      |novice           |              10.7119416|\n|            110|critical      |expert           |               8.5598122|\n|            111|critical      |novice           |               9.5967156|\n|            112|critical      |expert           |               4.1034680|\n|            113|critical      |novice           |               1.5549797|\n|            114|critical      |expert           |              10.7778670|\n|            115|critical      |novice           |               8.1236984|\n|            116|critical      |expert           |              11.1705505|\n|            117|critical      |novice           |               9.9640998|\n|            118|critical      |expert           |               7.0220472|\n|            119|critical      |novice           |               9.8529584|\n|            120|critical      |expert           |              12.4556351|\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(factorial_study) |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|   |participant_id |feedback_type    |experience_level |performance_improvement |\n|:--|:--------------|:----------------|:----------------|:-----------------------|\n|   |Min.   :  1.00 |Length:120       |Length:120       |Min.   :-1.882          |\n|   |1st Qu.: 30.75 |Class :character |Class :character |1st Qu.: 4.206          |\n|   |Median : 60.50 |Mode  :character |Mode  :character |Median : 6.937          |\n|   |Mean   : 60.50 |NA               |NA               |Mean   : 6.367          |\n|   |3rd Qu.: 90.25 |NA               |NA               |3rd Qu.: 8.757          |\n|   |Max.   :120.00 |NA               |NA               |Max.   :12.748          |\n\n\n:::\n:::\n\n\n\n**üí° Short recap**: How have these data sets been created? How do they connect to the experimental designs discussed in the lecture?\n\n::: {.callout-tip title=\"Possible answers\", collapse=\"true\"} \n\n- **Dataset 1**: Classic randomized controlled trial (RCT) with treatment and control groups\n- **Dataset 2**: One-way experimental design with three conditions (between-subjects)\n- **Dataset 3**: 2√ó2 factorial design allowing us to test main effects and interactions\n- **Connection to lecture**: These represent the three main experimental designs we discussed - simple, multi-group, and factorial\n:::\n\n---\n\n# Part 2: Simple Experiments - t-tests\n\nAssume we are asking the following research question:\n\n> Does leadership training improve team performance?\n\nOne way to tackle this question is to compare a treatment group, which has received a leadership training, to a control group, which has not received such training. If the groups are otherwise similar, then this setting should help us to identify the causal effect of the leadership training.^[At this point we assume that the groups were similar before the training. In practice, it would be good to first make sure the performances of the groups before the training were similar.]\n\n## Descriptive statistics\n\nFor this task, we will use the first data set.\nLet us first compute the standard statistics:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndescriptive_stats <- leadership_study_between %>%\n  group_by(group) %>%\n  summarise(\n    n = n(),\n    mean = mean(team_performance),\n    sd = sd(team_performance),\n    median = median(team_performance),\n    .groups = 'drop'\n  )\n\nkable(descriptive_stats, digits = 2)\n```\n\n::: {.cell-output-display}\n\n\n|group    |  n|  mean|   sd| median|\n|:--------|--:|-----:|----:|------:|\n|control  | 30| 74.53| 9.81|  74.26|\n|training | 30| 83.78| 8.35|  82.48|\n\n\n:::\n:::\n\n\nAs usual, it is also strongly recommended to complement the quantitative info with a visualization.\nData such as those is often presented using boxplots:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(leadership_study_between, aes(x = group, y = team_performance, fill = group)) +\n  geom_boxplot(alpha = 0.7) +\n  geom_jitter(width = 0.2, alpha = 0.5) +\n  stat_summary(fun = mean, geom = \"point\", shape = 23, size = 3, fill = \"red\") +\n  labs(title = \"Team Performance by Group\",\n       x = \"Group\",\n       y = \"Team Performance Score\",\n       caption = \"Red diamonds show group means\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nBut boxplots might shallow important distributional info, so you should use them carefully or complement them with other tools. Below is an alternative that provides more information on the distribution of the data.\nFor more on this issue see @Holtz_2025.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(\n  data = leadership_study_between, \n  mapping = aes(x = group, y = team_performance, fill = group)\n  ) +\n    stat_halfeye(\n    adjust = 0.5,\n    justification = -0.2,\n    .width = 0,\n    point_colour = NA\n  ) +\n  geom_boxplot(\n    width = 0.12,\n    outlier.color = NA,\n    alpha = 0.5\n  ) +\n  stat_dots(\n    side = \"left\",\n    justification = 1.1,\n    binwidth = 0.85\n  ) +\n  labs(\n    title = \"The effect of leadership training\",\n    y = \"Team performance\") +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(size = 11),\n    axis.title.x = element_blank()\n  ) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n\n## Assumption Checking\n\nIn the following we want to compare the means across independent groups.\nTo this end, we may use a t-test. \n\nBut such statistical tests make specific assumptions about the data. If these assumptions are violated, the results may be unreliable or incorrect. Therefore, it is important to check the adequacy of the data first.\n\nAnd no worries if the assumptions for one test are violated - usually there are alternatives available.\n\nIn the present case, we want to use a simple t-test. This test makes two assumptions:\n\n1. The two groups each are normally distributed.\n2. The variances of both groups are the same. \n\nTo test the first assumption, we can use the **Shapiro-Wilk Test for Normality**.\nHere we test the following hypotheses:\n\n- $H_0$: The data is normally distributed\n- $H_1$: The data is not normally distributed  \n\nThus, we we get $p > 0.05$, we cannot reject $H_0$. But for smaller $p$-values,\nwe should reject $H_0$ and need to look for alternative tests.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nleadership_study_between |> \n  filter(group==\"control\") |> \n  pull(team_performance) |> \n  shapiro.test()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  pull(filter(leadership_study_between, group == \"control\"), team_performance)\nW = 0.97894, p-value = 0.7966\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nleadership_study_between |> \n  filter(group==\"training\") |> \n  pull(team_performance) |> \n  shapiro.test()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  pull(filter(leadership_study_between, group == \"training\"), team_performance)\nW = 0.98662, p-value = 0.9614\n```\n\n\n:::\n:::\n\n\nGood! We cannot reject the hypothesis of normally distributed data!\n\nThe next step is to test, whether both groups have the same variance. \nLevene's test can be used to do exactly this. It tests:\n\n- **$H_0$**: The variances are equal across groups\n- **H_1**: The variances are not equal across groups\n\nIf $p > 0.05$, we do not reject $H_0$ and we can use a simple t-test.\nIf we have to reject $H_0$, however, it would be better to use the more robust Welch test.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncar::leveneTest(team_performance ~ group, data = leadership_study_between)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  1  1.0763 0.3038\n      58               \n```\n\n\n:::\n:::\n\n\n## Independent t-test\n\n**Why we use t-tests**: To compare means between two groups when we have continuous data and want to test if there's a statistically significant difference.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt_test_result <- t.test(\n  team_performance ~ group, \n  data = leadership_study_between,\n  var.equal = TRUE # Use FALSE if variances unequal\n  )  \nt_test_result\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tTwo Sample t-test\n\ndata:  team_performance by group\nt = -3.9344, df = 58, p-value = 0.0002256\nalternative hypothesis: true difference in means between group control and group training is not equal to 0\n95 percent confidence interval:\n -13.962870  -4.545972\nsample estimates:\n mean in group control mean in group training \n              74.52896               83.78338 \n```\n\n\n:::\n:::\n\n\n## Effect Size Calculation\n\n**What are effect sizes?** The previous result tells us that the difference in \nmeans between the groups appeaers to be about \n-9.25. But is this a lot?\nEffect sizes tell us about the practical significance of our findings - how big is the difference we found? Unlike $p$-values, effect sizes are not influenced by sample size and help us understand if our statistically significant result is also practically meaningful.\n**Cohen's d** is often used: This standardized effect size tells us how many standard deviations apart the two group means are.\n\n- **Small effect**: d ‚âà 0.2 (groups overlap about 85%)\n- **Medium effect**: d ‚âà 0.5 (groups overlap about 67%)  \n- **Large effect**: d ‚âà 0.8 (groups overlap about 53%)\n\nThe implementation in R is trivial:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncohens_d <- effectsize::cohens_d(team_performance ~ group, data = leadership_study_between)\nprint(cohens_d)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCohen's d |         95% CI\n--------------------------\n-1.02     | [-1.55, -0.47]\n\n- Estimated using pooled SD.\n```\n\n\n:::\n:::\n\n\nThe key value here is Cohen's of -1.02! \n(For the interpretation see the exercise below).\n\n## Paired t-test Example\n\nNext, we might want to look at our research question from a slightly different angle.\nRather than the between-subject design from above, we now take a *within-subject* view:\nto this end, we want to check whether the training had an effect on those people who were in the training (treatment) group by comparing their performance before and after the training.\n\nTo this end, we focus on the training group, and then\nuse the function `t.test()` with the argument `paired = TRUE`.\nThis makes sure we are using the version of the test for the within-subjects context:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntraining_group <- leadership_study_within %>% filter(group == \"training\")\npaired_result <- t.test(training_group$post_performance, \n                       training_group$pre_performance,\n                       paired = TRUE)\nprint(paired_result)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPaired t-test\n\ndata:  training_group$post_performance and training_group$pre_performance\nt = 7.4774, df = 29, p-value = 3.059e-08\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 10.55898 18.51001\nsample estimates:\nmean difference \n       14.53449 \n```\n\n\n:::\n:::\n\n\n**üéØ Exercise (5 minutes)**: Interpret the results. What can we conclude about the effectiveness of leadership training?\n\n::: {.callout-tip title=\"Possible answers\", collapse=\"true\"} \n- **Statistical significance**: If $p < 0.05$, training significantly improved performance; since $p\\approx 0$, the training has a highly significant effect\n- **Effect size interpretation**: Cohen's d is large, so we have a large effect. This suggests the effect of the training is also practically meaningful.\n- **Confidence interval**: If the CI doesn't include 0, we're confident there's a real difference; even if we are very conservative, we would still expect a 10 point improvement of the training.\n- **Business implication**: Training appears effective and worth the investment\n:::\n\n---\n\n# Part 3: Multi-Group Experiments - ANOVA (25 minutes)\n\nLet us now turn to the following research question:\n\n> Which communication method (face-to-face, video call, email) leads to highest satisfaction?\n\nNote that this time we not only compare one group to another as in the previous section, but we need to compare three groups with each other as we have three different communication methods.\nTherefore, we cannot use simple t-tests, but need to use an ANOVA.\n\n## Descriptive statistics \n\nBut first, let us again look at the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncommunication_study %>%\n  group_by(communication_method) %>%\n  summarise(\n    n = n(),\n    mean = mean(satisfaction_score),\n    sd = sd(satisfaction_score),\n    min = min(satisfaction_score),\n    max = max(satisfaction_score),\n    .groups = 'drop'\n  ) |> \n  kable(digits = 2)\n```\n\n::: {.cell-output-display}\n\n\n|communication_method |  n| mean|   sd|  min|  max|\n|:--------------------|--:|----:|----:|----:|----:|\n|email                | 30| 5.78| 1.46| 2.74| 8.73|\n|face_to_face         | 30| 7.48| 1.39| 5.14| 9.94|\n|video_call           | 30| 7.00| 1.10| 4.20| 9.50|\n\n\n:::\n:::\n\n\nAnd complement this by a visualization:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(\n  data = communication_study, \n  mapping = aes(\n    x = communication_method, \n    y = satisfaction_score, \n    fill = communication_method,\n    color = communication_method)\n  ) +\n    stat_halfeye(\n    adjust = 0.5,\n    justification = -0.2,\n    .width = 0,\n    point_colour = NA\n  ) +\n  geom_boxplot(\n    width = 0.12,\n    outlier.color = NA,\n    alpha = 0.5\n  ) +\n  stat_dots(\n    side = \"left\",\n    justification = 1.1,\n    binwidth = 0.15\n  ) +\n  stat_summary(fun = mean, geom = \"point\", shape = 23, size = 3, fill = \"white\") +\n  labs(\n    title = \"Satisfaction Scores by Communication Method\",\n    x = \"Communication Method\",\n    y = \"Satisfaction Score (1-10)\") +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(size = 11),\n    axis.title.x = element_blank()\n  ) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n\n\n## ANOVA Assumptions\n\nANOVA is more robust than t-tests but still requires certain conditions to be met for valid results.\nIn fact, we are testing the same assumptions as in the t-test case:\n\n- **Normality of Residuals**: For ANOVA, we check if the residuals (not the raw data) are normally distributed.\n\n\n**Homogeneity of Variances**: ANOVA assumes that the variance of the dependent variable is equal across all groups.\n\n\nLet us start with testing the normality of the residuals. We again use the Shapiro test, which tests the following hypothesis:\n\n- **$H_0$**: Residuals are normally distributed\n- **$H_1$**: Residuals are not normally distributed\n\nThus, if $p > 0.05$, the Null cannot be rejected and we can assume the residuals to follow a normal distribution.\nIf $p \\leq 0.05$, however, the hypothesis of normally distributed residuals must be rejected and we need to consider transforming the data or using a non-parametric test.\n\n\n::: {.cell}\n\n```{.r .cell-code}\naov_model <- aov(satisfaction_score ~ communication_method, data = communication_study)\n\nshapiro.test(residuals(aov_model))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  residuals(aov_model)\nW = 0.99149, p-value = 0.8342\n```\n\n\n:::\n:::\n\n\nSince $p>0.05$ we are on the save side!\n\nWe then check the equality of variances and again use Levene's test with the following hypotheses:\n\n- **$H_0$**: Variances are equal across all groups  \n- **$H_1$**: Variances are not equal across groups\n\nThus, if $p > 0.05$, the Null cannot be rejected and we can assume the variances to be equal.\nIf $p \\leq 0.05$, however, the hypothesis of equal variances must be rejected and we need to consider transforming the data or using  Welch's ANOVA.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncar::leveneTest(satisfaction_score ~ communication_method, data = communication_study)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  2  1.8801 0.1587\n      87               \n```\n\n\n:::\n:::\n\n\nAgain, the Null cannot be rejected and we can continue with the ANOVA as planned.\n\nBefore we enter the actual analysis we can also create the common diagnostics plots:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_data <- augment(aov_model) %>%\n  mutate(\n    sqrt_abs_resid = sqrt(abs(.std.resid)),\n    obs_number = row_number()\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The `augment()` method for objects of class `aov` is not maintained by the broom team, and is only supported through the `lm` tidier method. Please be cautious in interpreting and reporting broom output.\n\nThis warning is displayed once per session.\n```\n\n\n:::\n\n```{.r .cell-code}\nresiduals_vs_fitted <- model_data %>%\n  ggplot(aes(x = .fitted, y = .resid)) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"loess\", se = FALSE, color = \"red\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\", alpha = 0.7) +\n  labs(title = \"Residuals vs Fitted\", x = \"Fitted values\", y = \"Residuals\") +\n  theme_minimal()\n\nqq_plot <- model_data %>%\n  ggplot(aes(sample = .std.resid)) +\n  stat_qq(alpha = 0.7) +\n  stat_qq_line(color = \"red\") +\n  labs(title = \"Normal Q-Q\", x = \"Theoretical Quantiles\", y = \"Standardized Residuals\") +\n  theme_minimal()\n\nscale_location <- model_data %>%\n  ggplot(aes(x = .fitted, y = sqrt_abs_resid)) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"loess\", se = FALSE, color = \"red\") +\n  labs(title = \"Scale-Location\", x = \"Fitted values\", \n       y = expression(sqrt(\"|Standardized residuals|\"))) +\n  theme_minimal()\n\nresiduals_vs_leverage <- model_data %>%\n  ggplot(aes(x = .hat, y = .std.resid)) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"loess\", se = FALSE, color = \"red\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\", alpha = 0.7) +\n  labs(title = \"Residuals vs Leverage\", x = \"Leverage\", y = \"Standardized Residuals\") +\n  theme_minimal()\n\ncombined_patchwork <- (residuals_vs_fitted | qq_plot) / \n                            (scale_location | residuals_vs_leverage) +\n  plot_annotation(\n    title = \"ANOVA Model Diagnostic Plots\",\n    subtitle = \"Checking model assumptions\",\n    theme = theme(plot.title = element_text(size = 16, hjust = 0.5))\n  )\ncombined_patchwork\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 5.7673\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 1.7108\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 5.2991e-16\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 2.9267\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 5.7673\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 1.7108\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 5.2991e-16\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 2.9267\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 0.033333\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 1.6695e-14\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 7.744e-16\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.3333e-34\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n- **Residuals vs Fitted**: Should show random scatter (no patterns)\n- **Q-Q plot**: Points should follow the diagonal line (normality)\n- **Scale-Location**: Should show random scatter (equal variances)\n- **Residuals vs Leverage**: Identifies influential outliers\n\n## One-Way ANOVA\n\nSince we compare three groups we do not use t-tests but an ANOVA. \n\nAs you know, ANOVA is actually a special case of linear regression. \nTherefore, we can get the ANOVA results in two equivalent ways.\n\nThe first option is to use the classical `aov()` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova_result <- aov(satisfaction_score ~ communication_method, data = communication_study)\nsummary(anova_result)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                     Df Sum Sq Mean Sq F value   Pr(>F)    \ncommunication_method  2  46.29  23.146    13.2 9.81e-06 ***\nResiduals            87 152.50   1.753                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nThe second option is to use `lm()` as we know it from linear regression:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_model <- lm(satisfaction_score ~ communication_method, data = communication_study)\nanova(lm_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: satisfaction_score\n                     Df  Sum Sq Mean Sq F value    Pr(>F)    \ncommunication_method  2  46.292 23.1460  13.205 9.813e-06 ***\nResiduals            87 152.497  1.7528                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n- The overall $p$-value is extremely small, so the Null hypothesis of no difference between the groups should definitely be rejected\n- In other words: Communication method significantly affects satisfaction scores\n- This means that at least one communication method produces significantly different satisfaction scores than the others\n- But the result does not tell us which specific methods differ from each other (need post-hoc tests)\n- The result also does not contain information about the direction of differences (which method is best/worst) or the effect size\n\n## Detour: categorical variables in Regression\n\nWhen you add a categorial variable as a predictor to your regression, R automatically creates dummy variables for categorical predictors. The first level alphabetically becomes the reference group:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm_model)$coefficients |> \n  kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|                                 | Estimate| Std. Error| t value| Pr(>&#124;t&#124;)|\n|:--------------------------------|--------:|----------:|-------:|------------------:|\n|(Intercept)                      |    5.776|      0.242|  23.895|              0.000|\n|communication_methodface_to_face |    1.702|      0.342|   4.980|              0.000|\n|communication_methodvideo_call   |    1.227|      0.342|   3.590|              0.001|\n\n\n:::\n:::\n\nSince 'email' comes first alphabetically, it is the reference group.\n\n- **Intercept** = mean of reference group (email, comes first alphabetically)\n- **communication_methodface_to_face** = difference between face_to_face and email\n- **communication_methodvideo_call** = difference between video_call and email\n\nWe can verify this manually:\n\n::: {.cell}\n\n```{.r .cell-code}\ncommunication_study %>%\n  group_by(communication_method) %>%\n  summarise(mean = mean(satisfaction_score), .groups = 'drop') |> \n  kable(digits = 2)\n```\n\n::: {.cell-output-display}\n\n\n|communication_method | mean|\n|:--------------------|----:|\n|email                | 5.78|\n|face_to_face         | 7.48|\n|video_call           | 7.00|\n\n\n:::\n:::\n\n\n\n### Detour: When to Use `lm()` vs `aov()`\n\nAs shown above, both approaches give identical results.\nStill, they offer different perspectives:\n\n**Use aov() when:**\n- You want traditional ANOVA output\n- Focus is on group comparisons\n- Need post-hoc tests such as `TukeyHSD()`, which take the `aov`-model as an input\n\n**Use lm() when:**\n- You want to see specific contrasts\n- Planning to add continuous covariates later\n- Want regression-style interpretation\n- Building toward more complex models\n\n\n::: {.callout-tip collapse=\"true\"}\n### Example: From ANOVA to ANCOVA\n\nIf we add a continuous variable to an ANOVA, we get an ANCOVA:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nancova_model <- lm(satisfaction_score ~ communication_method + task_completion_time, \n                   data = communication_study)\nsummary(ancova_model) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = satisfaction_score ~ communication_method + task_completion_time, \n    data = communication_study)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3.07895 -0.87806 -0.00768  0.78530  2.90678 \n\nCoefficients:\n                                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                      5.628267   0.807830   6.967 6.15e-10 ***\ncommunication_methodface_to_face 1.737394   0.389664   4.459 2.48e-05 ***\ncommunication_methodvideo_call   1.253306   0.369901   3.388  0.00106 ** \ntask_completion_time             0.004472   0.023342   0.192  0.84853    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.331 on 86 degrees of freedom\nMultiple R-squared:  0.2332,\tAdjusted R-squared:  0.2064 \nF-statistic: 8.718 on 3 and 86 DF,  p-value: 4.108e-05\n```\n\n\n:::\n:::\n\n\nIn the example, we now control for individual differences in task completion time.\nWhile trivial in the `lm()`-context, this would be much harder to do with the aov() approach!\n:::\n\n\n## Effect Size for ANOVA\n\n$\\eta^2$ tells us what proportion of the total variance in the dependent variable is explained by the independent variable and, as explained above, serves as a standardized measure for comparing effect sizes:\n\nRemember that:\n\n- **Small effect**: Œ∑¬≤ ‚âà 0.01 (1% of variance)\n- **Medium effect**: Œ∑¬≤ ‚âà 0.06 (6% of variance)\n- **Large effect**: Œ∑¬≤ ‚âà 0.14 (14% of variance)\n- **Example**: Œ∑¬≤ = 0.23 means communication method explains 23% of satisfaction variance\n\nIn our case:\n\n\n::: {.cell}\n\n```{.r .cell-code}\neta_squared <- effectsize::eta_squared(anova_result)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nFor one-way between subjects designs, partial eta squared is equivalent\n  to eta squared. Returning eta squared.\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(eta_squared)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Effect Size for ANOVA\n\nParameter            | Eta2 |       95% CI\n------------------------------------------\ncommunication_method | 0.23 | [0.11, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n```\n\n\n:::\n:::\n\n\n## Post-Hoc Comparisons\n\nThe ANOVA tells us there's a difference somewhere among the groups, but not which specific groups differ. \nThis is why we need post-hoc tests:\nthey provide these pairwise comparisons while controlling for multiple testing.\n\n::: {.callout-tip collapse=\"true\"}\n### The multiple testing problem\n\nIf we do multiple t-tests (e.g. one for each pairwise comparison), our Type I error rate will inflate. \nPost-hoc tests adjust critical values to maintain overall $\\alpha = 0.05$.\n:::\n\n\nThe most common post-hoc test has a nice name:\nTukey's Honestly Significant Difference (HSD). \nIt takes the fitted ANOVA model as its input:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntukey_result <- TukeyHSD(anova_result)\nprint(tukey_result)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = satisfaction_score ~ communication_method, data = communication_study)\n\n$communication_method\n                             diff        lwr       upr     p adj\nface_to_face-email       1.702240  0.8871253 2.5173543 0.0000095\nvideo_call-email         1.227135  0.4120202 2.0422492 0.0015714\nvideo_call-face_to_face -0.475105 -1.2902195 0.3400094 0.3506328\n```\n\n\n:::\n:::\n\n\nThis suggests that the following differences exist:\n\n- Face-to-face > Email: 1.70 points higher satisfaction ($p < 0.001$)\n- Video call > Email: 1.23 points higher satisfaction ($p = 0.002$)\n\nBut there are no significant differences between video calls and face-to-face ($p = 0.35$)\n\nThus, both face-to-face and video call communication methods produce significantly higher satisfaction scores than email, but face-to-face and video call don't differ significantly from each other.\n\n\n# Part 4: Factorial Designs (20 minutes)\n\nFor this last part we consider the following research question:\n\n> How do feedback type and experience level interact to affect performance improvement?\n\nWe use the data stored as `factorial_study`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfactorial_study %>%\n  group_by(feedback_type, experience_level) %>%\n  summarise(\n    n = n(),\n    mean = mean(performance_improvement),\n    sd = sd(performance_improvement),\n    .groups = 'drop'\n  ) |> \n  kable(digits = 2)\n```\n\n::: {.cell-output-display}\n\n\n|feedback_type |experience_level |  n| mean|   sd|\n|:-------------|:----------------|--:|----:|----:|\n|critical      |expert           | 30| 6.53| 3.79|\n|critical      |novice           | 30| 5.53| 4.10|\n|positive      |expert           | 30| 6.69| 2.27|\n|positive      |novice           | 30| 6.71| 2.66|\n\n\n:::\n:::\n\n\nWe then visualize the relationship using an interaction plot as discussed in the lecture:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(\n  data = factorial_study, \n  mapping = aes(\n    x = experience_level, \n    y = performance_improvement, \n    color = feedback_type, \n    group = feedback_type)\n  ) +\n  stat_summary(fun = mean, geom = \"point\", size = 2) +\n  stat_summary(fun = mean, geom = \"line\", linewidth = 1) +\n  stat_summary(fun.data = mean_se, geom = \"errorbar\", width = 0.1) +\n  guides(color = guide_legend(position = \"inside\")) +\n  labs(\n    title = \"Interaction Plot: Feedback Type √ó Experience Level\",\n    x = \"Experience Level\",\n    y = \"Performance Improvement\",\n    color = \"Feedback Type\") +\n  theme_minimal() +\n  theme(legend.position.inside = c(0.5, 0.2))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\n\nThis already gives us a good visual impression of the results, but we also want to analyze the results quantitatively.\n\n### Two-Way ANOVA\n\nThe factorial design allows us to consider interaction effects among factors. \nBut to detect such interaction, we must use a two-way ANOVA, not the traditional one!\n\nTo do this, we still use the same function `aov()` (or `lm()`), but add the additional factor to the formula:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfactorial_model <- aov(\n  formula = performance_improvement ~ feedback_type * experience_level, \n  data = factorial_study)\nsummary(factorial_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                Df Sum Sq Mean Sq F value Pr(>F)\nfeedback_type                    1   13.4  13.430   1.237  0.268\nexperience_level                 1    7.1   7.115   0.656  0.420\nfeedback_type:experience_level   1    7.9   7.877   0.726  0.396\nResiduals                      116 1259.1  10.854               \n```\n\n\n:::\n:::\n\n\nAnd while the classical ANOVA was the same as simple linear regression with categorial variables, \ntwo-way ANOVA is the same as *multiple* regression with interaction effects:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_factorial <- lm(performance_improvement ~ feedback_type * experience_level, \n                   data = factorial_study)\nanova(lm_factorial)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: performance_improvement\n                                Df  Sum Sq Mean Sq F value Pr(>F)\nfeedback_type                    1   13.43 13.4301  1.2373 0.2683\nexperience_level                 1    7.12  7.1155  0.6556 0.4198\nfeedback_type:experience_level   1    7.88  7.8766  0.7257 0.3960\nResiduals                      116 1259.07 10.8541               \n```\n\n\n:::\n:::\n\n\n\n::: {.callout-tip collapse=\"true\"}\n### Dummy coding in the two-way context\n\nWith two factors, R creates dummy variables for each factor plus their interaction:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoefficients(lm_factorial)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                 (Intercept) \n                                   6.5317033 \n                       feedback_typepositive \n                                   0.1566833 \n                      experience_levelnovice \n                                  -0.9994123 \nfeedback_typepositive:experience_levelnovice \n                                   1.0247960 \n```\n\n\n:::\n:::\n\n\nTheir interpretation is as follows:\n\n- **Intercept** = mean of reference group (critical feedback + expert)\n- **feedback_typepositive** = main effect of positive vs critical for experts only\n- **experience_levelnovice** = main effect of novice vs expert for critical feedback only\n- **interaction** = additional effect of being novice AND receiving positive feedback\n\n\n:::\n\n\n\n\n## Effect Sizes for Factorial Design\n\nEffect sizes are computed in the same way:\n\n\n::: {.cell}\n\n```{.r .cell-code}\neta_squared_factorial <- effectsize::eta_squared(factorial_model)\nprint(eta_squared_factorial)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Effect Size for ANOVA (Type I)\n\nParameter                      | Eta2 (partial) |       95% CI\n--------------------------------------------------------------\nfeedback_type                  |           0.01 | [0.00, 1.00]\nexperience_level               |       5.62e-03 | [0.00, 1.00]\nfeedback_type:experience_level |       6.22e-03 | [0.00, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n```\n\n\n:::\n:::\n\n\n\n## Advanced Visualization of factorial designs\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(\n  data = factorial_study, \n  mapping = aes(\n    x = feedback_type, \n    y = performance_improvement, \n    fill = feedback_type)\n  ) +\n    stat_halfeye(\n    adjust = 0.5,\n    justification = -0.2,\n    .width = 0,\n    point_colour = NA\n  ) +\n  geom_boxplot(\n    width = 0.12,\n    outlier.color = NA,\n    alpha = 0.5\n  ) +\n  stat_dots(\n    side = \"left\",\n    justification = 1.1,\n    binwidth = 0.15\n  ) +\n  facet_wrap(~ experience_level) +\n  labs(\n    title = \"Performance Improvement by Feedback Type and Experience\",\n    x = \"Feedback Type\",\n    y = \"Performance Improvement\") +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(size = 11),\n    axis.title.x = element_blank()\n  ) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n:::\n\n\n\n**üéØ Intermediate exercise**: \n1. Interpret the main effects and interaction\n2. What practical recommendations would you make based on these results?\n3. How does this connect to the i-frame vs s-frame discussion from the lecture?\n\n::: {.callout-tip title=\"Possible answers\", collapse=} 2\n**1. Interpretation:**\n- **Main effect of feedback**: If significant, one type of feedback is generally better\n- **Main effect of experience**: If significant, novices and experts respond differently overall\n- **Interaction effect**: If significant, optimal feedback depends on experience level\n- **Visual cues**: Parallel lines = no interaction; crossing lines = interaction present\n\n**2. Practical recommendations:**\n- **If interaction significant**: Customize feedback approach based on experience level\n- **For novices**: Might need more positive, encouraging feedback\n- **For experts**: Might benefit from more critical, detailed feedback\n- **Training programs**: Should differentiate based on employee experience\n\n**3. i-frame vs s-frame connection:**\n- **i-frame approach**: Train managers to give different feedback to different employees\n- **s-frame approach**: Change organizational culture and systems to support appropriate feedback\n- **Individual focus**: Coaching managers on feedback skills\n- **Structural focus**: Performance management systems that account for experience levels\n:::\n\n---\n\n# Part 5: Power Analysis and Sample Size Planning\n\nStatistical power is the probability of detecting an effect when it truly exists. \nYou know from the lecture that the decision about sample sizes determines in part statistical power.\nPower analysis helps us plan adequate sample sizes and evaluate our study's sensitivity.\n\n## General aspects of power analysis\n\nRemember the **components of power analysis:**\n\n- **Power**: Probability of detecting effect (usually we want ‚â• 0.8)\n- **Effect size**: How big a difference we want to detect\n- **Sample size**: Number of participants needed\n- **Alpha level**: Type I error rate (usually 0.05)\n\nWe can use power analysis in two different ways:\n\n1. **Post-hoc (observed)**: What was our power given the sample size we had?\n2. **A priori (prospective)**: How many participants do we need to detect an effect?\n\nRegarding the first, we may ask: \nwhat was our power to detect the effect we found in the leadership study?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nobserved_power <- pwr.t.test(n = 30, d = as.numeric(cohens_d$Cohens_d), sig.level = 0.05)\nprint(observed_power)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Two-sample t test power calculation \n\n              n = 30\n              d = 1.015848\n      sig.level = 0.05\n          power = 0.9718339\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n\n\n:::\n:::\n\nLets turn to the \n*a priori power analysis*, i.e. what you should do BEFORE collecting data to determine how many participants you need.\n\nIn a first step, you always need to specify your research parameters:\n\n- What effect size do you want to detect?\n- What power level do you want? (typically 0.8 or 0.9)\n- What alpha level will you use? (typically 0.05)\n\nThe remaining steps depend on the analysis method we wish to employ:\n\n## t-Tests\n\nAssume we want to plan a new leadership training study, similar to the one above.\nWe want to detect a medium effect ($d = 0.5$) with 80% power.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample_size_medium <- pwr.t.test(d = 0.5, power = 0.8, sig.level = 0.05)\nprint(sample_size_medium)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Two-sample t test power calculation \n\n              n = 63.76561\n              d = 0.5\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n\n\n:::\n:::\n\n\nIf instead we would like to identify a small effect (with $d=0.5$). \nEverything else remains the same:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample_size_small <- pwr.t.test(d = 0.2, power = 0.8, sig.level = 0.05)\nprint(sample_size_small)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Two-sample t test power calculation \n\n              n = 393.4057\n              d = 0.2\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n\n\n:::\n:::\n\n\nAnd what would happen if we wanted higher power (90%) for a medium effect?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample_size_high_power <- pwr.t.test(d = 0.5, power = 0.9, sig.level = 0.05)\nprint(sample_size_high_power)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Two-sample t test power calculation \n\n              n = 85.03128\n              d = 0.5\n      sig.level = 0.05\n          power = 0.9\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n\n\n:::\n:::\n\n\nWe see that small design choices can have huge effects:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npower_results <- tibble(\n  Scenario = c(\"Medium effect, 80% power\", \"Small effect, 80% power\", \"Medium effect, 90% power\"),\n  Effect_Size = c(0.5, 0.2, 0.5),\n  Power = c(0.8, 0.8, 0.9),\n  Sample_per_Group = c(\n    ceiling(sample_size_medium$n),\n    ceiling(sample_size_small$n), \n    ceiling(sample_size_high_power$n)\n  ),\n  Total_Sample = c(\n    ceiling(sample_size_medium$n) * 2,\n    ceiling(sample_size_small$n) * 2,\n    ceiling(sample_size_high_power$n) * 2\n  )\n)\n\nkable(power_results)\n```\n\n::: {.cell-output-display}\n\n\n|Scenario                 | Effect_Size| Power| Sample_per_Group| Total_Sample|\n|:------------------------|-----------:|-----:|----------------:|------------:|\n|Medium effect, 80% power |         0.5|   0.8|               64|          128|\n|Small effect, 80% power  |         0.2|   0.8|              394|          788|\n|Medium effect, 90% power |         0.5|   0.9|               86|          172|\n\n\n:::\n:::\n\n\n\n\n##ANOVA \n\nAssume we are planning a communication study with 3 groups and we want to \ndetect a medium effect (f = 0.25) with 80% power. \nNote that what was Cohen's d for the t-test case, has now become Cohens f for the ANOVA case:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample_size_anova <- pwr.anova.test(k = 3, f = 0.25, sig.level = 0.05, power = 0.8)\nprint(sample_size_anova)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Balanced one-way analysis of variance power calculation \n\n              k = 3\n              n = 52.3966\n              f = 0.25\n      sig.level = 0.05\n          power = 0.8\n\nNOTE: n is number in each group\n```\n\n\n:::\n:::\n\n\n# Summary and Key Takeaways\n\n## Key take-aways\n1. **Data exploration** is crucial before statistical testing\n2. **Assumption checking** ensures valid results and guides method selection\n3. **Effect sizes** provide practical significance context beyond p-values\n4. **Visualization** aids interpretation and communication of results\n5. **ANOVA is just regression** with categorical predictors\n6. **Both aov() and lm()** give identical results but offer different perspectives\n7. **Post-hoc tests** control for multiple comparisons when making pairwise comparisons\n8. **Factorial designs** allow detection of interactions between factors\n\n### Key Decision Points in Analysis\n- **Assumptions violated**: Choose appropriate alternatives (Welch's tests, transformations, non-parametric)\n- **Multiple groups**: ANOVA preferred over multiple t-tests\n- **Factorial designs**: Allow testing of interactions between factors\n- **Effect size interpretation**: Always consider practical alongside statistical significance\n- **Post-hoc testing**: Required when ANOVA is significant to identify which groups differ\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}