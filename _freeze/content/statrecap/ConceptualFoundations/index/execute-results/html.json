{
  "hash": "30e71092edc888003755ff3dabdeb4c9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"1: What is Statistics all about? Conceptual Foundations\"\ndate: '2025-05-10'\n---\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Packages used for R examples\"}\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(ggpubr)\nlibrary(kableExtra)\n```\n:::\n\n\n\n# Introduction: Why Statistics Might Feel Intimidating (And Why It Shouldn't)\n\nIf you're reading this with a slight sense of dread, you're not alone. Many master's students in management and business fields approach statistics with apprehension, often because they've had negative experiences with mathematics in the past or because statistics feels abstract and removed from practical business applications. Let's start by addressing this directly: statistics is not about complex mathematical formulas that only mathematicians can understand. Instead, it's a powerful toolkit for making sense of uncertainty and making better decisions in an uncertain world.\n\nThink of statistics as a language—a way of communicating with data and extracting meaningful insights from the noise of everyday business and research activities. Just as you wouldn't expect to become fluent in a foreign language overnight, becoming comfortable with statistical thinking takes time and practice. The goal isn't to become a mathematician; it's to develop a mindset that helps you navigate uncertainty with confidence.\n\n# What is Statistics and Why Do We Need It?\n\nAt its core, statistics is the science of learning from data. More specifically, it's a collection of methods and principles that help us collect, organize, analyze, and interpret information to answer questions and solve problems. But why do we need this formal approach? Why can't we just look at data and draw conclusions intuitively?\n\n> Consider a simple business scenario: You're the marketing manager for a company that recently launched a new advertising campaign. After three months, you notice that sales have increased by over 56% if compared to the average sales before the campaign. \nThis sounds like good news, but several questions immediately arise: Is this increase actually due to your campaign, or could it be caused by seasonal trends, competitor actions, or random fluctuations? How confident can you be that this trend will continue? Is this increase significant enough to justify the campaign's cost? \n@fig-campaign gives a first idea of why the answer to these questions is not as easy as it might appear and requires thorough statistical reasoning and computation skills!\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Creating the dataset used in example\"}\n# Set seed for reproducibility\nset.seed(123)\n\n# Create monthly dates for a 2-year period\ndates <- seq(as.Date(\"2023-01-01\"), as.Date(\"2024-12-01\"), by = \"month\")\nmonth <- format(dates, \"%m\")\nyear <- format(dates, \"%Y\")\n\n# Create a seasonal pattern (higher in Q4, lower in Q1)\nseasonal_factor <- c(0.8, 0.7, 0.8, 0.9, 1.0, 1.0, 0.9, 0.9, 1.1, 1.3, 1.4, 1.6)\nmonthly_effect <- seasonal_factor[as.numeric(month)]\n\n# Base sales with year-over-year growth and seasonal effects\nbase_sales <- 100000 * (1 + 0.03 * (as.numeric(year) - 2023)) * monthly_effect\n# Add random noise\nsales <- base_sales * rnorm(length(dates), mean = 1, sd = 0.04)\n\n# Create campaign effect (after September 2024)\n# campaign effect is  5%, starts right before seasonal upswing\ncampaign_date <- as.Date(\"2024-09-01\")\ncampaign_effect <- ifelse(dates >= campaign_date, 1.05, 1)\n\n# Apply campaign effect to get final sales\nfinal_sales <- sales * campaign_effect\n\n# Create data frame\nsales_data <- data.frame(\n  date = dates,\n  month = month,\n  year = year,\n  sales = round(final_sales),\n  campaign = dates >= campaign_date\n)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"R code for the visualization\"}\nblue_col <- \"#3498db\"\nred_col <- \"#e74c3c\"\n\n# Get only 2024 data for the first plot\nsales_data_2024 <- filter(sales_data, year == \"2024\")\n\n# Calculate misleading metrics someone might report (2024 only)\nmean2024_before_campaign<- mean(filter(sales_data_2024, !campaign)$sales)\nmean2024_after_campaign <- mean(filter(sales_data_2024, campaign)$sales)\nnaive_increase_2024 <- (\n  mean2024_after_campaign / mean2024_before_campaign - 1) * 100\ncorrected_increase <- sales_data |>\n  filter(month %in% filter(sales_data_2024, campaign)$month) |>\n  summarise(avg_sales=mean(sales), .by = year) |>\n  pivot_wider(names_from = \"year\", values_from = \"avg_sales\") |>\n  mutate(increase=(`2024` / `2023` - 1) *100) |>\n  pull(\"increase\")\n\n# Plot 1: 2024-only view\nplot_2024 <- ggplot(sales_data_2024, aes(x = date, y = sales)) +\n  geom_line(alpha = 0.6, linewidth = 0.8) +\n  geom_point(aes(color = campaign), alpha = 0.8, size = 2.5) +\n  geom_vline(\n    xintercept = as.Date(\"2024-09-01\"),\n    linetype = \"dashed\", color = \"darkred\"\n  ) +\n  # Add annotation for campaign launch\n  annotate(\"text\",\n    x = as.Date(\"2024-09-01\") - 15, y = max(sales_data_2024$sales) * 0.95,\n    label = \"Campaign Launch\", hjust = 1, color = \"darkred\"\n  ) +\n  # Add horizontal line for average before\n  geom_hline(\n    yintercept = mean2024_before_campaign, linetype = \"dotted\", color = blue_col\n    ) +\n  annotate(\"text\",\n    x = as.Date(\"2024-03-15\"), y = mean2024_before_campaign * 1.03,\n    label = paste0(\"Avg Before: \", \n                   format(round(mean2024_before_campaign), \n                          big.mark = \".\", \n                          decimal.mark = \",\")\n                   ),\n    color = blue_col\n  ) +\n  # Add horizontal line for average after\n  geom_hline(\n    yintercept = mean2024_after_campaign, linetype = \"dotted\", color = red_col\n    ) +\n  annotate(\"text\",\n    x = as.Date(\"2024-03-15\"), y = mean2024_after_campaign * 1.03,\n    label = paste0(\"Avg After: \", \n                   format(round(mean2024_after_campaign), \n                          big.mark = \".\", \n                          decimal.mark = \",\")),\n    color = red_col\n  ) +\n  # Add title and labels\n  labs(\n    title = \"2024 Sales Before and After Marketing Campaign\",\n    subtitle = paste0(\n      \"It appears the campaign increased sales by \",\n      round(naive_increase_2024, 1), \"%!\"\n    ),\n    x = \"Month (2024)\",\n    y = \"Sales\",\n    color = \"After Campaign Launch\"\n  ) +\n  # Styling options\n  scale_color_manual(\n    values = c(\"FALSE\" = blue_col, \"TRUE\" = red_col)\n    ) +\n  scale_y_continuous(\n    labels = scales::number_format(scale = 0.001, suffix = \"k €\")\n    ) +\n  theme_minimal() +\n  theme(legend.position = \"none\", axis.title.x = element_blank())\n\n# Plot 2: The full context with both years\nplot_full <- ggplot(sales_data, aes(x = date, y = sales)) +\n  geom_line(alpha = 0.5) +\n  geom_point(aes(color = campaign), alpha = 0.7, size = 2) +\n  geom_vline(\n    xintercept = as.Date(\"2024-09-01\"),\n    linetype = \"dashed\", color = \"darkred\"\n  ) +\n  geom_vline(\n    xintercept = as.Date(\"2024-01-01\"),\n    linetype = \"dotted\", color = \"gray50\"\n  ) +\n  annotate(\"text\",\n    x = as.Date(\"2024-09-01\") - 15, y = max(sales_data$sales) * 0.9,\n    label = \"Campaign Launch\", hjust = 1, color = \"darkred\"\n  ) +\n  annotate(\"rect\",\n    xmin = as.Date(\"2023-09-01\"), xmax = as.Date(\"2023-12-31\"),\n    ymin = min(sales_data$sales) * 0.95, ymax = max(sales_data$sales),\n    alpha = 0.1, fill = \"darkblue\"\n  ) +\n  annotate(\"rect\",\n    xmin = as.Date(\"2024-09-01\"), xmax = as.Date(\"2024-12-31\"),\n    ymin = min(sales_data$sales) * 0.95, ymax = max(sales_data$sales),\n    alpha = 0.1, fill = \"darkred\"\n  ) +\n  annotate(\"text\",\n    x = as.Date(\"2023-06-01\"), y = max(sales_data$sales) * 0.85,\n    label = paste0(\"True year-over-year increase: \", \n                   round(corrected_increase, 1)  , \"%\"),\n    color = \"black\", size = 4\n  ) +\n  annotate(\"text\",\n    x = as.Date(\"2023-06-01\"), y = max(sales_data$sales) * 0.8,\n    label = \"Actual campaign effect: 5%\",\n    color = \"black\", size = 4\n  ) +\n  labs(\n    title = \"Full Context: Sales Data for 2023-2024\",\n    subtitle = \"Most of the increase is due to seasonal patterns\",\n    x = \"Month\",\n    y = \"Sales\",\n    color = \"After Campaign Launch\"\n  ) +\n  # Styling options\n  scale_color_manual(\n    values = c(\"FALSE\" = blue_col, \"TRUE\" = red_col)\n    ) +\n  scale_y_continuous(\n    labels = scales::number_format(scale = 0.001, suffix = \"k €\")\n    ) +\n  theme_minimal() +\n  theme(legend.position = \"none\", axis.title.x = element_blank())\n\n# Combine the plots\ncombined_plot <- ggarrange(plot_2024, plot_full,\n  labels = c(\"A\", \"B\"),\n  ncol = 1, nrow = 2,\n  legend = \"none\"\n)\n\n# Add an overall title\ncombined_plot <- annotate_figure(\n  combined_plot,\n  top = text_grob(\"The Importance of Sound Data Analysis\",\n    face = \"bold\", size = 14\n  )\n)\ncombined_plot\n```\n\n::: {.cell-output-display}\n![The apparent effect of a marketing campaign!](index_files/figure-html/fig-campaign-1.png){#fig-campaign width=864}\n:::\n:::\n\n\n\nThese questions illustrate why we need statistics. Our intuition, while valuable, is often inadequate for making sense of complex data patterns. Humans are naturally prone to seeing patterns where none exist (we call this \"apophenia\") and tend to overinterpret small samples or unusual events. Statistics provides us with rigorous methods to distinguish between real patterns and random noise, to quantify our uncertainty, and to make informed decisions despite incomplete information.\n\nStatistics serves several crucial functions in business and research contexts. First, it helps us describe and summarize large amounts of data in meaningful ways. When faced with thousands of customer transactions, we can use statistical measures to understand central tendencies, variability, and patterns that would be impossible to grasp by examining individual data points.\n\nSecond, statistics enables us to make inferences about populations based on samples. This is particularly valuable in business, where it's often impractical or impossible to survey every customer or test every possible scenario. By studying a representative sample, we can draw conclusions about the broader population with a known degree of confidence.\n\n> For instance, if you want to understand customer satisfaction across your company's 50,000 customers, you don't need to survey all 50,000. A properly designed survey of 1,000 randomly selected customers can give you reliable insights about the entire customer base, saving time and resources while still providing actionable information.\n\nThird, statistics helps us test hypotheses and evaluate claims. When someone claims that a new training program improves employee productivity, statistics provides the framework for testing whether this claim is supported by evidence or whether observed differences could reasonably be attributed to chance.\n\nFinally, statistics enables prediction and forecasting. While we cannot predict the future with certainty, statistical models help us understand relationships between variables and make informed projections about likely outcomes under different scenarios.\n\n# What is Probability Theory and Why Do We Need It?\n\nProbability theory might sound abstract, but it serves a crucial practical purpose: it provides the reference point we need to make sense of what we observe in data. Without probability theory, we cannot determine whether our observations are surprising, expected, or somewhere in between.\n\n> Imagine you're recruiting for a basketball team and a candidate tells you he was 200 cm tall. Is this unusually tall or fairly normal? You can't answer this question just by looking at this single number. You need a reference point - specifically, you need to know how height is distributed in the general population. Probability theory tells us that height of men in Germany follows a roughly normal distribution with an average around 178.9 cm and a certain spread around that average. With this reference, we can determine that 200 cm is indeed rare - occurring in perhaps 1 in 520 people or fewer (see @fig-height).\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"R code to compute change for being 200cm or higher\"}\nmean_height <- 178.9 # Mean height of German men\nsd_height <- 7.3  # Standard deviation\n\n# Create a data frame for the distribution\nheight_range <- seq(150, 230, by = 0.1)\nheight_density <- dnorm(height_range, mean = mean_height, sd = sd_height)\n\nheight_df <- data.frame(\n  height = height_range,\n  density = height_density\n)\n\n# Calculate the probability of being 200 cm or taller\nprob_200_plus <- pnorm(\n  q = 200, mean = mean_height, sd = sd_height, lower.tail = FALSE)\napprox_odds <- round(1 / prob_200_plus)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"R code for the visualization\"}\nggplot(height_df, aes(x = height, y = density)) +\n  geom_line(size = 1.2, color = \"royalblue\") +\n  geom_area(fill = \"royalblue\", alpha = 0.3) +\n  \n  geom_vline(xintercept = mean_height, linetype = \"dashed\", color = \"darkblue\") +\n  annotate(\"text\", x = mean_height + 4, y = max(height_density) * 0.95, \n           label = paste0(\"Mean = \", mean_height, \" cm\"), \n           hjust = 0, color = \"darkblue\") +\n  \n  geom_vline(xintercept = 200, linetype = \"dashed\", color = \"red\") +\n  \n  geom_area(data = subset(height_df, height >= 200),\n            fill = \"red\", alpha = 0.4) +\n  \n  # Add probability annotation\n  annotate(\"text\", x = 205, y = max(height_density) * 0.6,\n           label = paste0(\"Probability ≈ 1 in \", format(approx_odds, big.mark=\",\")),\n           color = \"red\", hjust = 0.0) +\n  \n  # Add standard deviation markers\n  geom_segment(aes(x = mean_height + sd_height, xend = mean_height + sd_height, \n                  y = 0, yend = dnorm(mean_height + sd_height, mean = mean_height, sd = sd_height)),\n              linetype = \"dotted\", color = \"gray30\") +\n  geom_segment(aes(x = mean_height + 2*sd_height, xend = mean_height + 2*sd_height, \n                  y = 0, yend = dnorm(mean_height + 2*sd_height, mean = mean_height, sd = sd_height)),\n              linetype = \"dotted\", color = \"gray30\") +\n  geom_segment(aes(x = mean_height + 3*sd_height, xend = mean_height + 3*sd_height, \n                  y = 0, yend = dnorm(mean_height + 3*sd_height, mean = mean_height, sd = sd_height)),\n              linetype = \"dotted\", color = \"gray30\") +\n  \n  # Add titles and labels\n  labs(\n    title = \"Distribution of Adult Male Height\",\n    subtitle = paste0(\"200 cm is an extreme value (approximately 1 in \", \n                     format(approx_odds, big.mark=\",\"), \" people)\"),\n    x = \"Height (cm)\",\n    y = \"Probability Density\",\n    caption = \"Note: Based on average adult male height distribution for Germany.\"\n  ) +\n  \n  # Set theme and appearance\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16),\n    plot.subtitle = element_text(color = \"darkred\", size = 12),\n    axis.title = element_text(size = 12),\n    panel.grid.minor = element_blank()\n  ) +\n  \n  # Set axis limits to focus on the relevant part of the distribution\n  coord_cartesian(xlim = c(150, 230), ylim = c(0, max(height_density) * 1.05))\n```\n\n::: {.cell-output-display}\n![The apparent effect of a marketing campaign!](index_files/figure-html/fig-height-1.png){#fig-height width=672}\n:::\n:::\n\n\nThis example illustrates the fundamental role of probability theory: it establishes baselines against which we can evaluate our observations. In business contexts, this principle applies constantly. Is a 15% increase in sales after a marketing campaign impressive? We can only answer this by comparing it to the typical variation in sales we'd expect to see without any intervention.\n\nProbability theory provides us with mathematical models that describe what we should expect to see if only random variation is at play. These models serve as our null hypothesis - our baseline assumption of \"nothing special happening.\" When our actual observations differ substantially from what these probability models predict, we have evidence that something interesting might be occurring.\n\n> Consider quality control in manufacturing. Suppose your process typically produces 2% defective items. Probability theory can tell you what to expect in a batch of 100 items: most batches will have 1-3 defective items, occasionally you might see 0 or 4-5, and very rarely you might see 6 or more (see @fig-defects). If you test a batch and find 8 defective items, probability theory helps you recognize this as highly unusual - suggesting something may have gone wrong with your process (see @tab-defects).\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"R code to compute expected defects\"}\n# Define parameters\nbatch_size <- 100     # Number of items in a batch\ndefect_rate <- 0.02   # Probability of a defective item (2%)\nobserved_defects <- 8 # Number of defects found in a batch\n\n# Create a table of probabilities for different numbers of defects\ndefect_probs <- tibble(\n  defects = 0:15,  # Range of possible defects to consider\n  \n  # Calculate exact probability for each number of defects\n  exact_prob = dbinom(defects, size = batch_size, prob = defect_rate),\n  \n  # Calculate probability of seeing AT LEAST this many defects\n  cumulative_prob = pbinom(defects - 1, size = batch_size, prob = defect_rate, \n                           lower.tail = FALSE),\n  \n  # Format probabilities as percentages\n  exact_prob_pct = scales::percent(exact_prob, accuracy = 0.001),\n  cumulative_prob_pct = scales::percent(cumulative_prob, accuracy = 0.001),\n  \n  # Calculate the odds (1 in X) for at least this many defects\n  odds = ifelse(cumulative_prob > 0, round(1/cumulative_prob), Inf)\n)\n\n# Table showing key probabilities (first 11 rows)\ndefect_table <- defect_probs %>%\n  filter(defects <= 10) %>%\n  select(defects, exact_prob_pct, cumulative_prob_pct, odds) %>%\n  rename(\n    \"Defects\" = defects,\n    \"Exact Probability\" = exact_prob_pct,\n    \"P(X ≥ Defects)\" = cumulative_prob_pct,\n    \"Odds (1 in X)\" = odds\n  )\n\n# Display the table\nkable(defect_table)\n```\n\n::: {.cell-output-display}\n\n\n| Defects|Exact Probability |P(X ≥ Defects) | Odds (1 in X)|\n|-------:|:-----------------|:--------------|-------------:|\n|       0|13.262%           |100.000%       |             1|\n|       1|27.065%           |86.738%        |             1|\n|       2|27.341%           |59.673%        |             2|\n|       3|18.228%           |32.331%        |             3|\n|       4|9.021%            |14.104%        |             7|\n|       5|3.535%            |5.083%         |            20|\n|       6|1.142%            |1.548%         |            65|\n|       7|0.313%            |0.406%         |           246|\n|       8|0.074%            |0.093%         |          1073|\n|       9|0.015%            |0.019%         |          5282|\n|      10|0.003%            |0.003%         |         29056|\n\n\n\nThe likelihoods of seeing different numbers of defect items.\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"R code for the visualization\"}\n# Create visualization of the probability distribution\nggplot(defect_probs %>% filter(defects <= 15), \n       aes(x = defects, y = cumulative_prob)) +\n  # Add line for cumulative probability\n  geom_line(color = \"darkblue\", size = 1) +\n  \n  # Add points\n  geom_point(color = \"darkblue\", size = 3) +\n  \n  # Highlight the observed value (8 defects)\n  geom_point(data = defect_probs %>% filter(defects == 8), \n             color = \"red\", size = 4) +\n  \n  # Add shading for area of interest (≥ 8 defects)\n  geom_area(data = defect_probs %>% filter(defects >= 8), \n            fill = \"red\", alpha = 0.3) +\n  \n  # Add annotation for probability\n  annotate(\"text\", x = 10, y = 0.1,\n           label = paste0(\"P(X ≥ 8) = \", \n                          defect_probs$cumulative_prob_pct[defect_probs$defects == 8]),\n           color = \"darkred\") +\n  \n  # Add titles and labels\n  labs(\n    title = \"Probability of Finding X or More Defects\",\n    subtitle = paste0(\"Finding 8+ defects when defect rate is 2% happens in only 1 in \", \n                      defect_probs$odds[defect_probs$defects == 8], \" batches\"),\n    x = \"Number of Defective Items (X)\",\n    y = \"Probability of X or More Defects\",\n    caption = \"Based on binomial distribution B(100, 0.02)\"\n  ) +\n  \n  # Customize the appearance\n  theme_minimal() +\n  \n  # Set y-axis as percentage\n  scale_y_continuous(labels = scales::percent_format()) +\n  \n  # Set x-axis to show only whole numbers of defects\n  scale_x_continuous(breaks = 0:15)\n```\n\n::: {.cell-output-display}\n![The likelihoods of seeing different numbers of defect items.](index_files/figure-html/fig-defects-1.png){#fig-defects width=672}\n:::\n:::\n\n\n\n\nThe key insight is that probability theory doesn't require us to know exactly what will happen - it tells us about the range of possibilities and how likely each one is. This framework transforms our question from \"What will happen?\" to \"How unusual is what we observed?\" This shift is fundamental to statistical thinking.\n\nProbability theory also helps us understand that unusual events do occur naturally through random variation. Just as you might occasionally flip a coin and get five heads in a row purely by chance, business processes will sometimes produce unusual results even when operating normally. Probability theory helps us distinguish between these natural anomalies and genuine signals that require attention.\n\n# How Do Probability and Statistics Work Together?\n\nThe relationship between probability and statistics represents one of the most elegant partnerships in scientific thinking. They work together to bridge the gap between theoretical expectations and real-world observations, creating a powerful cycle of reasoning that drives both business decision-making and scientific discovery.\n\nProbability provides the theoretical framework - it tells us what patterns we should expect to see if certain assumptions are true. Statistics then examines real data to see whether these expected patterns actually appear, allowing us to evaluate our assumptions and refine our understanding.\n\n> Think of a retail company testing whether a new store layout increases customer spending. Probability theory might suggest that if the layout truly has no effect, we should expect to see the same average spending as before, with purchases varying randomly around that average. If the new layout does have an effect, we should see a systematic shift in the spending pattern. Statistics then analyzes actual customer data to determine whether the observed spending pattern looks more like the \"no effect\" scenario or the \"positive effect\" scenario. Figure @fig-store shows the two crucial steps: you first use probability theory to construct a reference case, i.e. what you would expect to see of the new layout had no effect. Then you collect data and compare the collected data against the theoretical prediction and use tools from inferential statistics to make a rational conclusion.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"R code for the visualization\"}\n# Set seed for reproducibility\nset.seed(123)\n\n# Define parameters\nold_mean <- 65             # Mean spending with old layout (€)\nold_sd <- 12               # Standard deviation with old layout (€)\nn_customers <- 40          # Sample size for new layout test\n\n# Generate spending range for theoretical distributions\nspending_range <- seq(30, 120, by = 0.5)\n\n# Calculate standard error for the sample mean\nse <- old_sd / sqrt(n_customers)\n\n# Create a data frame for theoretical distributions\ntheory_df <- tibble(\n  spending = spending_range,\n  # Distribution of individual customer spending\n  null_density = dnorm(spending_range, mean = old_mean, sd = old_sd),\n  # Sampling distribution of the mean\n  sampling_density = dnorm(spending_range, mean = old_mean, sd = se)\n)\n\n# Create Panel A: Probability theory perspective\ntheory_plot <- ggplot(theory_df) +\n  # Add the null hypothesis distribution (individual customers)\n  geom_line(aes(x = spending, y = null_density), \n            color = \"darkblue\", size = 1.2) +\n  geom_area(aes(x = spending, y = null_density), \n            fill = \"darkblue\", alpha = 0.2) +\n  \n  # Add the sampling distribution of the mean (what we'd expect if H0 is true)\n  geom_line(aes(x = spending, y = sampling_density), \n            color = \"purple\", size = 1.2, linetype = \"dashed\") +\n  \n  # Add vertical line for baseline (old layout) mean\n  geom_vline(xintercept = old_mean, linetype = \"solid\", color = \"darkblue\") +\n\n  # Add labels and title\n  labs(\n    title = \"Probability Theory Perspective\",\n    subtitle = \"What we would expect to see if the new layout had no effect\",\n    x = \"Customer Spending (EUR)\",\n    y = \"Probability Density\"\n  ) +\n  \n  # Add annotations explaining the distributions\n  annotate(\"text\", x = 40, y = max(theory_df$null_density) * 1.5,\n           label = \"Individual customer\\nspending distribution\\nunder old layout\",\n           color = \"darkblue\", hjust = 0) +\n  annotate(\"text\", x = 75, y = max(theory_df$sampling_density) * 0.7,\n           label = \"Sampling distribution\\nof the mean\\n(if null hypothesis is true)\",\n           color = \"purple\", hjust = 0) +\n  \n  # Customize theme\n  theme_minimal()\n\n# Statistics perspective:\n\n# Create the actual observed data (simulated for this example)\n# We'll assume the new layout has an actual effect of +8€\nactual_effect <- 8\nnew_layout_data <- tibble(\n  spending = rnorm(n_customers, mean = old_mean + actual_effect, sd = old_sd),\n  layout = \"New Layout Test\"\n)\n\n# Calculate observed sample mean from new layout test\nobserved_mean <- mean(new_layout_data$spending)\n\n# Calculate z-score for the observed mean\nz_score <- (observed_mean - old_mean) / se\n\n# Calculate p-value (one-tailed test)\np_value <- pnorm(z_score, lower.tail = FALSE)\n\n# Create Panel B: Statistical analysis of the actual data\ndata_plot <- ggplot() +\n  # Add sampling distribution under null hypothesis\n  geom_line(data = theory_df, aes(x = spending, y = sampling_density), \n            color = \"purple\", size = 1) +\n  geom_area(data = theory_df, aes(x = spending, y = sampling_density), \n            fill = \"purple\", alpha = 0.1) +\n  \n  # Add vertical line for null hypothesis (old layout mean)\n  geom_vline(xintercept = old_mean, linetype = \"solid\", color = \"darkblue\") +\n  annotate(\"text\", x = old_mean - 1, y = max(theory_df$sampling_density) * 0.9, \n           label = \"Old Layout Mean\\n(null hypothesis)\", hjust = 1, color = \"darkblue\") +\n  \n  # Add critical value line\n  geom_vline(xintercept = old_mean + qnorm(0.95) * se, \n             linetype = \"dotted\", color = \"red\") +\n  \n  # Add the observed mean from our new layout test\n  geom_vline(xintercept = observed_mean, linetype = \"dashed\", \n             color = \"forestgreen\", size = 1) +\n  annotate(\"text\", x = observed_mean + 1, y = max(theory_df$sampling_density) * 0.9, \n           label = paste0(\"New Layout\\nObserved Mean: \", round(observed_mean, 1), \"€\"), \n           hjust = 0, color = \"forestgreen\") +\n  \n  # Add individual data points at the bottom for visual context\n  geom_jitter(data = new_layout_data, aes(x = spending, y = 0), \n              height = 0.0005, color = \"forestgreen\", alpha = 0.7) +\n  \n  geom_density(data = new_layout_data, aes(x = spending), \n             color = \"forestgreen\", fill = \"forestgreen\", alpha = 0.2, adjust = 1.5) +\n  \n  # Shade the p-value region\n  geom_area(data = filter(theory_df, spending >= observed_mean), \n            aes(x = spending, y = sampling_density), fill = \"red\", alpha = 0.3) +\n  \n  # Add annotation for p-value\n  annotate(\"text\", x = 100, y = max(theory_df$sampling_density) * 0.7,\n           label = paste0(\"p-value = \", round(p_value, 4), \"\\n\",\n                          \"z-score = \", round(z_score, 2)),\n           color = \"red\", hjust = 0.5) +\n  \n  # Add title and labels\n  labs(\n    title = \"Statistical Analysis of New Layout Test\",\n    subtitle = paste0(\"Evaluating evidence against the null hypothesis\"),\n    x = \"Customer Spending (€)\",\n    y = \"Probability Density\"\n  ) +\n  \n  # Customize theme\n  theme_minimal()\n\n# Combine the plots\nggarrange(\n  theory_plot, data_plot,\n  ncol = 1, nrow = 2,\n  labels = c(\"A\", \"B\"),\n  heights = c(1, 1.2)\n)\n```\n\n::: {.cell-output-display}\n![How to use probability theory and statistics in conjunction.](index_files/figure-html/fig-store-1.png){#fig-store width=960}\n:::\n:::\n\n\n\n\nThis partnership creates several important capabilities. First, it allows us to move beyond simple description to meaningful inference. We don't just observe that sales increased by 15% - we can assess whether this increase is likely due to our intervention or could reasonably be explained by normal business fluctuations.\n\nSecond, the probability-statistics partnership helps us calibrate our confidence in conclusions. When we observe an effect in our data, probability theory helps us calculate how likely we would be to see such an effect if nothing real were happening. This gives us a principled way to decide how much weight to place on our findings.\n\n> For example, if probability calculations show that we'd see a 15% sales increase less than 5% of the time purely by chance, we can be fairly confident that our marketing campaign contributed to the improvement. If such an increase would happen 40% of the time by chance alone, we should be much more cautious about claiming success.\n\nThird, this relationship enables prediction and planning. By understanding both the underlying probability patterns and how to extract information from data, we can make informed projections about future outcomes and assess the reliability of those projections.\n\nThe interplay between probability and statistics also illuminates why statistical reasoning requires both theoretical understanding and practical experience with data. Without probability theory, we might misinterpret random fluctuations as meaningful trends. Without statistical methods for analyzing real data, probability remains purely academic.\n\n# The Role of Uncertainty in Business and Research\n\nUnderstanding uncertainty represents perhaps the most crucial mindset shift for students approaching statistics. In many academic disciplines, we're taught to seek definitive answers - to prove or disprove propositions decisively. Statistics operates differently. Rather than eliminating uncertainty, it teaches us to acknowledge uncertainty as an inherent feature of complex systems and to make rational decisions despite incomplete information.\n\nIn business contexts, uncertainty permeates every decision. Market conditions shift unpredictably, consumer preferences evolve, competitors make unexpected moves, and economic conditions fluctuate. Even within organizations, employee performance varies, operational processes contain natural variation, and strategic outcomes depend on countless unpredictable factors.\n\n> Consider a product manager deciding how many units to manufacture for the upcoming holiday season. They might estimate demand at 10,000 units based on historical data and market research. However, actual demand could easily range from 7,000 to 13,000 units depending on economic conditions, competitor actions, weather, and countless other factors. Statistics doesn't eliminate this uncertainty, but it helps the manager understand the range of possibilities and make informed decisions about production levels, inventory management, and risk mitigation.\n\nStatistics teaches us that uncertainty isn't a flaw in our analysis - it's a fundamental characteristic of the world we must incorporate into our decision-making processes. This represents a mature, sophisticated approach to management and research. Instead of pretending we can predict everything precisely, we learn to work productively within uncertainty.\n\nThis perspective affects how we interpret findings and draw conclusions. When research suggests that a new management technique improves productivity, we don't just want to know the average improvement - we want to understand the range of outcomes we might reasonably expect and the factors that influence this variation.\n\n> A training program might show an average productivity increase of 12%, but this could mean that most employees see improvements between 8-16%, while a few see dramatic gains and others see little change. Understanding this variability helps managers set realistic expectations and tailor implementation strategies.\n\nEmbracing uncertainty also cultivates intellectual humility. Statistical thinking encourages us to be appropriately cautious about our conclusions, to acknowledge the limitations of our data and methods, and to update our beliefs when presented with new evidence. In a business world that often rewards confident assertions and decisive action, this nuanced approach can initially feel uncomfortable but ultimately leads to more robust strategies and better long-term outcomes.\n\nThis mindset connects statistics to critical thinking more broadly. Just as statistics teaches us to distinguish between correlation and causation, to recognize the limitations of small samples, and to account for various sources of bias, it cultivates careful, evidence-based reasoning that extends far beyond purely quantitative contexts.\n\n# Conclusion: Building Statistical Intuition\n\nAs we conclude this foundational overview, it's worth reflecting on what we're really trying to accomplish in developing statistical understanding. We're not just learning tools and techniques - we're cultivating a way of thinking about evidence, uncertainty, and decision-making that will serve you throughout your careers in management and research.\n\nStatistical thinking involves several key habits of mind. It means being curious about data and asking probing questions about what patterns might mean and what factors might explain them. It means being appropriately skeptical of simple explanations for complex phenomena while remaining open to evidence. Most importantly, it means being comfortable making decisions under uncertainty while acknowledging the limits of our knowledge.\n\n> Think of statistical reasoning as developing a new form of professional judgment. Just as an experienced manager learns to read market signals, assess team dynamics, and anticipate potential problems, statistical thinking provides systematic methods for evaluating evidence and making informed decisions when complete information isn't available.\n\nAs you progress through this course, remember that developing statistical intuition is a gradual process. The concepts we've introduced here - the need for reference points to interpret data, the partnership between probability and statistics, the reality of uncertainty in business decisions - will become more concrete and intuitive as you work with real data and tackle practical problems.\n\nThe investment in developing this statistical mindset will pay dividends far beyond any single course or project. In an increasingly data-rich business environment, the ability to think clearly about uncertainty, extract meaningful insights from complex information, and communicate these insights effectively has become an essential management skill.\n\nYour journey into statistical thinking begins with recognizing that uncertainty is not the enemy of good decision-making - it's simply the context within which all important decisions must be made. Statistics provides the tools and frameworks to make those decisions as wisely as possible, given the information available. This is both the challenge and the power of statistical reasoning: finding clarity and direction amid the inherent uncertainty of business and research endeavors.\n\n# Next steps\n- [Back to the recap overview](content/statrecap.qmd)\n- [Next topic: Data fundamentals](content/statrecap/DataFundamentals.qmd)\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}