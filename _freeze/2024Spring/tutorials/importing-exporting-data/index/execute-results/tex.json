{
  "hash": "e069ef34af96100010e96c1df2a2536f",
  "result": {
    "markdown": "---\ntitle: \"Importing and exporting data\" # Also check out line 43\nauthor: Claudius Gräbner-Radkowitsch\ndate: '2023-03-09'\ndocumentclass: scrartcl\nformat: \n  html:\n    theme: readable\n    highlight: tango\n    toc: true\n    toc_depth: 2\n    number_sections: true\n  pdf:\n    papersize: a4\n    toc: true\n    toc-depth: 2\n    number-sections: true\n    include-in-header: \n      text: |\n        \\usepackage{lmodern} \n        \\usepackage{graphicx}\n        \\usepackage{hyperref}\n        \\usepackage{url}                \n        \\usepackage{xcolor}\n        \\usepackage{booktabs}\n        \\usepackage{listings}\n        \\lstloadlanguages{R}\n        \n        \\definecolor{eufblue}{RGB}{0,57,91}\n        \\definecolor{eufgrey}{RGB}{111,111,111}\n        \\definecolor{euflightblue}{RGB}{105,170,205}\n        \n        \\hypersetup{\n        pdfauthor={Claudius Graebner-Radkowitsch}\n        colorlinks=true,\n        linkcolor=euflightblue,\n        urlcolor=euflightblue\n        }\n        \\usepackage[includehead,includefoot,top=2cm, bottom=1.5cm]{geometry}\n        \\usepackage[headsepline, footsepline]{scrlayer-scrpage}\n        \\pagestyle{scrheadings}\n        \\clearpairofpagestyles\n        \\ihead{Tutorial: Importing and exporting data}\n        %\\chead{Kopfzeile Mitte}\n        \\ohead{\\pagemark} %\n        \\ifoot{}\n        \\cfoot{\\href{https://euf-datascience-spring24.netlify.app/}{\\normalfont\\color{eufblue}{Data Science Using R - Spring Semester 2024}}} % Fußzeile Mitte\n        \\ofoot{} \n        \\setkomafont{disposition}{\\color{eufblue}\\bfseries}\n---\n\n\n\n\n\n**Packages used in this tutorial:**\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(here)\nlibrary(data.table)\nlibrary(dplyr)\n```\n:::\n\n\n\n# Introduction\n\nFunctions that are used to import data take as an argument a path to a file\ncontaining data, parse this file, and return an R object (usually a kind of\n`data.frame`) that contains the data from the file.\n\nIn general, there are different file formats for storing data, but the most widely\nused one is the `.csv`-format - an abbreviation for 'comma separated values',\nindicating that (usually) data points are separated from each other via \ncommas. The big advantage of such files is that they are platform-independent\nand do not require any external software. Their downside is that you they are\nrelatively large for a given amount of data, and that they are inferior to more\nmodern file formats when it comes to reading and writing speed. But these \ndisadvantages become relevant only for larger data sets, which is why `csv` \nfiles are a good default option to use, and this tutorial focuses on reading\nand writing `csv`-files (with a short overview over most common alternatives\nbelow).\n\nWhile writing (or 'exporting') data is usually straightforward, reading \n(or 'importing') data can be very frustrating and complicated. The reason is\nthat there are many different ways of how exactly data is stored within a \n`csv`-file. But don't worry: first, the package\n[data.table](https://github.com/Rdatatable/data.table) provides for the \namazing function `data.table::fread()` that allows you to account for basically\nevery specifity of the `csv`-files you will encounter. Second, with only a \nhandful of arguments passed to `data.table::fread()` you can already cover the\nvast majority of practically relevant cases.\n\nThe main focus of this tutorial, thus, is to introduce you to the most important \narguments of `data.table::fread()`. After this, we also make a few remarks on \nhow to save data and how to import/export data using different file formats.\nNote that while the arguments of `data.table::fread()` that will be covered are\nthe most important ones that allow you to deal with most practically relevant\ncases, the function allows for an even greater level of customization. You can\nfind more information via `help(fread)`, but it will be much easier to understand\nthe function manual after going through the base cases described below.\n\nA final remark: if you read about data import in, e.g., textbooks that usually\nrely on the [tidyverse](https://www.tidyverse.org/)\npackages, you will not find any mentioning of `data.table::fread()`. \nRather, the functions provided by the package [readr](https://readr.tidyverse.org/)\nwill be used. This is one of the very few exceptions where I recommend you to\nbreak the rule of writing code in a consistent dialect: while the `readr`-functions\nwould be more consistent with our commitment to the tidyverse, the function\n`data.table::fread()` is just too much better than these alternatives to be\nignored: not only is it *much, much* faster, it also allows for more customization.\nThe only 'drawback' is that after reading in data it returns this data as a\n`data.table` (or a `data.frame`, see below). But this is only a small cost \ncompared to the many benefits. We just should not forget to transform the\nobject returned by `data.table::fread()` into a `tibble`.\n\n# Importing csv data usind fread\n\nIn the following we assume that our R project is set up correctly, as described\nin the corresponding [tutorial](/tutorial/setting-up-an-r-project/), and that\nthe data set we would like to import is called `exp_data.csv` and stored in the\nsubdirectory `data/tidy/exp_data.csv`:\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](dir_structure.pdf){fig-align='center'}\n:::\n:::\n\n\n\nIn the following we assume we work in the file `importing.R`, the first lines\nof which should contain\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhere::i_am(\"R/importing.R\")\nlibrary(here)\nlibrary(data.table)\n```\n:::\n\n\n\nIf the data file is not too large it is a good idea to inspect the raw file\nusing the R-Studio file preview\n(for larger files it is usually better to open the file using a text editor,\nsuch as Emacs or TextEdit):\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](ViewFile.png){fig-align='center' width=60%}\n:::\n:::\n\n\n\nThis way you get almost all relevant information about how the file looks like \nand what kind of arguments you must use when calling `data.table::fread()`.\nIn the present example case, the file looks like this:\n\n```\niso2c,year,exports\nAT,2012,53.97\nAT,2013,53.44\nAT,2014,53.38\n```\n\nThis is a very standard `csv`-file: we see that there are three columns, \nall of them separated with a comma. Moreover, the third row contains decimal\nnumbers where the decimal sign is a dot. This is the standard case, and it\naligns well with all the default values for the optional arguments of \n`data.table::fread()`. Thus, we only need to specify the single mandatory\nargument of this function. It is called `file`^[You can also specify \nalternative arguments, such as `cmd` when you want to parse the input\nfile using a command line command. But we will not cover such more \nadvanced cases here.] and should be the relative path to the file. In our\ncase:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfile_path <- here::here(\"data/tidy/exp_data.csv\")\nexp_data <- data.table::fread(file = file_path)\nexp_data <- tibble::as_tibble(exp_data)\nexp_data\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 3\n  iso2c  year exports\n  <chr> <int>   <dbl>\n1 AT     2012    54.0\n2 AT     2013    53.4\n3 AT     2014    53.4\n```\n:::\n:::\n\n\n\nAs we can see the default options of `data.table::fread()` did an excellent\njob and we now have an R object that we could use immediately for further\nanalysis (e.g., to build visualizations as described in one of the previous\ntutorials). In many cases, however, we need to use some of the optional \narguments of `data.table::fread()` to get the desired result. In the following,\nwe will go through the most commonly used arguments. These are:\n\n* `sep`: symbol that separates columns\n* `dec`: symbol used as decimal sign\n* `colClasses`: set the object type of the columns\n* `select` and `drop`: specify columns that should (not) be read\n* `nrows` and `skip`: specify how many rows should be read /skipped from the top of the file\n* `header`: specify whether there is a header with variable names\n\n## Specify the column separator using `sep` and the decimal sign using `dec`\n\nWhile the example file above represents the widespread standard case in which\ncolumns are separated by a comma and the dot is used as the decimal sign, many \nfiles use other symbols. In Germany, for instance, it is very common to use\n`;` as a separator for columns, and `,` as a decimal sign instead.\nThus, the 'German version' of our example from above would look like this:\n\n```\niso2c;year;Exporte\nAT;2012;53,97\nAT;2013;53,44\nAT;2014;53,38\n```\n\nSometimes, `data.table::fread()` detects such cases automatically and adjusts\nthe values for the optional arguments implicitly. \nBut it is always better to explicit and to specify decimal signs and\ncolumn separators explicitly! This also increases the reading speed of\n`data.table::fread()`. \nTo set them explicitly, we use the arguments `sep` and `dec` as follows:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nexp_data <- data.table::fread(\n  file = file_path,\n  sep = \";\", \n  dec = \",\"\n  )\n```\n:::\n\n\n\nAfter completing the function call we should always inspect the imported object \nto make sure everything went well. We might have a look at the first lines:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nexp_data <- tibble::as_tibble(exp_data)\nhead(exp_data, n = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 3\n  iso2c  year exports\n  <chr> <int>   <dbl>\n1 AT     2012    54.0\n2 AT     2013    53.4\n```\n:::\n:::\n\n\n\n\nOr use `dplyr::glimpse()` or `str()`:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstr(exp_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntibble [3 x 3] (S3: tbl_df/tbl/data.frame)\n $ iso2c  : chr [1:3] \"AT\" \"AT\" \"AT\"\n $ year   : int [1:3] 2012 2013 2014\n $ exports: num [1:3] 54 53.4 53.4\n - attr(*, \".internal.selfref\")=<externalptr> \n```\n:::\n:::\n\n\n\n## Set the object type of the columns using `colClasses`\n\nUsually, the automatic type recognition of `data.table::fread()` works quite \nwell. This means that R chooses the right data type for each column \nautomatically.\nSometimes, however, this detection fails and you need to specify the column\ntypes manually. But even if the automatic recognition works, there are some\ngood reasons for playing save and specify the column types yourself: \n\n1. You will notice more easily if there is a problem with a column,\ne.g. if a word occurs in a column that consists exclusively of numbers. \noccurs. If you did not specify this column manually as `double`, \n`data.table::fread()` would simply interpret it silently as a `character` \nand you would later wonder later why you cannot calculate an average for the column;\n2. Your code will be more transparent and easier to read if one immediately \nknows what kind of data you are importing\n3. The import process will be *much* faster if you provide the column types \nyourself and the function does not need to guess the types itself.\n\nOne situation where specifying column types yourself is extremely important \nis when a column contains numerical codes that might contain a leading zero, \ne.g. when the data contain [HS product codes](), such as here:\n\n```\ncommoditycode,complexity\n0101,0.06\n0102,-0.49\n0103,0.51\n0104,-1.12\n0105,-0.17\n```\n\nAssuming the file is called `exp_data_hs.csv` and also is stored in \n`data/tidy/`, we might try to import it using the default argument values:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfile_path <- here::here(\"data/tidy/exp_data_hs.csv\")\nexp_prod_data <- data.table::fread(file = file_path)\nexp_prod_data <- tibble::as_tibble(exp_prod_data)\nexp_prod_data\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 2\n  commoditycode complexity\n          <int>      <dbl>\n1           101       0.06\n2           102      -0.49\n3           103       0.51\n4           104      -1.12\n5           105      -0.17\n```\n:::\n:::\n\n\n\nAs you can see, `data.table::fread()` interpreted the column\n`commoditycode` as `double`. But since numbers do not have leading zeros, these are\nremoved *silently*, meaning that `R` does not issue a warning message. This is\ndangerous and might come with serious misinterpretations later on. To avoid \nthis, you must choose the column types yourself via the `colClasses` argument, \nby simply specifying a vector with the data types:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfile_path <- here::here(\"data/tidy/exp_data_hs.csv\")\nexp_prod_data <- data.table::fread(\n  file = daten_pfad, colClasses = c(\"character\", \"double\")\n  )\ntibble::as_tibble(exp_prod_data)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 2\n  commoditycode complexity\n  <chr>              <dbl>\n1 0101                0.06\n2 0102               -0.49\n3 0103                0.51\n4 0104               -1.12\n5 0105               -0.17\n```\n:::\n:::\n\n\n\nAs you can see, encoding the column `commoditycode` as `character` preserves the \nleading zeros and the correct product codes.\n\nFor data sets with many columns it is often tedious to specify column types \none by one. Here it might be useful to use the function\n`rep()`: it saves space if, for instance, 6 subsequent columns are all of \ntype `double`. In this case you may just write `rep(\"double\" , 6)`.\n\n## Specify how many rows should be read/skipped using `nrows` and `skip`\n\nKeep in mind that you can increase the reading speed of `data.table::fread()` \n*considerably* by manually specifying the columns types. At the same time, \nopening very large data files in R Studio or even a text editor can slow down\nyour computer considerably. \n\nThus, it is advisable to read in the first 3-5 rows,\ninspect them, and then read in the whole data set with the right specification\nfor `colClasses`. \n\nYou can load only the first $n$ rows by using the argument `nrows`:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nexp_data <- tibble::as_tibble(data.table::fread(\n  file = here::here(\"data/tidy/exp_data.csv\"), \n  nrows = 1)\n  )\nexp_data\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 3\n  iso2c  year exports\n  <chr> <int>   <dbl>\n1 AT     2012    54.0\n```\n:::\n:::\n\n\n\nIn other instances, you might also want to *skip* the first $n$ rows. This \nis often the case if your file contains some general introductory header, which\nis placed before the actual data set. Such data with a header might look like \nthis:\n\n```\nThis is awesome data from 2012-2014\nIt was compiled be Claudius\nHe also added this useless header\niso2c,year,Exporte\nAT,2012,53.97\nAT,2013,53.44\nAT,2014,53.38\n\n```\n\nIn this case, you definitely want to ignore the first three rows when importing\nthe data set. Otherwise you will get hodgepodge:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nexp_data <- data.table::fread(\n  file = here::here(\"data/tidy/exp_data_header.csv\")\n  )\ntibble::as_tibble(exp_data)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 6\n  V1    It    was   compiled be      Claudius\n  <chr> <chr> <chr> <chr>    <chr>   <chr>   \n1 He    also  added this     useless header  \n```\n:::\n:::\n\n\n\nTo ignore the first three rows just set `skip` to `3`:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nexp_data <- tibble::as_tibble(data.table::fread(\n  file = here::here(\"data/tidy/exp_data_header.csv\"), \n  skip = 3)\n  )\nexp_data\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 3\n  iso2c  year Exporte\n  <chr> <int>   <dbl>\n1 AT     2012    54.0\n2 AT     2013    53.4\n3 AT     2014    53.4\n```\n:::\n:::\n\n\n\n\n\nAgain, the automatic detection of `fread()` often works quite well when it \ncomes to the identification of useless headers, but better be prepared to use\n`skip` whenever necessary.\n\n## Specify columns that should (not) be read using `select` and `drop`\n\nSometimes you only want to read in a certain selection of columns.\nThis can also save a lot of time when working with large data sets.\nIn the following example we only want to import the columns `year` and \n`exports`:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nexp_data <- data.table::fread(\n  file = here::here(\"data/tidy/exp_data.csv\")\n  nrows = 1, \n  select = c(\"year\", \"Exporte\")\n  )\nexp_data <- tibble::as_tibble(exp_data)\nexp_data\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 2\n   year exports\n  <int>   <dbl>\n1  2012    54.0\n2  2013    53.4\n```\n:::\n:::\n\n\n\nIf you want to manually specify column types, you can do so without using\n`colClasses` by passing a named vector to `select`:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nexp_data <- data.table::fread(\n  file = here::here(\"data/tidy/exp_data.csv\")\n  nrows = 1, \n  select = c(\"year\"=\"double\", \"exports\"=\"double\")\n  )\nexp_data <- tibble::as_tibble(exp_data)\nexp_data\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 2\n   year exports\n  <dbl>   <dbl>\n1  2012    54.0\n2  2013    53.4\n```\n:::\n:::\n\n\nAlternatively, we can also specify columns to be ignored via `drop`:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nexp_data <- data.table::fread(\n  file = here::here(\"data/tidy/exp_data.csv\")\n  nrows = 1, \n  drop = \"iso2c\"\n  )\nexp_data <- tibble::as_tibble(exp_data)\nexp_data\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 2\n   year exports\n  <int>   <dbl>\n1  2012    54.0\n2  2013    53.4\n```\n:::\n:::\n\n\n\n# Importing data from other file formats\n\nEven though `csv`-files are the most widely used data,\nthere are of course many other formats you will encounter.\nHere I would like to give examples of three other formats \n(`.rds`, `.rdata` and `.dta`).\n\nFirst, `R` has two 'in-house' formats that while being extremely well suited \nfor storing larger data, can only be opened via `R`. \nThese files have the ending `.rds`/`.Rds`, `.RData`, or `.Rda` \n(where `.Rda` is just an abbreviation for `.RData`).\n\nGenerally, `.Rds` store individual R-objects, such as single\natomic vectors, `list`s, or `data.frame`s.\nSuch files can be read with the function `readRDS()`, which takes a single \nargument - the name of the `.Rds`-file - and returns the object stored in the\nfile:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata_set <- readRDS(file = here::here(\"data/tidy/exp_data.Rds\"))\n```\n:::\n\n\n\nBy contrast, `.RData`-files can contain more than one objects. \nMoreover, the corresponding import function `load()` does not return an \nobject to which you can assign a name. \nInstead, the objects retain the name with which they were originally saved and \nare available immediately after calling `load()`: In the following example,\nimport two objects called `test_dat` and `test_vec`:\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nload(here::here(\"data/tidy/test_daten.RData\"))\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntest_dat\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  a b\n1 1 3\n2 2 4\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntest_vec\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Test vector\"\n```\n:::\n:::\n\n\n\nThe use of `.RData` is particularly useful whenever you want to store several \nobjects and if some of these objects are not data sets, \nfor which other formats would be readily available.\n\nA format often used in economics is the native format of the commercial software \n[STATA](https://de.wikipedia.org/wiki/Stata).\nThese file end with `.dta`.\nTo read files in this format you may use the function\n`read_dta()` from the package [haven](https://github.com/tidyverse/haven), \nwhich accepts the filename via the argument `file`:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndta_file <- here::here(\"data/tidy/exp_data.dta\")\ndta_data <- haven::read_dta(file = dta_file)\n```\n:::\n\n\n\nThe package [haven](https://github.com/tidyverse/haven) actually provides a \nnumber of other functions that allow you to read (and write) in a number of \ndata formats used by commercial software packages such as SAS or SPSS.\n\n# Exporting data\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\nCompared to reading in data, saving it is much easier, because\nthe data is already in a reasonable format. \nSo the only real question is: in which file format should you save your data? \n\nIn the vast majority of cases, this question can comfortably be answered with \n`csv.`\nThis format is easy to read and fully platform compatible.\nIt also does not have the worst properties in terms of reading and writing \nspeed, especially if you compress the data later on.\n\nThe fastest and, in my opinion, by far the best function for writing\n`csv`.files is the function `fwrite()` from the package `data.table` -\nthink of it as the sister to `data.table::fread()`.\n\nTo illustrate how to use it, suppose we have a data set `test_data` that we \nwant to store in the directory subfolder `data/tidy` as `test_data.csv`.\nThis is easily done with `data.table::fwrite()`:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfile_name <- here::here(\"data/tidy/test_data.csv\")\ndata.table::fwrite(x = test_data, file = file_name)\n```\n:::\n\n\n\nIn addition to the object to be written as the first argument (`x`), you also \nneed to specify the argument `file`, which determines the name and path of the \nfile to be written. \n`data.table::fwrite()` accepts some more optional arguments, but in most cases \nyou will not need them. \nIf you are interested, just have a look at the help function!\n\n\nThe R-specific formats `.Rdata` and `.Rds` have \nspeed and compression advantages over the `csv` format, and remain fully \nplatform-compatible.\nTheir biggest drawback, however, is that they can only be used by other R-users.\nThus, before using them you should make sure that all potential users of your\ndata also use `R`. In this case you can save a single object in an `.Rds`-file\nby using the function `saveRDS()` with the arguments `object` and `file`:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsaveRDS(\n  object = test_data,  \n  file = here::here(\"data/tidy/test_data.Rds\"))\n```\n:::\n\n\n\nIn addition, you may use the optional argument `compress` to select the \ncompression type: `gz` is the fastest, `bz` the strongest, and `xz` represents\nthe middle ground.\n\nIf you want to save several objects at once you can do this using the \nformat `.RData`.\nThe corresponding function is `save()`.\nAlthough you can simply pass all the objects you want to save as the first \narguments to the function, it is more transparent to do this via the `list` \nargument.\nThe following code stores the two objects `test_data` and `data` in the\nfile `\"data/tidy/datacollection.Rdata\"`:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsave(\n  list=c(\"test_data\", \"daten\"), \n  file=here::here(\"data/tidy/datensammlung.RData\")\n  )\n```\n:::\n\n\n\nLike `saveRDS()`, `save()` allows you to select the compression algorithm via \nthe `compress` argument. Moreover, you may control the compression level \nvia the optional argument `compression_level`. Possible values range\nfrom `1` (fast, but little compression) to `9` (slow, but strong compression). \n\nThe final format considered is the\n[STATA](https://de.wikipedia.org/wiki/Stata)-specific format `.dta`.\nTo store data in this format you may use the function `write_dta()`\nfrom the package [haven](https://github.com/tidyverse/haven):\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhaven::write_dta(\n  data = test_data, \n  path = here::here(\"data/tidy/test_data.dta\")\n  )\n```\n:::\n\n\n\nFor `SAS` and `SPSS` formats similar functions are also provided by the\n[haven](https://github.com/tidyverse/haven) package.\n\n> **Note:** Especially with large data sets, the read and write speed of functions \nis very important. \nThe question of the best file format becomes much more relevant in these cases,\nif compared with the cases of small data sets, where the question of format \nmainly revolves around the issue of 'compatibility'. \nSome nice articles comparing different functions and formats with regard to \ntheir speed can be found, e.g., \n[here](https://csgillespie.github.io/efficientR/efficient-inputoutput.html) or  \n[here](https://data.nozav.org/tutorial/2019-r-data-frame-benchmark/).\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}