[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Theoretical and Empirical Research Methodology",
    "section": "",
    "text": "üìë The course in brief\nFocus: This course is part of the module Theoretical and Empirical Research Methodology. It complements the theoretical lectures by introducing you to the statistical programming language R and acquire practical knowledge about how to implement essential research tools and all theoretical concepts discussed during the main lecture in R.\nHow: The course comprises a mixture of (i) lectures, in which I introduce concepts in the classroom, (ii) automated hands-on exercises for you to do at home on your own and (iii) flipped-classroom elements where you watch videos at home and we practice the content together in class.\nPrerequisites: The course does not require you to have any prior knowledge in R or any other programming language. Depending on your prior knowledge or affinity to programming, the course will be quite demanding, but equip you with computational skills that are most valuable both within academia and the business world.\n\n\nüéØ Learning Objectives\n\nUse R together with the integrated development environment R Studio\nUnderstand the use of R packages to perform specific data analytic tasks\nWrite reproducible data analysis reports using Quarto\nTransform raw data into tidy data, which is suitable for further analysis\nChoose and justify the correct visualization approach, and create appealing visualizations using the R package ggplot2\nImplement and interpret linear regression models with numerical and categorial variables\n\n\n The main course on moodle"
  },
  {
    "objectID": "2024Spring/exercises.html",
    "href": "2024Spring/exercises.html",
    "title": "Additional exercises",
    "section": "",
    "text": "Here are some additional exercises, on top of those provided by the exercise package.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Session date - Oldest\n        \n         \n          Session date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nSession date\n\n\nTitle\n\n\n\n\n\n\nMarch 28, 2024\n\n\nBasic object types: exercises\n\n\n\n\nMay 16, 2024\n\n\nQuarto exercises\n\n\n\n\nJune 7, 2024\n\n\nExercises on multiple linear regression\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "2024Spring/index.html",
    "href": "2024Spring/index.html",
    "title": "Data Science using R",
    "section": "",
    "text": "üìç Lecture\nThursdays 14:15-15:45 in MAD 131 & Fridays 12:15-13:45 in MAD 225\nPlease make sure to check out the most recent version of the seminar timetable since lecture dates might differ from one week to another. The most recent version can be found here.\n\n\nüíª Exercises\nThere is an R package with interactive exercises for this course. I strongly recommend to do the exercises for each session since regular practice is the most important determinant in your success in learning R. You find more information on how to use the exercises in this tutorial. On top of that, there are some additional exercises on selected topics here.\n\n\nüìÇ Material\nYou find an overview about all lecture materials, such as slides and reading lists here. Complete material lists for the single sessions are distributed via the respective session pages. Lecture videos can, so far, only be accessed via Moodle. EUF students can register for the Moodle course 13895 using the password DataScience24.\n\n\nüìñ Tutorials\nComplementary to the lectures there are also short tutorials, which explain certain concepts in a more detailed and applied manner. You can find an overview over all tutorials here.\n\n\nüíå Contact and discussion\nFor asking questions and starting discussions, please use the forum in Moodle."
  },
  {
    "objectID": "2024Spring/tutorials.html",
    "href": "2024Spring/tutorials.html",
    "title": "Tutorials",
    "section": "",
    "text": "Here are tutorials, meant to complement the course.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Session date - Oldest\n        \n         \n          Session date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nSession date\n\n\nTitle\n\n\n\n\n\n\nMarch 14, 2024\n\n\nInstallation of the necessary software\n\n\n\n\nMarch 14, 2024\n\n\nInstalling R packages\n\n\n\n\nMarch 14, 2024\n\n\nUsing the exercise package\n\n\n\n\nMarch 21, 2024\n\n\nFirst steps in R\n\n\n\n\nMarch 28, 2024\n\n\nFundamental object types in R I: Functions\n\n\n\n\nMarch 28, 2024\n\n\nFundamental object types in R II: Vectors\n\n\n\n\nApril 11, 2024\n\n\nFundamental object types in R III: Factors and data frames\n\n\n\n\nApril 19, 2024\n\n\nVisualization\n\n\n\n\nApril 25, 2024\n\n\nImporting and exporting data\n\n\n\n\nApril 25, 2024\n\n\nSetting up an R project\n\n\n\n\nApril 26, 2024\n\n\nData preparation\n\n\n\n\nMay 31, 2024\n\n\nMonte Carlo Simulations in R\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "2024Spring/material/index.html",
    "href": "2024Spring/material/index.html",
    "title": "Material overview",
    "section": "",
    "text": "The following textbooks offer a good general reference to the course content, and I think its a good idea to read into these books in a general way. Moreover, I often point to chapters in the respective session pages.\n\nWickham, H., √áetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science: Import, tidy, transform, visualize, and model data (2nd edition). O‚ÄôReilly. https://r4ds.hadley.nz/\nIsmay, C., & Kim, A. Y.-S. (2020). Statistical inference via data science: A ModernDive, into R and the tidyverse. CRC Press, Taylor and Francis Group. https://moderndive.com/index.html\n\nFor more advanced details on the fundamentals of programming in R, I recommend the following:\n\nWickham, H. (2019). Advanced R (Second edition). CRC Press/Taylor & Francis Group. https://adv-r.hadley.nz/\n\nFor the model-related parts of the lecture I recommend the following book as a further reading reference:\n\nJames, G., Witten, D., Hastie, T., & Tibshirani, R. (2021). An introduction to statistical learning: With applications in R (Second edition). Springer. https://www.statlearning.com/"
  },
  {
    "objectID": "2024Spring/material/index.html#general-references",
    "href": "2024Spring/material/index.html#general-references",
    "title": "Material overview",
    "section": "",
    "text": "The following textbooks offer a good general reference to the course content, and I think its a good idea to read into these books in a general way. Moreover, I often point to chapters in the respective session pages.\n\nWickham, H., √áetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science: Import, tidy, transform, visualize, and model data (2nd edition). O‚ÄôReilly. https://r4ds.hadley.nz/\nIsmay, C., & Kim, A. Y.-S. (2020). Statistical inference via data science: A ModernDive, into R and the tidyverse. CRC Press, Taylor and Francis Group. https://moderndive.com/index.html\n\nFor more advanced details on the fundamentals of programming in R, I recommend the following:\n\nWickham, H. (2019). Advanced R (Second edition). CRC Press/Taylor & Francis Group. https://adv-r.hadley.nz/\n\nFor the model-related parts of the lecture I recommend the following book as a further reading reference:\n\nJames, G., Witten, D., Hastie, T., & Tibshirani, R. (2021). An introduction to statistical learning: With applications in R (Second edition). Springer. https://www.statlearning.com/"
  },
  {
    "objectID": "2024Spring/material/index.html#session-specific-material",
    "href": "2024Spring/material/index.html#session-specific-material",
    "title": "Material overview",
    "section": "üîñ Session-specific material",
    "text": "üîñ Session-specific material\n\n\n\n\n\n\nHow to use the exercise codes?\n\n\n\n\n\nFor information on how to use the exercise code, read this tutorial.\n\n\n\n\n\n\nSession\nTopic\nSlides\nExercise code\n\n\n\n\n1\nGeneral introduction\nSlides\n\n\n\n2\nBasics of R and R-Studio\nSlides\nBasics, Functions\n\n\n3\nBasic objects\nSlides\nObjectTypes1\n\n\n4\nAdvanced objects\nSlides\nObjectTypes2\n\n\n5\nRecap & practice\n\n\n\n\n6\nVisualization\nSlides\nVisualization1\n\n\n7\nProject management and data import\nSlides\nProjectOrga\n\n\n8 & 9\nData wrangling\nSlides\nWrangling1, Wrangling2\n\n\n10\nExploratory data analysis (recap)\nSlides\n\n\n\n11\nQuarto/R Markdown\nSlides\nQuarto\n\n\n12\nRecap & practice\nNA\n\n\n\n13\nIntroduction to data analysis\nSlides\n\n\n\n14\nSampling\nSlides\nSampling\n\n\n15\nSimple linear Regression\nSlides\nLinearRegression1\n\n\n16\nMultiple linear Regression\nSlides\nLinearRegression2"
  },
  {
    "objectID": "2024Spring/material/session01.html",
    "href": "2024Spring/material/session01.html",
    "title": "üóìÔ∏è Session 01 - Introduction, overview and installation",
    "section": "",
    "text": "In this first week, we will cover what you can expect to learn from this course and the course logistics: all you need to know about the structure of the lectures, exercises, and assessments, what will be expected of you, what you will learn and what has helped previous participants in excelling in this course. Finally, we are installing all the programs and packages we need in this course."
  },
  {
    "objectID": "2024Spring/material/session01.html#lecture-slides",
    "href": "2024Spring/material/session01.html#lecture-slides",
    "title": "üóìÔ∏è Session 01 - Introduction, overview and installation",
    "section": "üë®‚Äçüè´ Lecture Slides",
    "text": "üë®‚Äçüè´ Lecture Slides\nEither click on the slide area below or click here to download the slides."
  },
  {
    "objectID": "2024Spring/material/session01.html#accompanying-lecture-videos",
    "href": "2024Spring/material/session01.html#accompanying-lecture-videos",
    "title": "üóìÔ∏è Session 01 - Introduction, overview and installation",
    "section": "üé• Accompanying lecture videos",
    "text": "üé• Accompanying lecture videos\nAll the videos are available via this playlist.\n\n\n\n\n\n\nExpand to access the videos directly"
  },
  {
    "objectID": "2024Spring/material/session01.html#mandatory-reading",
    "href": "2024Spring/material/session01.html#mandatory-reading",
    "title": "üóìÔ∏è Session 01 - Introduction, overview and installation",
    "section": "üìö Mandatory Reading",
    "text": "üìö Mandatory Reading\nRead the following tutorials:\n\nInstallation of the necessary software\nInstalling R packages\nUsing the exercise package"
  },
  {
    "objectID": "2024Spring/material/session01.html#coursework",
    "href": "2024Spring/material/session01.html#coursework",
    "title": "üóìÔ∏è Session 01 - Introduction, overview and installation",
    "section": "‚úçÔ∏è Coursework",
    "text": "‚úçÔ∏è Coursework\n\nMake sure you installed R, R-Studio, Git and all the required R packages\nIf you have questions or problems, please post them in the Moodle forum"
  },
  {
    "objectID": "2024Spring/material/session02.html",
    "href": "2024Spring/material/session02.html",
    "title": "üóìÔ∏è Session 2: First steps in R",
    "section": "",
    "text": "In this session, you will learn about how to use the integrated development environment R-Studio to edit and execute R script and about the basic commands in R. Moreover, you will be introduced to two fundamental concepts: assignments and functions."
  },
  {
    "objectID": "2024Spring/material/session02.html#lecture-slides",
    "href": "2024Spring/material/session02.html#lecture-slides",
    "title": "üóìÔ∏è Session 2: First steps in R",
    "section": "üë®‚Äçüè´ Lecture Slides",
    "text": "üë®‚Äçüè´ Lecture Slides\nEither click on the slide area below or click here to download the slides.\n\n  \n\n\n\n\n\n\n\nThe R script of this session"
  },
  {
    "objectID": "2024Spring/material/session02.html#accompanying-lecture-videos",
    "href": "2024Spring/material/session02.html#accompanying-lecture-videos",
    "title": "üóìÔ∏è Session 2: First steps in R",
    "section": "üé• Accompanying lecture videos",
    "text": "üé• Accompanying lecture videos\nAll the videos are available via this playlist.\n\n\n\n\n\n\nExpand to access the videos directly"
  },
  {
    "objectID": "2024Spring/material/session02.html#mandatory-reading",
    "href": "2024Spring/material/session02.html#mandatory-reading",
    "title": "üóìÔ∏è Session 2: First steps in R",
    "section": "üìö Mandatory Reading",
    "text": "üìö Mandatory Reading\n\nTutorial First steps in R\nChapter 2 in Wickham et al. (2023).\n\n\nüèÜ Further readings\n\nR Studio Cheat Sheet\nChapter 4 in Wickham et al. (2023).\nChapter 8 in Wickham et al. (2023)."
  },
  {
    "objectID": "2024Spring/material/session02.html#coursework",
    "href": "2024Spring/material/session02.html#coursework",
    "title": "üóìÔ∏è Session 2: First steps in R",
    "section": "‚úçÔ∏è Coursework",
    "text": "‚úçÔ∏è Coursework\n\nDo the Basics exercises of the package DataScienceExercises\n\n\n\n\n\n\n\nQuick code for starting the exercises\n\n\n\n\n\n\nlearnr::run_tutorial(\n  name = \"Basics\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))\n\n\n\n\n\nDo the Functions exercises of the package DataScienceExercises\n\n\n\n\n\n\n\nQuick code for starting the exercises\n\n\n\n\n\n\nlearnr::run_tutorial(\n  name = \"Functions\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))\n\n\n\n\n\nIf you have questions or problems, please post them in the Moodle forum"
  },
  {
    "objectID": "2024Spring/material/session03.html",
    "href": "2024Spring/material/session03.html",
    "title": "üóìÔ∏è Session 3: Basic object types in R",
    "section": "",
    "text": "This session is video-based since it introduces some very important fundamentals, which might be a bit boring to listen to in a lecture. In the videos, you learn about the most important and most fundamental object types in R, such as decimal numbers or words. While this might look a bit boring at first, understanding these basic types is fundamental for all the more advanced (and exiting) stuff in the future!"
  },
  {
    "objectID": "2024Spring/material/session03.html#lecture-slides",
    "href": "2024Spring/material/session03.html#lecture-slides",
    "title": "üóìÔ∏è Session 3: Basic object types in R",
    "section": "üë®‚Äçüè´ Lecture Slides",
    "text": "üë®‚Äçüè´ Lecture Slides\nEither click on the slide area below or click here to download the slides.\n\n  \n\n\n\n\n\n\n\nSolutions to the intermediate exercises"
  },
  {
    "objectID": "2024Spring/material/session03.html#lecture-videos",
    "href": "2024Spring/material/session03.html#lecture-videos",
    "title": "üóìÔ∏è Session 3: Basic object types in R",
    "section": "üé• Lecture videos",
    "text": "üé• Lecture videos\nAll the videos are available via this playlist.\n\n\n\n\n\n\nExpand to access the videos directly"
  },
  {
    "objectID": "2024Spring/material/session03.html#mandatory-reading",
    "href": "2024Spring/material/session03.html#mandatory-reading",
    "title": "üóìÔ∏è Session 3: Basic object types in R",
    "section": "üìö Mandatory Reading",
    "text": "üìö Mandatory Reading\nRead the following tutorials:\n\nFundamental object types in R I: Functions\nFundamental object types in R II: Vectors\n\n\nüèÜ Further readings\nI suggest you read these references after you learned about data frames in session 4 and data wrangling techniques in sessions 8 and 9. - Sections 1-3 in Chapter 12 of Wickham et al. (2023). - Chapter 13 in Wickham et al. (2023). - Chapter 14 in Wickham et al. (2023)."
  },
  {
    "objectID": "2024Spring/material/session03.html#coursework",
    "href": "2024Spring/material/session03.html#coursework",
    "title": "üóìÔ∏è Session 3: Basic object types in R",
    "section": "‚úçÔ∏è Coursework",
    "text": "‚úçÔ∏è Coursework\n\nDo the ObjectTypes1 exercises of the package DataScienceExercises\n\n\n\n\n\n\n\nQuick code for starting the exercises\n\n\n\n\n\n\nlearnr::run_tutorial(\n  name = \"ObjectTypes1\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))\n\n\n\n\n\nIf you have questions or problems, please post them in the Moodle forum"
  },
  {
    "objectID": "2024Spring/material/session04.html",
    "href": "2024Spring/material/session04.html",
    "title": "üóìÔ∏è Session 4: Advanced object types in R",
    "section": "",
    "text": "In this video-based lecture you learn about the most important advanced object types in R. The two object types covered in this lecture, factors and data frames, are advanced in the sense that they can be thought of extensions of some of the basic object types you encountered before: factors and special kinds of integers, and data frames are special kinds of lists. This lecture concludes the first part of the lecture about the basics of R."
  },
  {
    "objectID": "2024Spring/material/session04.html#lecture-slides",
    "href": "2024Spring/material/session04.html#lecture-slides",
    "title": "üóìÔ∏è Session 4: Advanced object types in R",
    "section": "üë®‚Äçüè´ Lecture Slides",
    "text": "üë®‚Äçüè´ Lecture Slides\nEither click on the slide area below or click here to download the slides.\n\n  \n\n\n\n\n\n\n\nThe R script of this session"
  },
  {
    "objectID": "2024Spring/material/session04.html#lecture-videos",
    "href": "2024Spring/material/session04.html#lecture-videos",
    "title": "üóìÔ∏è Session 4: Advanced object types in R",
    "section": "üé• Lecture videos",
    "text": "üé• Lecture videos\nAll the videos are available via this playlist.\n\n\n\n\n\n\nExpand to access the videos directly"
  },
  {
    "objectID": "2024Spring/material/session04.html#mandatory-reading",
    "href": "2024Spring/material/session04.html#mandatory-reading",
    "title": "üóìÔ∏è Session 4: Advanced object types in R",
    "section": "üìö Mandatory Reading",
    "text": "üìö Mandatory Reading\nRead the following tutorials:\n\nFundamental object types in R III: Factors and data frames\n\n\nüèÜ Further readings\nI suggest you read these references after you learned about data frames in session 4 and data wrangling techniques in sessions 8 and 9.\n\nChapter 16 in Wickham et al. (2023)."
  },
  {
    "objectID": "2024Spring/material/session04.html#coursework",
    "href": "2024Spring/material/session04.html#coursework",
    "title": "üóìÔ∏è Session 4: Advanced object types in R",
    "section": "‚úçÔ∏è Coursework",
    "text": "‚úçÔ∏è Coursework\n\nDo the ObjectTypes2 exercises of the package DataScienceExercises\n\n\n\n\n\n\n\nQuick code for starting the exercises\n\n\n\n\n\n\nlearnr::run_tutorial(\n  name = \"ObjectTypes2\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))\n\n\n\n\n\nIf you have questions or problems, please post them in the Moodle forum"
  },
  {
    "objectID": "2024Spring/material/session05-exercises.html",
    "href": "2024Spring/material/session05-exercises.html",
    "title": "Exercises for Recap Session 1",
    "section": "",
    "text": "Exercise 1: Basic object types I\n\nCreate a vector containing the numbers 2, 5, 2.4 and 11.\nReplace the second element with 5.9.\nAdd the elements 3 and 1 to the beginning, and the elements \"8.0\" and \"9.2\" to the end of the vector.\nCreate a vector with the numbers from -8 to 9 (step size: 0.5)\nCompute the square root of each element of the first vector using vectorisation.\nCreate a character vector containing then strings \"Number_1\" to \"Number_5\". Use suitable helper functions to create this vector quickly.\n\n\n\nExercise 2: Basic object types II\nConsider the following vector:\n\nex_2_vec &lt;- c(1, \"2\", FALSE)\n\n\nWhat is the type of this vector? Why?\nWhat happens if you coerce this vector into type integer? Why?\nWhat does sum(is.na(x)) tell you about a vector x? What is happening here?\nIs it a good idea to use as.integer() on double characters to round them to the next integer? Why (not)? What other ways are there to do the rounding?\n\n\n\nExercise 3: Define a function\nCreate functions that take a vector as input and returns:\n\nThe last value.\nEvery element except the last value and any missing values.\nOnly even numbers.\n\n\nHint: Use the operation x %% y to get the remainder from diving x by y, the so called ‚Äòmodulo y‚Äô. For even numbers, the modulo 2 is zero.\n\nApply your function to the following example vector:\n\nex_3_vec &lt;- c(1, -8, 99, 3, NA, 3, -0.5)\n\n\n\nExercise 4: Lists\n\nCreate a list that contains three elements called 'a', 'b' and 'c'. The first element should correspond to a double vector with the elements 1.5, -2.9 and 99. The second element should correspond to a character vector with the elments 'Hello', '3', and 'EUF'. The third element should contain three times the entry FALSE.\nTransform this list into a data.frame and a tibble. Then apply str() to get information about the respective structure. How do the results differ?\n\n\n\nExercise 5: Data frames and the study semester distribution at EUF\nThe package DataScienceExercises contains a data set called EUFstudentsemesters, which contains information about the distribution of study semesters of enrolled students at the EUF in 2021. You can shortcut the data set as follows:\n\neuf_semesters &lt;- DataScienceExercises::EUFstudentsemesters\n\n\nWhat happens if you extract the column with study semesters as a vector and transform it into a double?\nWhat is the average study semester of those students being in their 8th or earlier semester?\nHow many students are in their 9th or higher study semester?\nWhat does typeof(euf_semesters) return and why?"
  },
  {
    "objectID": "2024Spring/material/session05-solutions.html",
    "href": "2024Spring/material/session05-solutions.html",
    "title": "Exercises for Recap Session 1",
    "section": "",
    "text": "Exercise 1: Basic object types I\n\nCreate a vector containing the numbers 2, 5, 2.4 and 11.\n\n\nex1_vec &lt;- c(2, 5, 2.4, 11)\n\n\nReplace the second element with 5.9.\n\n\nex1_vec[2] &lt;- 5.9\nex1_vec\n\n[1]  2.0  5.9  2.4 11.0\n\n\n\nAdd the elements 3 and 1 to the beginning, and the elements \"8.0\" and \"9.2\" to the end of the vector.\n\n\nva_1 &lt;- c(3, 1)\nva_2 &lt;- c(\"8.0\", \"9.2\")\nex1_vec_extended &lt;- c(va_1, ex1_vec, va_2)\nex1_vec_extended\n\n[1] \"3\"   \"1\"   \"2\"   \"5.9\" \"2.4\" \"11\"  \"8.0\" \"9.2\"\n\n\n\nCreate a vector with the numbers from -8 to 9 (step size: 0.5)\n\n\nex1_vec_4 &lt;- seq(-8, 9, by = 0.5)\nex1_vec_4\n\n [1] -8.0 -7.5 -7.0 -6.5 -6.0 -5.5 -5.0 -4.5 -4.0 -3.5 -3.0 -2.5 -2.0 -1.5 -1.0\n[16] -0.5  0.0  0.5  1.0  1.5  2.0  2.5  3.0  3.5  4.0  4.5  5.0  5.5  6.0  6.5\n[31]  7.0  7.5  8.0  8.5  9.0\n\n\n\nCompute the square root of each element of the first vector using vectorisation.\n\n\nsqrt(ex1_vec_4)\n\nWarning in sqrt(ex1_vec_4): NaNs produced\n\n\n [1]       NaN       NaN       NaN       NaN       NaN       NaN       NaN\n [8]       NaN       NaN       NaN       NaN       NaN       NaN       NaN\n[15]       NaN       NaN 0.0000000 0.7071068 1.0000000 1.2247449 1.4142136\n[22] 1.5811388 1.7320508 1.8708287 2.0000000 2.1213203 2.2360680 2.3452079\n[29] 2.4494897 2.5495098 2.6457513 2.7386128 2.8284271 2.9154759 3.0000000\n\n\n\nCreate a character vector containing then strings \"Number_1\" to \"Number_5\". Use suitable helper functions to create this vector quickly.\n\n\nex1_char_vec &lt;- paste0(\"Number_\", seq(1, 5))\nex1_char_vec\n\n[1] \"Number_1\" \"Number_2\" \"Number_3\" \"Number_4\" \"Number_5\"\n\n\n\n\nExercise 2: Basic object types II\nConsider the following vector:\n\nex_2_vec &lt;- c(1.9, \"2\", FALSE)\n\n\nWhat is the type of this vector? Why?\n\n\ntypeof(ex_2_vec)\n\n[1] \"character\"\n\n\nAtomic vectors only contain objects of the same type, and there is a hierarchy. Elements that themselves are of a type lower in the hierarchy are coerced to the same type as the object highest in the hierarchy. The hierarchy is as as follows:\n\ncharacter\ndouble\ninteger\nlogical\n\nTherefore, the type of ex_2_vec is character. The underlying reason is that you can, for instance, always transform a double value into a character but not vice versa.\n\nWhat happens if you coerce this vector into type integer? Why?\n\n\nas.integer(ex_2_vec)\n\nWarning: NAs introduced by coercion\n\n\n[1]  1  2 NA\n\n\nBecause integer is lower in the hierarchy than character, the transformation is not straightforward. By coincidence, the first two elements can actually be coerced into integers (albeit maybe not with the expected result), but there is no way you can transform the logical value FALSE into an integer, which is why a missing value is produced.\n\nWhat does sum(is.na(x)) tell you about a vector x? What is happening here?\n\n\nx &lt;- c(1,2,3,NA,NA,8)\n\nFirst, is.na(x) creates a vector with logical values indicating whether a value of the original vector is missing (i.e.¬†NA):\n\nis.na(x)\n\n[1] FALSE FALSE FALSE  TRUE  TRUE FALSE\n\n\nThen, sum() computes the sum over this vecor of boolean values:\n\nsum(is.na(x))\n\n[1] 2\n\n\nHere, TRUE counts as one and FALSE as zero, so sum() gives the number of cases in which is.na(x) has evaluated to TRUE:\n\nIs it a good idea to use as.integer() on double characters to round them to the next integer? Why (not)? What other ways are there to do the rounding?\n\nNo, because as.integer() is not acutally rounding numbers (as, for example, as.integer(2.1) would make you think), but only removing the decimal part of the number:\n\nas.integer(2.9) # you might expect 2...\n\n[1] 2\n\n\nBetter use round():\n\nround(2.9)\n\n[1] 3\n\n\n\n\nExercise 3: Define a function\nCreate functions that take a vector as input and returns:\n\nThe last value.\n\n\nget_last_val &lt;- function(x){\n  last_val &lt;- x[length(x)]\n  return(last_val)\n}\n\n\nEvery element except the last value and any missing values.\n\n\nget_beginning &lt;- function(x){\n  beginning &lt;- x[-length(x)] # Removes last value\n  na_positions &lt;- which(is.na(beginning)) # Get positions of NA values\n  beginning_nonas &lt;- beginning[-na_positions] # Removes these values\n  return(beginning_nonas)\n} \n\n\nOnly even numbers.\n\n\nHint: Use the operation x %% y to get the remainder from diving x by y, the so called ‚Äòmodulo y‚Äô. For even numbers, the modulo 2 is zero.\n\n\nget_even &lt;- function(x){\n  modulo_2s &lt;- x%%2 # Module 2 is zero for even numbers only\n  even_nbs &lt;- x[modulo_2s==0] # Keep only those for which modulo 2 is zero\n  na_positions &lt;- which(is.na(even_nbs)) # Get positions of NA values\n  even_nbs_nonas &lt;- even_nbs[-na_positions] # Removes these values\n  return(even_nbs_nonas)\n}\n\nApply your function to the following example vector:\n\nex_3_vec &lt;- c(1, -8, 99, 3, NA, 4, -0.5, 50)\n\n\nget_last_val(ex_3_vec)\n\n[1] 50\n\nget_beginning(ex_3_vec)\n\n[1]  1.0 -8.0 99.0  3.0  4.0 -0.5\n\nget_even(ex_3_vec)\n\n[1] -8  4 50\n\n\n\n\nExercise 4: Lists\n\nCreate a list that contains three elements called 'a', 'b' and 'c'. The first element should correspond to a double vector with the elements 1.5, -2.9 and 99. The second element should correspond to a character vector with the elments 'Hello', '3', and 'EUF'. The third element should contain three times the entry FALSE.\n\n\nex_4_list &lt;- list(\n  'a' = c(1.5, -2.9, 99),\n  'b' = c('Hello', \"'3'\", 'EUF'),\n  'c' = rep(FALSE, 3)\n)\n\n\nTransform this list into a data.frame and a tibble. Then apply str() to get information about the respective structure. How do the results differ?\n\n\nex_4_df &lt;- as.data.frame(ex_4_list)\nex_4_tb &lt;- tibble::as_tibble(ex_4_list)\nstr(ex_4_list)\n\nList of 3\n $ a: num [1:3] 1.5 -2.9 99\n $ b: chr [1:3] \"Hello\" \"'3'\" \"EUF\"\n $ c: logi [1:3] FALSE FALSE FALSE\n\nstr(ex_4_df)\n\n'data.frame':   3 obs. of  3 variables:\n $ a: num  1.5 -2.9 99\n $ b: chr  \"Hello\" \"'3'\" \"EUF\"\n $ c: logi  FALSE FALSE FALSE\n\nstr(ex_4_tb)\n\ntibble [3 √ó 3] (S3: tbl_df/tbl/data.frame)\n $ a: num [1:3] 1.5 -2.9 99\n $ b: chr [1:3] \"Hello\" \"'3'\" \"EUF\"\n $ c: logi [1:3] FALSE FALSE FALSE\n\n\nstr() only differs with regard to the first line describing the type.\n\n\nExercise 5: Data frames and the study semester distribution at EUF\nThe package DataScienceExercises contains a data set called EUFstudentsemesters, which contains information about the distribution of study semesters of enrolled students at the EUF in 2021. You can shortcut the data set as follows:\n\neuf_semesters &lt;- DataScienceExercises::EUFstudentsemesters\n\n\nWhat happens if you extract the column with study semesters as a vector and transform it into a double?\n\n\nunique(euf_semesters[[\"Semester\"]])\n\n[1] \"6\"           \"4\"           \"2\"           \"8\"           \"9 or higher\"\n[6] \"7\"           \"5\"           \"3\"           \"1\"          \n\nsemesters &lt;- as.double(euf_semesters[[\"Semester\"]])\n\nWarning: NAs introduced by coercion\n\nunique(semesters)\n\n[1]  6  4  2  8 NA  7  5  3  1\n\n\nWe see that the previous entry \"9 or higher\" has been transformed into NA.\n\nWhat is the average study semester of those students being in their 8th or earlier semester?\n\n\nmean(semesters, na.rm = TRUE)\n\n[1] 4.177026\n\n\n\nHow many students are in their 9th or higher study semester?\n\n\nsum(euf_semesters$Semester==\"9 or higher\")\n\n[1] 469\n\n\n\nWhat does typeof(euf_semesters) return and why?\n\n\ntypeof(euf_semesters)\n\n[1] \"list\"\n\n\nIt returns list, because while euf_semesters is a tibble, typeof() always gives the underlying basic object type. For tibbles, this is list."
  },
  {
    "objectID": "2024Spring/material/session05.html",
    "href": "2024Spring/material/session05.html",
    "title": "üóìÔ∏è Sessions 5 and 6: Recap and practice",
    "section": "",
    "text": "This session is about recap and practice. We will do exercises on topics that you suggest, and recap concepts you found particularly hard to grasp. To this end, make sure you communicate your preferences on topics via Moodle until one week before this session."
  },
  {
    "objectID": "2024Spring/material/session05.html#lecture-slides",
    "href": "2024Spring/material/session05.html#lecture-slides",
    "title": "üóìÔ∏è Sessions 5 and 6: Recap and practice",
    "section": "üë®‚Äçüè´ Lecture Slides",
    "text": "üë®‚Äçüè´ Lecture Slides\nThere were no slides used during this session.\n\n\n\n\n\n\nScript for the function example we were using\n\n\n\n\n\nThis is basically a step-by-step solution to the first function exercise of the Basics exercise collection in the package DataScienceExercises."
  },
  {
    "objectID": "2024Spring/material/session05.html#lecture-videos",
    "href": "2024Spring/material/session05.html#lecture-videos",
    "title": "üóìÔ∏è Sessions 5 and 6: Recap and practice",
    "section": "üé• Lecture videos",
    "text": "üé• Lecture videos\nThere will be no videos for recap sessions."
  },
  {
    "objectID": "2024Spring/material/session05.html#suggested-reading",
    "href": "2024Spring/material/session05.html#suggested-reading",
    "title": "üóìÔ∏è Sessions 5 and 6: Recap and practice",
    "section": "üìö Suggested Reading",
    "text": "üìö Suggested Reading\n\nRead again the tutorial on functions\nI added more mini exercises for defining functions to the package DataScienceExercises as part of the new exercise package Functions\n\n\n\n\n\n\n\nQuick code for starting the exercises on functions\n\n\n\n\n\n\nlearnr::run_tutorial(\n  name = \"Functions\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))"
  },
  {
    "objectID": "2024Spring/material/session05.html#coursework",
    "href": "2024Spring/material/session05.html#coursework",
    "title": "üóìÔ∏è Sessions 5 and 6: Recap and practice",
    "section": "‚úçÔ∏è Coursework",
    "text": "‚úçÔ∏è Coursework\nDuring the first 60 minutes of the session you will work on this sheet in groups of three people. Please use only one computer but develop the solutions together. In the remaining 30 minutes we will go through your solutions and discuss problems. I will post my own solutions online after the session, but urge to first try to come up with solutions on your own.\n\nExercise sheet for this session\nR file template for your solutions\nPossible solutions to the exercises"
  },
  {
    "objectID": "2024Spring/material/session07.html",
    "href": "2024Spring/material/session07.html",
    "title": "üóìÔ∏è Session 7: Visualization",
    "section": "",
    "text": "One area for which R is particulary well-known for is the area of visualization. This is particularly because of the package ggplot2. This session introduces ggplot2 and the general approach to generate visualization in R. The good thing is that if you follow the approach described here, you can basically create every visualization type you can think of."
  },
  {
    "objectID": "2024Spring/material/session07.html#lecture-slides",
    "href": "2024Spring/material/session07.html#lecture-slides",
    "title": "üóìÔ∏è Session 7: Visualization",
    "section": "üë®‚Äçüè´ Lecture Slides",
    "text": "üë®‚Äçüè´ Lecture Slides\nEither click on the slide area below or click here to download the slides.\n\n  \n\n\n\n\n\n\n\nThe R script of this session"
  },
  {
    "objectID": "2024Spring/material/session07.html#lecture-videos",
    "href": "2024Spring/material/session07.html#lecture-videos",
    "title": "üóìÔ∏è Session 7: Visualization",
    "section": "üé• Lecture videos",
    "text": "üé• Lecture videos\nCurrently, no videos are available for this session. Check out the tutorial instead."
  },
  {
    "objectID": "2024Spring/material/session07.html#mandatory-reading",
    "href": "2024Spring/material/session07.html#mandatory-reading",
    "title": "üóìÔ∏è Session 7: Visualization",
    "section": "üìö Mandatory Reading",
    "text": "üìö Mandatory Reading\n\nThe tutorial visualization"
  },
  {
    "objectID": "2024Spring/material/session07.html#further-reading",
    "href": "2024Spring/material/session07.html#further-reading",
    "title": "üóìÔ∏è Session 7: Visualization",
    "section": "Further Reading",
    "text": "Further Reading\n\nWickham (2010), who introduces the theory underlying ggplot2\nggplot2 cheat sheet\nBrowse the website from Data to Viz and try to re-create some of the figures yourself"
  },
  {
    "objectID": "2024Spring/material/session07.html#coursework",
    "href": "2024Spring/material/session07.html#coursework",
    "title": "üóìÔ∏è Session 7: Visualization",
    "section": "‚úçÔ∏è Coursework",
    "text": "‚úçÔ∏è Coursework\n\nDo the exercises Visualization1 from the DataScienceExercises package\n\n\n\n\n\n\n\nQuick code for starting the exercises\n\n\n\n\n\n\nlearnr::run_tutorial(\n  name = \"Visualization1\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))"
  },
  {
    "objectID": "2024Spring/material/session08.html",
    "href": "2024Spring/material/session08.html",
    "title": "üóìÔ∏è Session 8: Project management",
    "section": "",
    "text": "This is one of the most underestimated topics. In this session you learn how to adequately set up your working environment on your computer. This means where you should save which files, which directory structure you should use, and how to point the computer to other files on your computer. While this sounds boring at first, taking seriously the insights from this session will save you tons of hours of frustration in the future!"
  },
  {
    "objectID": "2024Spring/material/session08.html#lecture-slides",
    "href": "2024Spring/material/session08.html#lecture-slides",
    "title": "üóìÔ∏è Session 8: Project management",
    "section": "üë®‚Äçüè´ Lecture Slides",
    "text": "üë®‚Äçüè´ Lecture Slides\nEither click on the slide area below or click here to download the slides."
  },
  {
    "objectID": "2024Spring/material/session08.html#lecture-videos",
    "href": "2024Spring/material/session08.html#lecture-videos",
    "title": "üóìÔ∏è Session 8: Project management",
    "section": "üé• Lecture videos",
    "text": "üé• Lecture videos\nCurrently, no videos are available for this session. Check out the tutorial on project setup instead."
  },
  {
    "objectID": "2024Spring/material/session08.html#mandatory-reading",
    "href": "2024Spring/material/session08.html#mandatory-reading",
    "title": "üóìÔ∏è Session 8: Project management",
    "section": "üìö Mandatory Reading",
    "text": "üìö Mandatory Reading\n\nThe tutorial Setting up an R project"
  },
  {
    "objectID": "2024Spring/material/session08.html#further-reading",
    "href": "2024Spring/material/session08.html#further-reading",
    "title": "üóìÔ∏è Session 8: Project management",
    "section": "Further Reading",
    "text": "Further Reading\nWhile we do not cover this in this course, I highly recommend learning the version control system Git. Personally, I can recommend the following:\n\nVery concise introduction to Git\nIntroduction to GitHub: GitHub skills and the official docs"
  },
  {
    "objectID": "2024Spring/material/session08.html#coursework",
    "href": "2024Spring/material/session08.html#coursework",
    "title": "üóìÔ∏è Session 8: Project management",
    "section": "‚úçÔ∏è Coursework",
    "text": "‚úçÔ∏è Coursework\n\nDo the exercises ProjectOrga from the DataScienceExercises package that refer to setting up an R project\n\n\n\n\n\n\n\nQuick code for starting the exercises\n\n\n\n\n\n\nlearnr::run_tutorial(\n  name = \"ProjectOrga\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))"
  },
  {
    "objectID": "2024Spring/material/session09.html",
    "href": "2024Spring/material/session09.html",
    "title": "üóìÔ∏è Session 9: Importing data",
    "section": "",
    "text": "This is also one of the most underestimated topics. This session builds upon the previous session on setting up a project environment. Now you will learn how to import data obtained elsewhere into R. We focus on importing .csv files, but with the skills acquired in this context you will face no difficulties in importing other data types as well."
  },
  {
    "objectID": "2024Spring/material/session09.html#lecture-slides",
    "href": "2024Spring/material/session09.html#lecture-slides",
    "title": "üóìÔ∏è Session 9: Importing data",
    "section": "üë®‚Äçüè´ Lecture Slides",
    "text": "üë®‚Äçüè´ Lecture Slides\nEither click on the slide area below or click here to download the slides.\n\n  \n\n\nData for the exercises"
  },
  {
    "objectID": "2024Spring/material/session09.html#lecture-videos",
    "href": "2024Spring/material/session09.html#lecture-videos",
    "title": "üóìÔ∏è Session 9: Importing data",
    "section": "üé• Lecture videos",
    "text": "üé• Lecture videos\nAll the videos are available via this playlist.\n\n\n\n\n\n\nExpand to access the videos directly"
  },
  {
    "objectID": "2024Spring/material/session09.html#mandatory-reading",
    "href": "2024Spring/material/session09.html#mandatory-reading",
    "title": "üóìÔ∏è Session 9: Importing data",
    "section": "üìö Mandatory Reading",
    "text": "üìö Mandatory Reading\n\nThe tutorial Importing and exporting data using data.table"
  },
  {
    "objectID": "2024Spring/material/session09.html#further-reading",
    "href": "2024Spring/material/session09.html#further-reading",
    "title": "üóìÔ∏è Session 9: Importing data",
    "section": "Further Reading",
    "text": "Further Reading\nTBA"
  },
  {
    "objectID": "2024Spring/material/session09.html#coursework",
    "href": "2024Spring/material/session09.html#coursework",
    "title": "üóìÔ∏è Session 9: Importing data",
    "section": "‚úçÔ∏è Coursework",
    "text": "‚úçÔ∏è Coursework\n\nDo the exercises ProjectOrga from the DataScienceExercises package\n\n\n\n\n\n\n\nQuick code for starting the exercises\n\n\n\n\n\n\nlearnr::run_tutorial(\n  name = \"ProjectOrga\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))"
  },
  {
    "objectID": "2024Spring/material/session10.html",
    "href": "2024Spring/material/session10.html",
    "title": "üóìÔ∏è Session 10: Data preparation",
    "section": "",
    "text": "In this session you learn how to turn your raw data into a state such that you can work with it. Luckily, there is one particular form for our data that represents the common starting point for all further operations, such as visualization or modelling. This form is called tidy data. And the goal of this session is to equip you with the tools that you need to turn the often messy raw data into tidy data. These skills are important because they make you independent: you will be able to prepare any data you find or create yourself such that you can further process it, and you will not rely on others to provide you data in a particular form."
  },
  {
    "objectID": "2024Spring/material/session10.html#lecture-slides",
    "href": "2024Spring/material/session10.html#lecture-slides",
    "title": "üóìÔ∏è Session 10: Data preparation",
    "section": "üë®‚Äçüè´ Lecture Slides",
    "text": "üë®‚Äçüè´ Lecture Slides\nEither click on the slide area below or click here to download the slides.\n\n  \n\n\n\n\n\n\n\nData and solutions to the intermediate exercises\n\n\n\n\n\n\nData used in the video\nData for exercises"
  },
  {
    "objectID": "2024Spring/material/session10.html#lecture-videos",
    "href": "2024Spring/material/session10.html#lecture-videos",
    "title": "üóìÔ∏è Session 10: Data preparation",
    "section": "üé• Lecture videos",
    "text": "üé• Lecture videos\nAll the videos are available via this playlist.\n\n\n\n\n\n\nExpand to access the videos directly\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolutions to the intermediate exercises"
  },
  {
    "objectID": "2024Spring/material/session10.html#mandatory-reading",
    "href": "2024Spring/material/session10.html#mandatory-reading",
    "title": "üóìÔ∏è Session 10: Data preparation",
    "section": "üìö Mandatory Reading",
    "text": "üìö Mandatory Reading\n\nThe tutorial Data preparation\nChapter 5 in Wickham et al. (2023)."
  },
  {
    "objectID": "2024Spring/material/session10.html#further-reading",
    "href": "2024Spring/material/session10.html#further-reading",
    "title": "üóìÔ∏è Session 10: Data preparation",
    "section": "Further Reading",
    "text": "Further Reading\n\nThe help page for the selection helpers, which facilitate the selection of particular columns.\nChapter 13 in Wickham et al. (2023).\nChapter 14 in Wickham et al. (2023).\nWickham (2014) on the concept of ‚Äòtidy data‚Äô (see the Github repo for reproduction of the paper)"
  },
  {
    "objectID": "2024Spring/material/session10.html#coursework",
    "href": "2024Spring/material/session10.html#coursework",
    "title": "üóìÔ∏è Session 10: Data preparation",
    "section": "‚úçÔ∏è Coursework",
    "text": "‚úçÔ∏è Coursework\n\nDo the exercises Wrangling1 from the DataScienceExercises package\n\n\n\n\n\n\n\nQuick code for starting the exercises\n\n\n\n\n\n\nlearnr::run_tutorial(\n  name = \"Wrangling1\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))\n\n\n\n\n\nDownload data about the CO2 emissions for some countries of your choice from the World Bank website for the years 2000 to 2020. Set up an R project, save the data, import it, and make a line graph.\n\nZIP file with a possible solution1\n\nIf you want more exercises on the challenge of making data longer/wider, you can do the exercises Wrangling2 from the DataScienceExercises package\n\n\n\n\n\n\n\nQuick code for starting the exercises\n\n\n\n\n\n\nlearnr::run_tutorial(\n  name = \"Wrangling2\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))"
  },
  {
    "objectID": "2024Spring/material/session10.html#footnotes",
    "href": "2024Spring/material/session10.html#footnotes",
    "title": "üóìÔ∏è Session 10: Data preparation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYou can ignore the make_co2_data.R for now and only look at make_co2_plot.R.‚Ü©Ô∏é"
  },
  {
    "objectID": "2024Spring/material/session11.html",
    "href": "2024Spring/material/session11.html",
    "title": "üóìÔ∏è Session 11: A very short introduction to Quarto",
    "section": "",
    "text": "Quarto is a modern multi-language version of R Markdown. As with its predessessor, the idea is to provide people with the opportunity to write text and code into the very same document. This makes the creation of nice looking and reproducible reports or paper very easy. Moreoever, with Quarto it is very easy to create very nice papers, reports, websites or interactive apps. This website, for example, is fully written in Quarto. In this lecture, you learn everything you need to get started with writing your first Quarto documents. In fact, its really straighforward once you get the basic idea."
  },
  {
    "objectID": "2024Spring/material/session11.html#lecture-slides",
    "href": "2024Spring/material/session11.html#lecture-slides",
    "title": "üóìÔ∏è Session 11: A very short introduction to Quarto",
    "section": "üë®‚Äçüè´ Lecture Slides",
    "text": "üë®‚Äçüè´ Lecture Slides\nEither click on the slide area below or click here to download the slides.\n\n  \n\n\nDesasterMarkdown.pdf\nNicerMarkdown.pdf\n\n\n\n\n\n\n\nCode for the markdown desaster and a possible solution"
  },
  {
    "objectID": "2024Spring/material/session11.html#lecture-videos",
    "href": "2024Spring/material/session11.html#lecture-videos",
    "title": "üóìÔ∏è Session 11: A very short introduction to Quarto",
    "section": "üé• Lecture videos",
    "text": "üé• Lecture videos\nSo far, there are no learning videos available for this lecture."
  },
  {
    "objectID": "2024Spring/material/session11.html#mandatory-reading",
    "href": "2024Spring/material/session11.html#mandatory-reading",
    "title": "üóìÔ∏è Session 11: A very short introduction to Quarto",
    "section": "üìö Mandatory Reading",
    "text": "üìö Mandatory Reading\n\nThe CommonMark markdown tutorial\nQuarto tutorial I: the basics\nQuarto tutorial II: computations\nQuarto tutorial III: authoring quarto documents"
  },
  {
    "objectID": "2024Spring/material/session11.html#further-reading",
    "href": "2024Spring/material/session11.html#further-reading",
    "title": "üóìÔ∏è Session 11: A very short introduction to Quarto",
    "section": "Further Reading",
    "text": "Further Reading\n\nBlog introducing Quarto\nQuarto and R Markdown\nThe comprehensive Quarto documentation\nMarkdown basics\nThe R Markdown Cookbook"
  },
  {
    "objectID": "2024Spring/material/session11.html#coursework",
    "href": "2024Spring/material/session11.html#coursework",
    "title": "üóìÔ∏è Session 11: A very short introduction to Quarto",
    "section": "‚úçÔ∏è Coursework",
    "text": "‚úçÔ∏è Coursework\n\nDo the exercises Quarto from the DataScienceExercises package\n\n\n\n\n\n\n\nQuick code for starting the exercises\n\n\n\n\n\n\nlearnr::run_tutorial(\n  name = \"Quarto\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))\n\n\n\n\n\nDo the following practical exercise:\n\n\n\n\n\n\n\nExercise description\n\n\n\n\n\nCreate a new Quarto document where you set the title, date, and the author explicitly. Write a sample text that comprises‚Ä¶\n\n‚Ä¶at least one level 1 heading\n‚Ä¶at least two level 2 headings\n‚Ä¶a YAML part that specifies that R code remains hidden by default\n‚Ä¶one R chunk where both the output and the code is printed in the final document\n‚Ä¶one R chunk that produces a simply ggplot object and where the code producing the plot is hidden\n\nThen do the following:\n\nKnit the document to html with a floating table of contents and a special theme.\nMake the document available via Netlify Drop and add the possibility to download the underlying Rmd file. &gt; Note: For Netlify Drop to work, the html file must be called `index.html```!\nKnit the document to PDF and make sure that it includes a table of contents.\n\n\n\n\n\n\n\n\n\n\nPossible solution"
  },
  {
    "objectID": "2024Spring/material/session12.html",
    "href": "2024Spring/material/session12.html",
    "title": "üóìÔ∏è Sessions 12 and 13: Recap and practice",
    "section": "",
    "text": "This session is about recap and practice. We will do exercises on topics that you suggest, and recap concepts you found particularly hard to grasp. To this end, make sure you communicate your preferences on topics via Moodle until one week before this session."
  },
  {
    "objectID": "2024Spring/material/session12.html#lecture-slides",
    "href": "2024Spring/material/session12.html#lecture-slides",
    "title": "üóìÔ∏è Sessions 12 and 13: Recap and practice",
    "section": "üë®‚Äçüè´ Lecture Slides",
    "text": "üë®‚Äçüè´ Lecture Slides\nThere were no slides used during this session."
  },
  {
    "objectID": "2024Spring/material/session12.html#lecture-videos",
    "href": "2024Spring/material/session12.html#lecture-videos",
    "title": "üóìÔ∏è Sessions 12 and 13: Recap and practice",
    "section": "üé• Lecture videos",
    "text": "üé• Lecture videos\nThere will be no videos for recap sessions."
  },
  {
    "objectID": "2024Spring/material/session12.html#exercises-for-the-class",
    "href": "2024Spring/material/session12.html#exercises-for-the-class",
    "title": "üóìÔ∏è Sessions 12 and 13: Recap and practice",
    "section": "‚úçÔ∏è Exercises for the class",
    "text": "‚úçÔ∏è Exercises for the class\nI suggest you create one R project environment for all the exercises of this  session.\n\nSolving the CO2 exercise from session 10 together\nDownload data about the CO2 emissions for some countries of your choice from the World Bank website for the years 2000 to 2020. Set up an R project, save the data, import it, and make a line graph.\n\n\nData wrangling I\nDownload and import the following data set on education spending and income.\nCompute, for each country, the percentage change of the spending from the year 2010 to the year 2020 and save this as a variable called perc_change.\n\nHint: The equation to compute the percentage change of a variable \\(X\\) from \\(t=1\\) to \\(t=2\\) is as follows:\n\n\\[g_X = \\frac{X_{t=2}-X_{t=1}}{X_{t=1}}\\cdot 100\\]\nFilter the data set such that there are no entries with a missing value in the variable perc_change.\nSave the new data set under a useful name in an adequate location.\n\n\nData wrangling II\nUse the same data set as in the exercise before.\nCompute for each income group the average expense of education over the whole period. Make sure missing values are ignored.\nSave the new data set under a useful name in an adequate location.\n\n\nVisualization and Quarto\nCreate a Quarto document and make sure that the following applies:\n\nYour name is set as the author of the file\nYour document is rendered to html format\nThe title of the file is ‚ÄúSessions 12 and 13: Recap and Practice‚Äù\nSections are numbered\nThere is a table of contents at the beginning of the document\n\nThen read in the following data set on GDP per capita and child mortality.\nSummarize the data per country such that you have one mean value for child mortality and GDP per capita for each country (ignoring missing values).\nCreate a scatter plot, in which the y axis shows child mortality and the x axis GDP per capita.\nThen create a second scatter plot, in which both variables are transformed using the natural logarithm (using the R function log()).\nIn your rendered quarto document, there should be no R code visible, only the output. Also, warnings and messages should not be visible."
  },
  {
    "objectID": "2024Spring/material/session12.html#suggested-reading",
    "href": "2024Spring/material/session12.html#suggested-reading",
    "title": "üóìÔ∏è Sessions 12 and 13: Recap and practice",
    "section": "üìö Suggested Reading",
    "text": "üìö Suggested Reading\n\nSolutions to all the exercises\nTutorial on using the WDI package (TBA)\n‚Ä¶"
  },
  {
    "objectID": "2024Spring/material/session14.html",
    "href": "2024Spring/material/session14.html",
    "title": "üóìÔ∏è Session 14: An introduction to data analysis",
    "section": "",
    "text": "In this theoretical lecture, we will discuss key concepts in data analysis The aim is to give you an overview of the different types of data analysis and which techniques can be used in which context. In addition, the basic vocabulary is clarified so that you don‚Äôt get lost in the jungle of buzzwords that exists in the context of ‚Äòdata science‚Äô."
  },
  {
    "objectID": "2024Spring/material/session14.html#lecture-slides",
    "href": "2024Spring/material/session14.html#lecture-slides",
    "title": "üóìÔ∏è Session 14: An introduction to data analysis",
    "section": "üë®‚Äçüè´ Lecture Slides",
    "text": "üë®‚Äçüè´ Lecture Slides\nEither click on the slide area below or click here to download the slides."
  },
  {
    "objectID": "2024Spring/material/session14.html#lecture-videos",
    "href": "2024Spring/material/session14.html#lecture-videos",
    "title": "üóìÔ∏è Session 14: An introduction to data analysis",
    "section": "üé• Lecture videos",
    "text": "üé• Lecture videos\nSo far, there are no learning videos available for this lecture."
  },
  {
    "objectID": "2024Spring/material/session14.html#mandatory-reading",
    "href": "2024Spring/material/session14.html#mandatory-reading",
    "title": "üóìÔ∏è Session 14: An introduction to data analysis",
    "section": "üìö Mandatory Reading",
    "text": "üìö Mandatory Reading\n\nIntroduction and Section 2.1. in James et al. (2021)."
  },
  {
    "objectID": "2024Spring/material/session14.html#coursework",
    "href": "2024Spring/material/session14.html#coursework",
    "title": "üóìÔ∏è Session 14: An introduction to data analysis",
    "section": "‚úçÔ∏è Coursework",
    "text": "‚úçÔ∏è Coursework\n\nAnswer the recap questions from the last slide"
  },
  {
    "objectID": "2024Spring/material/session15-solution-clt.html",
    "href": "2024Spring/material/session15-solution-clt.html",
    "title": "The Central Limit Theorem",
    "section": "",
    "text": "1 Packages used\n\nlibrary(tibble)\nlibrary(data.table)\nlibrary(ggplot2)\nlibrary(ggpubr)\nlibrary(icaeDesign)\n\n\n\n2 Statement of the CLT\nThe CLT states that - if certain general conditions are met - that the distribution of the mean values of samples that were drawn from an arbitrary population tend to be normally distributed if the sample size becomes large enough.\nThis result holds irrespective of the distribution of the population as such.\n\n\n3 Solution\nHere is an example. Consider the following population parameter, which is clearly distributed exponentially:\n\nset.seed(123)\n# Population with 5000 exponentially distributed values\nN &lt;- 5000\nexp_par &lt;- 2\n\npopulation &lt;- rexp(n = N, rate = exp_par)\npopulation_tab &lt;- tibble(\"pop_n\" = population) \ntrue_mean &lt;- mean(population)\n\npopulation_plot &lt;- ggplot(data = population_tab, aes(x = pop_n)) +\n  geom_histogram(aes(y = after_stat(density))) + \n  scale_y_continuous(expand = expansion(add = c(0, 0.05))) +\n  labs(title = \"The population\", y = \"Density\") +\n  theme_icae() +\n  theme(axis.title.x = element_blank())\npopulation_plot\n\n\n\n\nTo illustrate the CLT, we conduct a MCS where we draw samples of sizes 5, 10, 20 or 50, compute the means of the samples:\n\niterations &lt;- 500\nsample_sizes &lt;- c(5, 10, 20, 50)\nmean_dist_list &lt;- list()\n\nfor (i in seq_along(sample_sizes)){\n  sample_size &lt;- sample_sizes[i]\n  \n  sample_means &lt;- rep(NA, iterations)\n  \n  for (j in seq_len(iterations)){\n    sample_drawn &lt;- sample(population, size = sample_size, replace = FALSE)\n    sample_means[[j]] &lt;- mean(sample_drawn)\n  }\n  \n  sample_means_tab &lt;- tibble(\n    \"sample_size\"=sample_size, \n    \"sample_means\"=sample_means\n  )\n  mean_dist_list[[sample_size]] &lt;- sample_means_tab\n}\n\nfull_results &lt;- data.table::rbindlist(mean_dist_list)\n\nWe now visualize the resulting sampling distributions using histograms. To see how the distribution becomes more and more similar to a noramel distribution, we add a fitted normal distribution on each histogram:\n\nhist_plot &lt;- ggplot(\n  data = full_results, aes(x=sample_means)\n  ) +\n  geom_histogram(\n    mapping = aes(y=after_stat(density)), \n    alpha=0.5, color=\"#00395B\", fill=\"#00395B\"\n    ) +\n  scale_y_continuous(expand = expansion(add = c(0, 0.05))) +\n  scale_x_continuous(limits = c(-0.2, 1.2), expand = expansion()) +\n  facet_wrap(~sample_size, ncol = 4) +\n  stat_function(\n    data = dplyr::filter(full_results, sample_size==5), \n    fun = dnorm, \n    args = list(\n      mean = mean(dplyr::filter(full_results, sample_size==5)$sample_means), \n      sd = sd(dplyr::filter(full_results, sample_size==5)$sample_means))\n  ) + \n  stat_function(\n    data = dplyr::filter(full_results, sample_size==10), \n    fun = dnorm, \n    args = list(\n      mean = mean(dplyr::filter(full_results, sample_size==10)$sample_means), \n      sd = sd(dplyr::filter(full_results, sample_size==10)$sample_means))\n  ) + \n  stat_function(\n    data = dplyr::filter(full_results, sample_size==20), \n    fun = dnorm, \n    args = list(\n      mean = mean(dplyr::filter(full_results, sample_size==20)$sample_means), \n      sd = sd(dplyr::filter(full_results, sample_size==20)$sample_means))\n  ) + \n  stat_function(\n    data = dplyr::filter(full_results, sample_size==50), \n    fun = dnorm, \n    args = list(\n      mean = mean(dplyr::filter(full_results, sample_size==50)$sample_means), \n      sd = sd(dplyr::filter(full_results, sample_size==50)$sample_means))\n  ) + \n  labs(x = \"Sample means\", y = \"Density\", title = \"The sampling distributions\") +\n  theme_icae()\nhist_plot\n\n\n\n\nBut note that the CLT does not hold universally, i.e.¬†certain conditions must be met and it does not hold for all underlying distributions. It does not hold, for example, if the underlying distribution has infinite variance."
  },
  {
    "objectID": "2024Spring/material/session15-solution-eufstudents.html",
    "href": "2024Spring/material/session15-solution-eufstudents.html",
    "title": "Estimating average height of EUF students - a MCS",
    "section": "",
    "text": "library(tibble)\nlibrary(ggplot2)\n\nTask:\n\nSuppose you are interested in the average height of the students at the European University Flensburg and you are wondering what a good sample size would be. Suppose further that the data set DataScienceExercises::EUFstudents contains the result of a census of EUF students. Study the process of sampling by carrying an MCS in which you draw random samples of size 10 and 50 from this population. To do this, conduct an MCS with 1000 repetitions and check what difference it makes to increase the sample size.\n\nFirst, make sure you understand which steps are necessary to solve this task. Here, you need to:\n\nRead in and understand the data set DataScienceExercises::EUFstudents\nDraw a random sample from this data set and compute the average height of students in this sample\nDesign a MCS in which this draw is executed 1000 times for two different sample sizes\nAnalyze the results by studying the mean and variance of the estimates.\n\nOnce you have set up such a plan you can proceed step-by-step.\n\n1 Read in and understand the data set\nIt is always a good idea to have a shortcut to your data:\n\nstudent_data &lt;- DataScienceExercises::EUFstudents\n\nThen, inspect the data:\n\nhead(student_data)\n\n# A tibble: 6 √ó 2\n  Gender Height\n  &lt;chr&gt;   &lt;dbl&gt;\n1 female   159.\n2 female   161.\n3 female   173.\n4 female   163.\n5 female   164.\n6 female   174.\n\n\nWe see that there are two columns. For the purpose of this task, only the column Height is relevant.\n\n\n2 Draw and analyze a random sample from this data set\nTo draw a random sample of size 10, we can use the function sample() as follows:\n\nsample(x = student_data[[\"Height\"]], size = 10)\n\n [1] 158.0240 164.2462 155.5370 193.4313 173.8579 182.2533 159.8923 166.3148\n [9] 166.3390 167.3599\n\n\nNote that sample() takes as input an atomic vector. Thus, you need to extract the column Height as a vector from the underlying data set before drawing the sample!\nBut since we are interested in the average height of the students (our population parameter of interest), we need to compute this parameter also for our sample:\n\nmean(sample(x = student_data[[\"Height\"]], size = 10))\n\n[1] 168.4152\n\n\nWe now need to embed this process into a MCS!\n\n\n3 Design a MCS\nAlthough we need to run our MCS for 1000 times, it is a good idea to first design it using fewer iteration. In any case, we should follow the standard procedure of developing an MCS.\nFirst, create an output container with as many NAs as we will have repetitions. Note that since we collect two kinds of results - one for sample size 10, one for sample size 50 - we need two containers:\n\nn_repetitions &lt;- 5 # Start with 5 iterations\noutput_container_n10 &lt;- rep(NA, n_repetitions)\noutput_container_n50 &lt;- rep(NA, n_repetitions)\noutput_container_n10\n\n[1] NA NA NA NA NA\n\n\nSecond, think about the looping sequence. In our case, we want to repeat the MCS for n_repetitions times, so the looping sequence becomes:\n\nfor (i in seq_len(n_repetitions))\n\nThird, add the action body. Here we use the code to draw a sample from above and just integrate it into the loop:\n\nfor (i in seq_len(n_repetitions)){\n  output_container_n10[i] &lt;- mean(sample(\n    x = student_data[[\"Height\"]], size = 10))\n\n    output_container_n50[i] &lt;- mean(sample(\n    x = student_data[[\"Height\"]], size = 50))\n}\n\nFinally, to make our results fully reproducible despite involving random processes, we use the function set.seed().\nIn all, this leads to the following code:\n\nn_repetitions &lt;- 5 # Start with 5 iterations\noutput_container_n10 &lt;- rep(NA, n_repetitions)\noutput_container_n50 &lt;- rep(NA, n_repetitions)\n\nset.seed(123)\nfor (i in seq_len(n_repetitions)){\n  output_container_n10[i] &lt;- mean(sample(\n    x = student_data[[\"Height\"]], size = 10))\n\n    output_container_n50[i] &lt;- mean(sample(\n    x = student_data[[\"Height\"]], size = 50))\n}\n\nWe can test this by running the code and inspect the output container:\n\noutput_container_n10\n\n[1] 166.1539 163.8509 167.5664 168.1203 167.5359\n\n\nOkay, this makes sense. So now we can set n_repetitions to 1000 and run the MCS as desired.\n\nAnalyze the results by studying the mean and variance of the estimates\n\nTo compare the results, we now look at the resulting sampling distributions. We can do so visually, but for the task at hand, just computing the mean and standard deviation is sufficient:\n\nn_repetitions &lt;- 1000\noutput_container_n10 &lt;- rep(NA, n_repetitions)\noutput_container_n50 &lt;- rep(NA, n_repetitions)\n\nset.seed(123)\nfor (i in seq_len(n_repetitions)){\n  output_container_n10[i] &lt;- mean(sample(\n    x = student_data[[\"Height\"]], size = 10))\n\n    output_container_n50[i] &lt;- mean(sample(\n    x = student_data[[\"Height\"]], size = 50))\n}\n\nmean_10 &lt;- mean(output_container_n10)\nmean_50 &lt;- mean(output_container_n50)\nsd_10 &lt;- sd(output_container_n10)\nsd_50 &lt;- sd(output_container_n50)\n\ntibble::tribble(\n  ~`Sample size`, ~Mean, ~Variation,\n  #--|--|----\n  10, mean_10, sd_10,\n  50, mean_50, sd_50\n)\n\n# A tibble: 2 √ó 3\n  `Sample size`  Mean Variation\n          &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1            10  167.      2.77\n2            50  167.      1.23\n\n\nWe see that the mean is very similar, meaning that on average both sample sizes are equivalent. But we also see that the larger sample shows much less variation and the estimates from the single samples are more concentrated around the true value. Thus, having larger samples makes our estimations more precise!\n\n\n4 Addendum: Visualizing the results\nIf you wanted to visualize the results, you could proceed as follows. First, because ggplot() requires tibbles as input, you first need to put your results into a tibble:\n\nresult_tibble &lt;- tibble::tibble(\n  \"sample_mean\" = c(output_container_n10, output_container_n50),\n  \"sample_size\" = c(rep(10, length(output_container_n10)), \n                    rep(50, length(output_container_n50)))\n)\nhead(result_tibble)\n\n# A tibble: 6 √ó 2\n  sample_mean sample_size\n        &lt;dbl&gt;       &lt;dbl&gt;\n1        166.          10\n2        164.          10\n3        168.          10\n4        168.          10\n5        168.          10\n6        169.          10\n\n\n\nsampling_plot &lt;- ggplot(data = result_tibble, aes(x=sample_mean)) +\n  geom_histogram(alpha=0.5, color=\"#00395B\", fill=\"#00395B\", binwidth = 0.5) +\n  scale_y_continuous(expand = expansion(add = c(0, 10))) +\n  facet_wrap(~sample_size, nrow = 2) +\n  labs(\n    x = \"Sample means\", \n    y = \"Count\", \n    title = \"The sampling distributions\") +\n  theme_linedraw()\nsampling_plot\n\n\n\n\nHere, the similar mean but very different variance become apparent!"
  },
  {
    "objectID": "2024Spring/material/session15-solution-terminology.html",
    "href": "2024Spring/material/session15-solution-terminology.html",
    "title": "Estimating average height of EUF students",
    "section": "",
    "text": "1 Task\n\nConsider the example from the previous task on estimating the average height of EUF students. Use the right vocabulary from sampling theory to describe it.\n\n\n\n2 Possible solution\nThe population is the set of all students enrolled at the EUF (\\(N=\\) 6402). We are interested in the population parameter ‚Äòaverage height‚Äô.\nThe sample is set of randomly drawn students from the population. We consider two cases, one with the sample size \\(n=10\\) and one with \\(n=20\\). We can assume the sample is a viable random sample, i.e.¬†that it is unbiased and representative of the population.\nThe point estimate is the sample mean of the height, which is used to estimate the population parameter of interest (i.e.¬†the average height of EUF students). This is viable since, given our assumptions, statements about the sample can be generalized to the population.\nThe sampling distribution visualizes the sampling variation, i.e.¬†the variation of the point estimate obtained from different random samples. While in reality the sampling distribution remains unknown due to the fact that only one sample can be drawn, in the present case we used an artificial population and a Monte Carlo Simulation to characterize the sampling distribution as follows:\n\n\n\n\n\nThe standard error corresponds to the standard deviation of the sampling distributions and, due to the MCS framework, can be computed directly:\n\n\n\n\n\n\nMean\nVariation\n\n\n\n\nSample size: 10\n166.49\n2.832\n\n\nSample size: 50\n166.54\n1.244\n\n\n\n\n\n\n\n3 Summary table\n\n\n\n\n\n\n\nConcept\nPendant in example\n\n\n\n\nPopulation\nSet of all students enrolled at the EUF\n\n\nSample\nSet of randomly drawn students from the population\n\n\nSample size\nHere 10 or 50\n\n\nPoint estimate\nMean height of all students in the sample\n\n\nSampling distribution\nThe distribution of all the samples drawn from the population\n\n\nStandard error\nThe standard deviation of the sampling distribution\n\n\nProperties of the sample\nWe assume the sample to be a viable random sample, i.e.¬†that it is unbiased and representative of the population, so its results are generalizable.\n\n\nCensus\nThis would mean to measure the height of every student in the population directly.\n\n\nInference\nThe strategy of understanding a population parameter by studying a sample and generalize to the population."
  },
  {
    "objectID": "2024Spring/material/session15.html",
    "href": "2024Spring/material/session15.html",
    "title": "üóìÔ∏è Sessions 15 and 16: Sampling",
    "section": "",
    "text": "A central concept in data science - and in applied statistics more generally - is that of sampling. This refers to the strategy of using (small) samples to learn about a (large) population. For example, if you wanted to understand the effect of TV advertising on the consumer behaviour of young men in Germany, you could study the whole population of young men in Germany. But since this is usually not feasible, you would rather take a sample of young men, study their behaviour and then generalise to the whole population. In this session we will discuss when and how this is possible. In this context, we will also learn about the concept of Monte Carlo simulations and two central concepts of probability theory underlying applied statistics: the central limit theorem and the law of large numbers, both of which underlie much of modern sampling theory."
  },
  {
    "objectID": "2024Spring/material/session15.html#lecture-slides",
    "href": "2024Spring/material/session15.html#lecture-slides",
    "title": "üóìÔ∏è Sessions 15 and 16: Sampling",
    "section": "üë®‚Äçüè´ Lecture Slides",
    "text": "üë®‚Äçüè´ Lecture Slides\nEither click on the slide area below or click here to download the slides.\n\n  \n\n\n\n\n\n\n\nLecture code\n\n\n\n\n\n\n\n\n\n\nExtensive solution for the exercise on the average height of EUF students\nSolution for the exercise on terminology\nExplanation of the Central Limit Theorem and the corresponding exercise"
  },
  {
    "objectID": "2024Spring/material/session15.html#lecture-videos",
    "href": "2024Spring/material/session15.html#lecture-videos",
    "title": "üóìÔ∏è Sessions 15 and 16: Sampling",
    "section": "üé• Lecture videos",
    "text": "üé• Lecture videos\nSo far, there are no learning videos available for this lecture."
  },
  {
    "objectID": "2024Spring/material/session15.html#mandatory-reading",
    "href": "2024Spring/material/session15.html#mandatory-reading",
    "title": "üóìÔ∏è Sessions 15 and 16: Sampling",
    "section": "üìö Mandatory Reading",
    "text": "üìö Mandatory Reading\n\nTutorial on sampling\nChapter 7 in Ismay and Kim (2020)."
  },
  {
    "objectID": "2024Spring/material/session15.html#coursework",
    "href": "2024Spring/material/session15.html#coursework",
    "title": "üóìÔ∏è Sessions 15 and 16: Sampling",
    "section": "‚úçÔ∏è Coursework",
    "text": "‚úçÔ∏è Coursework\n\nDo the exercises Sampling from the DataScienceExercises package\n\n\n\n\n\n\n\nQuick code for starting the exercises\n\n\n\n\n\n\nlearnr::run_tutorial(\n  name = \"Sampling\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))"
  },
  {
    "objectID": "2024Spring/material/session17.html",
    "href": "2024Spring/material/session17.html",
    "title": "üóìÔ∏è Sessions 17 & 18: Linear regresssion",
    "section": "",
    "text": "Simple linear regression is one of the most commonly used methods in inferential statistics or supervised machine learning. It can be used to study the relationship between two numerical variables and make predictions about the values of one of them based on the analysis of a sample. In this session we will discuss when to use linear regression models and where the limitations of this method lie."
  },
  {
    "objectID": "2024Spring/material/session17.html#lecture-slides",
    "href": "2024Spring/material/session17.html#lecture-slides",
    "title": "üóìÔ∏è Sessions 17 & 18: Linear regresssion",
    "section": "üë®‚Äçüè´ Lecture Slides",
    "text": "üë®‚Äçüè´ Lecture Slides\nEither click on the slide area below or click here to download the slides.\n\n  \n\n\n\n\n\n\n\nLecture code"
  },
  {
    "objectID": "2024Spring/material/session17.html#lecture-videos",
    "href": "2024Spring/material/session17.html#lecture-videos",
    "title": "üóìÔ∏è Sessions 17 & 18: Linear regresssion",
    "section": "üé• Lecture videos",
    "text": "üé• Lecture videos\nSo far, there are no learning videos available for this lecture."
  },
  {
    "objectID": "2024Spring/material/session17.html#mandatory-reading",
    "href": "2024Spring/material/session17.html#mandatory-reading",
    "title": "üóìÔ∏è Sessions 17 & 18: Linear regresssion",
    "section": "üìö Mandatory Reading",
    "text": "üìö Mandatory Reading\n\nChapter 5 in Ismay and Kim (2020).\n\n\nüèÜ Further readings\n\nChapter 3 in James et al. (2021)"
  },
  {
    "objectID": "2024Spring/material/session17.html#coursework",
    "href": "2024Spring/material/session17.html#coursework",
    "title": "üóìÔ∏è Sessions 17 & 18: Linear regresssion",
    "section": "‚úçÔ∏è Coursework",
    "text": "‚úçÔ∏è Coursework\n\nDo the exercises LinearRegression1 from the DataScienceExercises package\n\n\n\n\n\n\n\nQuick code for starting the exercises\n\n\n\n\n\n\nlearnr::run_tutorial(\n  name = \"LinearRegression1\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))"
  },
  {
    "objectID": "2024Spring/material/session19.html",
    "href": "2024Spring/material/session19.html",
    "title": "üóìÔ∏è Session 19: Recap and practice",
    "section": "",
    "text": "Possible solution to the wrangling task in the mock exam"
  },
  {
    "objectID": "2024Spring/material/timetable.html",
    "href": "2024Spring/material/timetable.html",
    "title": "Seminar timetable",
    "section": "",
    "text": "Tentative outline\n\n\n\n\n\n\nüì¢ Important change! (07.06.2024)\n\n\n\n\n\n\nüóìÔ∏èAdjusting times after sampling session!\n\n\n\n\n\n\n\n\n\n\n\n\n\n#\nDate\nDay\nTopic\n\n\n\n\n1\n14.03.24\nThu\nGeneral introduction and installation\n\n\n2\n21.03.24\nThu\nIntroducing the basics of R and R Studio\n\n\n3\n28.03.24\nThu\nBasic object types in R (learning video)\n\n\n4\n11.04.24\nThu\nAdvanced object types in R (learning video)\n\n\n5\n18.04.24\nThu\nRecap and practice\n\n\n6\n19.04.24\nFri\nRecap and practice\n\n\n7\n25.04.24\nThu\nData visualization\n\n\n8\n26.04.24\nFri\nFinish data visualization and Project Management\n\n\n9\n02.05.24\nThu\nData import (video lecture)\n\n\n10\n03.05.24\nFri\nVideo lectures on data wrangling.\n\n\nNN\n09.05.24\nThu\nNo lecture due to Christi Himmelfahrt\n\n\n11\n10.05.24\nFri\nIntroducing Quarto and R Markdown\n\n\n12\n16.05.24\nThu\nRecap and practice: Visualization & data preparation\n\n\n13\n30.05.24\nThu\nRecap and practice: explorative data analysis\n\n\nNN\n31.05.24\nFri\nCancelled\n\n\n14\n06.06.24\nThu\nIntroduction to data analysis\n\n\n15\n07.06.24\nFri\nSampling I\n\n\n16\n13.06.24\nThu\nSampling II\n\n\n17\n14.06.24\nFri\nSimple linear regression I\n\n\n18\n20.06.24\nThu\nSimple linear regression II\n\n\n19\n21.06.24\nFri\nRecap and practice\n\n\nNN\n27.06.24\nMon\nFinal exam; 14:00 ‚Äì 16:00, HEL 063\n\n\nNN\n29.08.24\nThu\nRe-take exam; 14:00 ‚Äì 16:00, HEL 063\n\n\n\nThe re-take exam is only for those who have failed the final exam."
  },
  {
    "objectID": "2024Spring/material/session12-material/session12-solutions.html",
    "href": "2024Spring/material/session12-material/session12-solutions.html",
    "title": "Possible solutions for the recap exercises",
    "section": "",
    "text": "1 Packages used\n\nlibrary(here)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(data.table)\n\n\n\n2 CO2\nWe first import the raw data. Please make sure you use the here-package and adjust the relative paths of the following code.\nSince many of the column headers were numbers (a.k.a. years), we need to make explicit that these are not values but header names. We do so by seeting the optional argument header = TRUE:\n\nco2_data_raw &lt;- fread(\"co2_raw.csv\", header = TRUE) \n\nAfter inspecting the data using functions such as str(), unique() or head(), we first remove colums we obviously do not need and that might be irritating:\n\nco2_data_tidy_1 &lt;- co2_data_raw %&gt;% \n  select(-c(\n    \"Indicator Name\", \"Indicator Code\", \n    # unique() tells you there is only one indicator\n    \"Country Code\", # Not needed\n    \"V69\" # Sometimes such erroneous columns are part of what you download\n  ))\n\nWe then move the year columns into rows by using tidyr::pivot_longer():\n\nco2_data_tidy_2 &lt;- co2_data_tidy_1 %&gt;% \n  tidyr::pivot_longer(\n    cols = -\"Country Name\", \n    names_to = \"year\", \n    values_to = \"co2_percap\") \nhead(co2_data_tidy_2)\n\n# A tibble: 6 √ó 3\n  `Country Name` year  co2_percap\n  &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;\n1 Aruba          1960          NA\n2 Aruba          1961          NA\n3 Aruba          1962          NA\n4 Aruba          1963          NA\n5 Aruba          1964          NA\n6 Aruba          1965          NA\n\n\nWe see that the year column is still a character. So me transform it into a double to then filter the years. We can also filter for the required countries within the same function call and then rename the column:\n\nco2_data_tidy_3 &lt;- co2_data_tidy_2 %&gt;% \n  mutate(year = as.double(year)) %&gt;% \n  filter(\n    year &gt;= 2000, year&lt;=2020, \n    `Country Name` %in% c(\n      \"South Africa\", \"United States\", \"Sub-Saharan Africa\", \n      \"European Union\", \"Germany\", \"China\")\n  ) %&gt;% \n  rename(country = `Country Name`)\n\nWe could have done everything in one call as well:\n\nco2_data_tidy &lt;- co2_data_raw %&gt;% \n  select(-c(\n    \"Indicator Name\", \"Indicator Code\", \n    # unique() tells you there is only one indicator\n    \"Country Code\", # Not needed\n    \"V69\" # Sometimes such erroneous columns are part of what you download\n  )) %&gt;% \n  tidyr::pivot_longer(\n    cols = -\"Country Name\", \n    names_to = \"year\", \n    values_to = \"co2_percap\") %&gt;% \n  mutate(year = as.double(year)) %&gt;% \n  filter(\n    year &gt;= 2000, year&lt;=2020, \n    `Country Name` %in% c(\n      \"South Africa\", \"United States\", \"Sub-Saharan Africa\", \n      \"European Union\", \"Germany\", \"China\")\n  ) %&gt;% \n  rename(country = `Country Name`)\n\nThen think about a useful location to store the data and do something like:\n\nfwrite(co2_data_tidy, file = here(\"data/tidy/co2_tidy.csv\"))\n\n\n\n3 Data wrangling I\nPlease make sure you use the here-package and adjust the relative paths of the following code:\nCompute, for each country, the percentage change of the spending from the year 2010 to the year 2020 and save this as a variable called perc_change.\n\neduc_exercise_data_raw &lt;- fread(\"education_income.csv\") \n\neduc_exercise_data &lt;- educ_exercise_data_raw %&gt;%\n  dplyr::select(-c(\"income\", \"GDPpc\")) %&gt;% \n  dplyr::filter(year %in% c(2010, 2020)) %&gt;% \n  tidyr::pivot_wider(\n    names_from = \"year\", \n    values_from = \"EducationSpending\"\n    ) %&gt;% \n  dplyr::mutate(\n    perc_change = ((`2020`-`2010`)/`2010`)*100\n    ) %&gt;% \n  dplyr::filter(!is.na(perc_change))\nhead(educ_exercise_data)\n\n# A tibble: 6 √ó 4\n  iso3c `2010` `2020` perc_change\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;       &lt;dbl&gt;\n1 ALB     3.41   3.34       -2.07\n2 AND     2.98   2.86       -4.05\n3 AGO     3.42   2.74      -19.8 \n4 ARG     5.02   5.28        5.18\n5 ARM     3.25   2.71      -16.7 \n6 AUS     5.54   5.61        1.27\n\n\nThen think about a useful location to store the data and do something like:\n\ndata.table::fwrite(\n  x = educ_exercise_data, \n  file = here(\"data/tidy/educ_perc_change.csv\"))\n\n\n\n4 Data wrangling II\nWe use educ_exercise_data_raw as imported above as a starting point and proceed as follows:\nCompute for each income group the average expense of education over the whole period. Make sure missing values are ignored.\nSave the new data set under a useful name in an adequate location.\n\neduc_exercise_summarized &lt;- educ_exercise_data_raw %&gt;% \n  dplyr::summarise(\n    EducExpense_avg = mean(EducationSpending, na.rm = TRUE), \n    .by = \"income\") \neduc_exercise_summarized\n\n               income EducExpense_avg\n1          Low income        3.342121\n2 Upper middle income        4.723520\n3 Lower middle income        4.534556\n4         High income        4.644050\n\n\nThen think about a useful location to store the data and do something like:\n\ndata.table::fwrite(\n  x = educ_exercise_summarized, \n  file = here(\"data/tidy/educ_perc_income-groups.csv\"))\n\n\n\n5 Visualization and Quarto\nThe quarto header should look like this:\ntitle: \"Sessions 12 and 13: Recap and Practice\"\nauthor: \"Claudius Gr√§bner-Radkowitsch\"\nformat: \n  html:\n    number-sections: true\n    table-of-contents: true\n    toc-location: body\nexecute: \n  echo: false\n  warning: false\n  message: false\n\n\n6 Visualization and Quarto\nTo read in the data set do something as the following, but make sure you are using the here-package and set the path accordingly.\n\nchild_mortality &lt;- data.table::fread(\"child_mortality.csv\")\nhead(child_mortality)\n\n    iso3c  year ChildMortality    GDPpc\n   &lt;char&gt; &lt;int&gt;          &lt;num&gt;    &lt;num&gt;\n1:    AFG  2017           64.6 2096.093\n2:    AFG  2014           73.4 2110.830\n3:    AFG  2016           67.2 2023.835\n4:    AFG  2012           80.3 1958.448\n5:    AFG  2021           55.7 1673.144\n6:    AFG  2007          100.0 1287.064\n\n\nTo summarize the data:\n\nchild_mortality_summarized &lt;- child_mortality %&gt;% \n  dplyr::summarise(\n    ChildMortality = mean(ChildMortality, na.rm = TRUE), \n    GDPpc = mean(GDPpc, na.rm = TRUE),\n    .by = \"iso3c\")\nhead(child_mortality_summarized)\n\n  iso3c ChildMortality     GDPpc\n1   AFG      88.459091  1660.568\n2   ALB      15.031818  9437.101\n3   DZA      29.486364 11735.174\n4   ASM            NaN       NaN\n5   AND       4.718182       NaN\n6   AGO     125.831818  6029.127\n\n\nWe can then directly create a simple scatter plot:\n\nggplot2::ggplot(\n  data = child_mortality_summarized, \n  mapping = aes(x = GDPpc, y = ChildMortality)\n  ) +\n  geom_point() +\n  theme_linedraw()\n\n\n\n\nWe see a clear non-linear relationship.\nWe now plot the data in logarithms. You can do this by changing the underlying data, rescale an axis, or make the change directly in the data argument of ggplot2::ggplot():\n\nggplot2::ggplot(\n  data = child_mortality_summarized, \n  mapping = aes(x = log(GDPpc), y = log(ChildMortality))\n  ) +\n  geom_point() +\n  theme_linedraw()\n\n\n\n\nThe relationship now becomes almost linear. This is typical for relationships that are exponential. We can say: an increase in GDP per capita by one percent is on average associated with a reduction of child mortality by 0.83 per cent (the latter value is given by a regression, but we come to this later)."
  },
  {
    "objectID": "2024Spring/tutorials/data-wrangling/index.html",
    "href": "2024Spring/tutorials/data-wrangling/index.html",
    "title": "Data preparation",
    "section": "",
    "text": "library(dplyr)\nlibrary(tidyr)\nlibrary(data.table)\nlibrary(here)\n\nThe data sets used in these notes are available from the course homepage:\n\nwrangling_data_raw.csv (data_raw)\nwrangling_data_raw_long.csv (data_raw_long)\nwrangling_data_final_expl.csv (data_final_expl)\nwrangling_gini_join.csv (gini_join)\nwrangling_gdp_join.csv (gdp_join)\n\nThe brackets show the names of the data sets used below."
  },
  {
    "objectID": "2024Spring/tutorials/data-wrangling/index.html#wide-and-long-format-definition",
    "href": "2024Spring/tutorials/data-wrangling/index.html#wide-and-long-format-definition",
    "title": "Data preparation",
    "section": "Wide and long format: definition",
    "text": "Wide and long format: definition\nThere is no strict definition for wide and long data. Rather, the two should be understood as relative descriptions of data, meaning that it is more straightforward to speak of a data set that is longer relative to another one, rather than a long data set per se.\nHere is an example for a rather long data set:\n\n\n   country  year variable    value\n    &lt;char&gt; &lt;int&gt;   &lt;char&gt;    &lt;num&gt;\n1: Germany  2017    unemp     3.75\n2: Germany  2017      gdp 53071.46\n3: Germany  2018    unemp     3.38\n4: Germany  2018      gdp 53431.39\n5:  Greece  2017    unemp    21.49\n6:  Greece  2017      gdp 28604.86\n7:  Greece  2018    unemp    19.29\n8:  Greece  2018      gdp 29141.17\n\n\nHere, we have one column identifying the variable, the value of which is stored in a separate column. This means that the data is relatively ‚Äòlong‚Äô in the sense of having many rows. At the same time, it is relatively ‚Äònarrow‚Äô in the sense of not having too many columns since the variable identifier is kept in a single column.\nContrast this with an example for a rather wide data set, where each variable has its own column:\n\n\n   country  year unemp      gdp\n    &lt;char&gt; &lt;int&gt; &lt;num&gt;    &lt;num&gt;\n1: Germany  2017  3.75 53071.46\n2: Germany  2018  3.38 53431.39\n3:  Greece  2017 21.49 28604.86\n4:  Greece  2018 19.29 29141.17\n\n\nWhile the number of columns remains the same, the data set has relatively more columns as compared to the rows. At the same time, it tends to be shorter in the sense of having fewer rows.1\nWhile the long format is often easier to read and preferable when communicating data to humans, making data tidy often involves the task of making data ‚Äòlonger‚Äô."
  },
  {
    "objectID": "2024Spring/tutorials/data-wrangling/index.html#transforming-long-data-into-wide-data",
    "href": "2024Spring/tutorials/data-wrangling/index.html#transforming-long-data-into-wide-data",
    "title": "Data preparation",
    "section": "Transforming long data into wide data",
    "text": "Transforming long data into wide data\nTo make data wider we use the function tidyr::pivor_wider().\nAssume that we start with our long data set introduced above and that this data set is bound to the name data_raw_long.\n\ndplyr::glimpse(data_raw_long)\n\nRows: 8\nColumns: 4\n$ country  &lt;chr&gt; \"Germany\", \"Germany\", \"Germany\", \"Germany\", \"Greece\", \"Greece‚Ä¶\n$ year     &lt;int&gt; 2017, 2017, 2018, 2018, 2017, 2017, 2018, 2018\n$ variable &lt;chr&gt; \"unemp\", \"gdp\", \"unemp\", \"gdp\", \"unemp\", \"gdp\", \"unemp\", \"gdp\"\n$ value    &lt;dbl&gt; 3.75, 53071.46, 3.38, 53431.39, 21.49, 28604.86, 19.29, 29141‚Ä¶\n\n\nWe will now use tidyr::pivor_wider() to make this data set wider. The most important arguments of this function are as follows:2\n\ndata is the first argument and refers to the name of the data set to be considered\nnames_from denotes the column that includes the names of the new columns\nvalues_from denotes the column that includes the values to be allocated in the newly created cells\n\nIn the present case, the call would look like the following:\n\ndata_raw_wide &lt;- tidyr::pivot_wider(\n  data = data_raw_long, \n  names_from = \"variable\", \n  values_from = \"value\")\ndata_raw_wide\n\n# A tibble: 4 √ó 4\n  country  year unemp    gdp\n  &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Germany  2017  3.75 53071.\n2 Germany  2018  3.38 53431.\n3 Greece   2017 21.5  28605.\n4 Greece   2018 19.3  29141."
  },
  {
    "objectID": "2024Spring/tutorials/data-wrangling/index.html#transforming-wide-data-into-long-data",
    "href": "2024Spring/tutorials/data-wrangling/index.html#transforming-wide-data-into-long-data",
    "title": "Data preparation",
    "section": "Transforming wide data into long data",
    "text": "Transforming wide data into long data\nAssume we want to take the data set data_raw_wide and re-create the original long version. To achieve this we can use tidyr::pivot_longer(). Again, lets have a look at the most important arguments:3\n\ndata is the first argument and refers to the name of the data set to be considered\ncols denotes the columns that should be transformed into the longer format\nnames_to denotes the column that includes the names of the new columns\nvalues_to denotes the column that includes the values to be allocated in the newly created cells\n\nThe arguments names_to and values_to are not strictly necessary since they have useful default values, but its usually nicer to be explicit.\nWhen specifying the argument cols you have several possibilities. The simplest variant is to pass a character vector with the column names. But note that you can save a lot of writing by using so called selection helpers, a very useful tool we will learn about later.\nIn our case this amounts to:\n\ndata_raw_long &lt;- tidyr::pivot_longer(\n  data = data_raw_wide, \n  cols = c(\"unemp\", \"gdp\"), \n  names_to = \"indicator\", \n  values_to = \"values\")\ndata_raw_long\n\n# A tibble: 8 √ó 4\n  country  year indicator   values\n  &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n1 Germany  2017 unemp         3.75\n2 Germany  2017 gdp       53071.  \n3 Germany  2018 unemp         3.38\n4 Germany  2018 gdp       53431.  \n5 Greece   2017 unemp        21.5 \n6 Greece   2017 gdp       28605.  \n7 Greece   2018 unemp        19.3 \n8 Greece   2018 gdp       29141."
  },
  {
    "objectID": "2024Spring/tutorials/data-wrangling/index.html#creating-or-manipulating-variables",
    "href": "2024Spring/tutorials/data-wrangling/index.html#creating-or-manipulating-variables",
    "title": "Data preparation",
    "section": "Creating or manipulating variables",
    "text": "Creating or manipulating variables\nThe function dplyr::mutate() is used both for manipulating existing columns as well as creating new columns. In the first case the name of the column that the result of dplyr::mutate() is written into already exists, in the second case we just use a new name.\nConsider the following data set with the unemployment rate as an example:\n\ndata_unemp\n\n# A tibble: 2 √ó 3\n   year Germany Greece\n  &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1  2017    3.75   21.5\n2  2018    3.38   19.3\n\n\nAssume we want to express the percentage values via decimal numbers and, to this end, divide the values in the columns Germany and Greece by 100. We can use dplyr::mutate() to achieve this:\n\ndata_unemp %&gt;%\n  dplyr::mutate(\n    Germany = Germany/100,\n    Greece = Greece/100\n  )\n\n# A tibble: 2 √ó 3\n   year Germany Greece\n  &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1  2017  0.0375  0.215\n2  2018  0.0338  0.193\n\n\nBut we could use basically the same code to create a new column. Assume, for instance, we want a new column containing the difference between the unemployment rates:\n\ndata_unemp %&gt;%\n  dplyr::mutate(\n    Difference = Greece - Germany\n  )\n\n# A tibble: 2 √ó 4\n   year Germany Greece Difference\n  &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1  2017    3.75   21.5       17.7\n2  2018    3.38   19.3       15.9\n\n\nThe only difference here was that the left-hand-side name of the column to be manipulated did not exist before!"
  },
  {
    "objectID": "2024Spring/tutorials/data-wrangling/index.html#filtering-rows",
    "href": "2024Spring/tutorials/data-wrangling/index.html#filtering-rows",
    "title": "Data preparation",
    "section": "Filtering rows",
    "text": "Filtering rows\nThe function dplyr::filter() can be used to filter rows according to certain conditions. The conditions must evaluate for each cell entry to either TRUE or FALSE, and only those rows for which they evaluate to TRUE remain in the data set. Often, the conditions are specified via logical operators, which were already covered in the tutorial on vector types.\nAs always, the first argument to dplyr::filter() is data, i.e.¬†the data set on which you want to operate. Then follow an arbitrary number of logical conditions on the different columns of the data set on question.\nAssume we want to take the previously defined data set data_raw_long\n\ndata_raw_long\n\n# A tibble: 8 √ó 4\n  country  year indicator   values\n  &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n1 Germany  2017 unemp         3.75\n2 Germany  2017 gdp       53071.  \n3 Germany  2018 unemp         3.38\n4 Germany  2018 gdp       53431.  \n5 Greece   2017 unemp        21.5 \n6 Greece   2017 gdp       28605.  \n7 Greece   2018 unemp        19.3 \n8 Greece   2018 gdp       29141.  \n\n\nand only want to keep data on GDP:\n\ndata_raw_long %&gt;%\n  dplyr::filter(indicator==\"gdp\")\n\n# A tibble: 4 √ó 4\n  country  year indicator values\n  &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;      &lt;dbl&gt;\n1 Germany  2017 gdp       53071.\n2 Germany  2018 gdp       53431.\n3 Greece   2017 gdp       28605.\n4 Greece   2018 gdp       29141.\n\n\nYou may also combine more than one condition in one call to dplyr::filter(). If you also want to filter by values and only keep those rows where the value is below 50.000:\n\ndata_raw_long %&gt;%\n  dplyr::filter(\n    indicator==\"gdp\",\n    values &lt; 50000)\n\n# A tibble: 2 √ó 4\n  country  year indicator values\n  &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;      &lt;dbl&gt;\n1 Greece   2017 gdp       28605.\n2 Greece   2018 gdp       29141."
  },
  {
    "objectID": "2024Spring/tutorials/data-wrangling/index.html#selecting-columns",
    "href": "2024Spring/tutorials/data-wrangling/index.html#selecting-columns",
    "title": "Data preparation",
    "section": "Selecting columns",
    "text": "Selecting columns\nWhen you only want to keep certain columns we speak of selecting (rather than filtering) columns. This is done - surprise - via the function ¬¥dplyr::select()`.\nThere are different ways for selecting columns. In any case, the first argument is, again, data, i.e.¬†the data set considered. In the present case, we will refer to data_raw:\n\ndata_raw\n\n   country  year unemp      gdp\n    &lt;char&gt; &lt;int&gt; &lt;num&gt;    &lt;num&gt;\n1: Germany  2017  3.75 53071.46\n2: Germany  2018  3.38 53431.39\n3:  Greece  2017 21.49 28604.86\n4:  Greece  2018 19.29 29141.17\n\n\nThen we can now select columns using one of the following two options. First, you may refer to columns via their name:\n\ndata_raw %&gt;%\n  dplyr::select(country, year, unemp)\n\n   country  year unemp\n    &lt;char&gt; &lt;int&gt; &lt;num&gt;\n1: Germany  2017  3.75\n2: Germany  2018  3.38\n3:  Greece  2017 21.49\n4:  Greece  2018 19.29\n\n\nBut this is often error-prone. Thus, it is usually better to refer to the columns via selection helpers, which is also the most flexible version. While we will learn about more selection helpers later, here we will mainly use dplyr::all_of(), which accepts a character vector of column names:\n\ndata_raw %&gt;%\n  dplyr::select(dplyr::all_of(c(\"country\", \"year\", \"gdp\")))\n\n   country  year      gdp\n    &lt;char&gt; &lt;int&gt;    &lt;num&gt;\n1: Germany  2017 53071.46\n2: Germany  2018 53431.39\n3:  Greece  2017 28604.86\n4:  Greece  2018 29141.17\n\n\n\nCaution: Do not forget the c()! Otherwise:\n\n\ndata_raw %&gt;%\n  dplyr::select(dplyr::all_of(\"country\", \"year\", \"gdp\"))\n\nError in `dplyr::select()`:\n‚Ñπ In argument: `dplyr::all_of(\"country\", \"year\", \"gdp\")`.\nCaused by error in `dplyr::all_of()`:\n! unused arguments (\"year\", \"gdp\")\n\n\n\nIt is also possible to define the column vector first:\n\n\ncols2keep &lt;- c(\"country\", \"year\", \"gdp\")\ndata_raw %&gt;%\n  dplyr::select(dplyr::all_of(cols2keep))\n\n   country  year      gdp\n    &lt;char&gt; &lt;int&gt;    &lt;num&gt;\n1: Germany  2017 53071.46\n2: Germany  2018 53431.39\n3:  Greece  2017 28604.86\n4:  Greece  2018 29141.17\n\n\n\nSelection helpers allow you to specify the columns to be selected more generally. For instance, dplyr::ends_with() allows you to select all colums that end with a certain pattern:\n\n\ndata_raw %&gt;%\n  dplyr::select(dplyr::ends_with(\"p\"))\n\n   unemp      gdp\n   &lt;num&gt;    &lt;num&gt;\n1:  3.75 53071.46\n2:  3.38 53431.39\n3: 21.49 28604.86\n4: 19.29 29141.17\n\n\nIn any case, you can also specify the columns you want to drop. To this end, just add a - in front of the selection command:\n\ndata_raw %&gt;%\n  dplyr::select(-unemp, -gdp)\n\n   country  year\n    &lt;char&gt; &lt;int&gt;\n1: Germany  2017\n2: Germany  2018\n3:  Greece  2017\n4:  Greece  2018"
  },
  {
    "objectID": "2024Spring/tutorials/data-wrangling/index.html#merging-data-sets",
    "href": "2024Spring/tutorials/data-wrangling/index.html#merging-data-sets",
    "title": "Data preparation",
    "section": "Merging data sets",
    "text": "Merging data sets\nOften you need to obtain data from different sources. To merge all your data in one single data set, you need to use one of the *_join() functions of the dplyr-package. These functions all merge two data sets, but the way they do it is different. Below we illustrate the most common joins (so called mutating joins).4\nAs a guiding example we use the following two data sets:\nFirst, data on income inequality from the SWIID data base:\n\ngini_join\n\n   country  year  gini\n    &lt;char&gt; &lt;int&gt; &lt;num&gt;\n1:  Greece  2015  33.1\n2:  Greece  2017  32.2\n\n\nSecond, data on GDP per capita from the World Bank:\n\ngdp_join\n\n   country  year      gdp\n    &lt;char&gt; &lt;int&gt;    &lt;num&gt;\n1: Germany  2017 53071.46\n2: Germany  2018 53431.39\n3:  Greece  2017 28604.86\n4:  Greece  2018 29141.17\n\n\nWe will consider the behavior of the following four functions:\n\ndplyr::left_join()\ndplyr::right_join()\ndplyr::full_join()\ndplyr::inner_join()\n\nAll of them accept the following arguments:\n\nx and y: the two data sets to be merged\nby: a vector or a named vector indicating on which columns the data sets should be merged\n\nIts easier to understand their behavior if you contrast them directly with each other. First, dplyr::left_join() joins the data sets on those columns mentioned in by, but only keeps those rows for which x contains an observation:\n\ndplyr::left_join(x = gdp_join, y = gini_join, by = c(\"country\", \"year\"))\n\n   country  year      gdp  gini\n    &lt;char&gt; &lt;int&gt;    &lt;num&gt; &lt;num&gt;\n1: Germany  2017 53071.46    NA\n2: Germany  2018 53431.39    NA\n3:  Greece  2017 28604.86  32.2\n4:  Greece  2018 29141.17    NA\n\n\nThis might introduce NAs into the columns of y, but not of x. It is the other way around for dplyr::right_join(): it only keeps those rows for which y contains an observation:\n\ndplyr::right_join(x = gdp_join, y = gini_join, by = c(\"country\", \"year\"))\n\n   country  year      gdp  gini\n    &lt;char&gt; &lt;int&gt;    &lt;num&gt; &lt;num&gt;\n1:  Greece  2017 28604.86  32.2\n2:  Greece  2015       NA  33.1\n\n\ndplyr::inner_join() is the most restrictive option, keeping only those rows for which both x and y contain an observation (i.e.¬†it never introduces NAs):\n\ndplyr::inner_join(x = gdp_join, y = gini_join, by = c(\"country\", \"year\"))\n\n   country  year      gdp  gini\n    &lt;char&gt; &lt;int&gt;    &lt;num&gt; &lt;num&gt;\n1:  Greece  2017 28604.86  32.2\n\n\nFinally, dplyr::full_join() contains all rows that occur at least in x or y, i.e.¬†it might introduce NAs in both the columns of x and y:\n\ndplyr::full_join(x = gdp_join, y = gini_join, by = c(\"country\", \"year\"))\n\n   country  year      gdp  gini\n    &lt;char&gt; &lt;int&gt;    &lt;num&gt; &lt;num&gt;\n1: Germany  2017 53071.46    NA\n2: Germany  2018 53431.39    NA\n3:  Greece  2017 28604.86  32.2\n4:  Greece  2018 29141.17    NA\n5:  Greece  2015       NA  33.1\n\n\nTwo final remarks: first, the types of the columns on which you merge the data sets must be equal, otherwise R throws an error:\n\ngini_join &lt;- dplyr::mutate(gini_join, year=as.character(year))\ndplyr::left_join(x = gdp_join, y = gini_join, by = c(\"country\", \"year\"))\n\nError in `dplyr::left_join()`:\n! Can't join `x$year` with `y$year` due to incompatible types.\n‚Ñπ `x$year` is a &lt;integer&gt;.\n‚Ñπ `y$year` is a &lt;character&gt;.\n\n\nJust enforce the correct data type before merging:\n\ngini_join %&gt;% \n  dplyr::mutate(year=as.integer(year)) %&gt;%\n  dplyr::left_join(x = gdp_join, y = ., by = c(\"country\", \"year\"))\n\n   country  year      gdp  gini\n    &lt;char&gt; &lt;int&gt;    &lt;num&gt; &lt;num&gt;\n1: Germany  2017 53071.46    NA\n2: Germany  2018 53431.39    NA\n3:  Greece  2017 28604.86  32.2\n4:  Greece  2018 29141.17    NA\n\n\nSecond, you can also merge on columns with different names by passing named vectors to by:\n\ngini_join &lt;- gini_join %&gt;%\n  mutate(Year=as.double(year)) %&gt;%\n  select(-year)\ngini_join\n\n   country  gini  Year\n    &lt;char&gt; &lt;num&gt; &lt;num&gt;\n1:  Greece  33.1  2015\n2:  Greece  32.2  2017\n\n\nThen this does not work any more:\n\ndplyr::left_join(\n  x = gdp_join, y = gini_join, \n  by = c(\"country\", \"year\"))\n\nError in `dplyr::left_join()`:\n! Join columns in `y` must be present in the data.\n‚úñ Problem with `year`.\n\n\nBut the named vector fixes it:\n\ndplyr::left_join(\n  x = gdp_join, y = gini_join, \n  by = c(\"country\", \"year\"=\"Year\"))\n\n   country  year      gdp  gini\n    &lt;char&gt; &lt;num&gt;    &lt;num&gt; &lt;num&gt;\n1: Germany  2017 53071.46    NA\n2: Germany  2018 53431.39    NA\n3:  Greece  2017 28604.86  32.2\n4:  Greece  2018 29141.17    NA"
  },
  {
    "objectID": "2024Spring/tutorials/data-wrangling/index.html#grouping-and-summarising-data",
    "href": "2024Spring/tutorials/data-wrangling/index.html#grouping-and-summarising-data",
    "title": "Data preparation",
    "section": "Grouping and summarising data",
    "text": "Grouping and summarising data\nThe final challenge we consider involves the application of two functions (at least in most cases): dplyr::group_by() and dplyr::summarize().\ndplyr::group_by() is usually used within pipes and groups a data set according to an arbitrary number of variables, each of which must refer to one (and only one) column. It produces a grouped data set:\n\ndata_raw_grouped &lt;- data_raw %&gt;%\n  dplyr::group_by(country)\ndata_raw_grouped\n\n# A tibble: 4 √ó 4\n# Groups:   country [2]\n  country  year unemp    gdp\n  &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Germany  2017  3.75 53071.\n2 Germany  2018  3.38 53431.\n3 Greece   2017 21.5  28605.\n4 Greece   2018 19.3  29141.\n\n\nAs you can see, the data set is now grouped by the variable country. We can specify the grouping variables the same way we selected columns in the context of dplyr::select() (see above).\nGrouped data sets are usually not interesting in itself. You can ungroup them via dplyr::ungroup():\n\ndata_raw_grouped %&gt;%\n  dplyr::ungroup()\n\n# A tibble: 4 √ó 4\n  country  year unemp    gdp\n  &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Germany  2017  3.75 53071.\n2 Germany  2018  3.38 53431.\n3 Greece   2017 21.5  28605.\n4 Greece   2018 19.3  29141.\n\n\nThey are most useful if used in conjunction with dplyr::summarise(), which summarizes variables. While it can be used without dplyr::group_by(), it is most useful if it is applied to grouped data sets: then it computes summary statistics for each group.\n\ndata_raw %&gt;%\n  summarise(\n    avg_gdp=mean(gdp)\n  )\n\n   avg_gdp\n1 41062.22\n\n\n\ndata_raw_grouped %&gt;%\n  summarise(\n    avg_gdp=mean(gdp)\n  )\n\n# A tibble: 2 √ó 2\n  country avg_gdp\n  &lt;chr&gt;     &lt;dbl&gt;\n1 Germany  53251.\n2 Greece   28873.\n\n\nYou can also summarized more than one column:\n\ndata_raw_grouped %&gt;%\n  summarise(\n    avg_gdp=mean(gdp),\n    median_unemp=median(unemp)\n  )\n\n# A tibble: 2 √ó 3\n  country avg_gdp median_unemp\n  &lt;chr&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 Germany  53251.         3.57\n2 Greece   28873.        20.4 \n\n\nNote that dplyr::summarise() drops all columns that it is not asked to compute summary statistics for, except potential grouping variables. There are also some advanced features of the functions, which are explained in the official documentation."
  },
  {
    "objectID": "2024Spring/tutorials/data-wrangling/index.html#footnotes",
    "href": "2024Spring/tutorials/data-wrangling/index.html#footnotes",
    "title": "Data preparation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf we had a data set with three instead of two variables, the wide data set would have the same number of rows, but more columns, i.e.¬†it would be wider in an absolute sense as well.‚Ü©Ô∏é\n The function allows for much more finetuning. You might read more about its argument in the help page of the function or the online documentation.‚Ü©Ô∏é\n See the online documentation for a more complete description.‚Ü©Ô∏é\n The other join types are filtering joins and nest joins. You find more information in the web, and more details on the underlying theory in chapter 13 of R4DS.‚Ü©Ô∏é\nWe have not yet covered the function ifelse(). It contains a logical test as a first argument, and then two further arguments: one return value for the case in which the test returns TRUE, and one for which the test returns FALSE.‚Ü©Ô∏é"
  },
  {
    "objectID": "2024Spring/tutorials/first-steps/index.html",
    "href": "2024Spring/tutorials/first-steps/index.html",
    "title": "First steps in R",
    "section": "",
    "text": "In this post we will learn about the basic syntax of R. The syntax basically refers to the grammatical rules you must adhere to when communicating with your computer in the language R: if you do not follow the right syntax, i.e.¬†you ‚Äòspeak‚Äô grammatically incorrect, your computer will not understand you and communicate this to you by throwing up an error message.\nTo learn about these important basics, the post follows the following structure:"
  },
  {
    "objectID": "2024Spring/tutorials/first-steps/index.html#footnotes",
    "href": "2024Spring/tutorials/first-steps/index.html#footnotes",
    "title": "First steps in R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf you do not know what the console is, you should have a look at the lecture slides from the Material section again.‚Ü©Ô∏é\nYou may try this out by typing 1:100 into your console and see what happens: this returns a vector of length 100, which certainly will contain some line breaks.‚Ü©Ô∏é\nAgain, the use of scripts has been explained in the lecture, so have a look at the slides (or the R-Studio cheat sheet) in the Material section.‚Ü©Ô∏é\nIn theory we can use &lt;- also the other way around: 2 + 3 -&gt; intermediate_result. At first sight this is more intuitive and respects the sequence of events: first, the result of 2 + 3 gets created, i.e.¬†a new object gets defined. Then, this object gets the name intermediate_result. However, the code that results from such practice is usually much more difficult to read, so it is common practice to use &lt;- rather than -&gt;.‚Ü©Ô∏é\nWickham and Bryan (2022) provide an excellent introduction to the development of R packages‚Ü©Ô∏é\nPackages not released on this platform can also be installed directly from the repository they were published, e.g.¬†Github. To this end, the package remotes must be installed first, then you can use functions such as install_github(). A short manual is provided here.‚Ü©Ô∏é"
  },
  {
    "objectID": "2024Spring/tutorials/importing-exporting-data/index.html",
    "href": "2024Spring/tutorials/importing-exporting-data/index.html",
    "title": "Importing and exporting data",
    "section": "",
    "text": "Packages used in this tutorial:\nlibrary(here)\nlibrary(data.table)\nlibrary(dplyr)"
  },
  {
    "objectID": "2024Spring/tutorials/importing-exporting-data/index.html#specify-the-column-separator-using-sep-and-the-decimal-sign-using-dec",
    "href": "2024Spring/tutorials/importing-exporting-data/index.html#specify-the-column-separator-using-sep-and-the-decimal-sign-using-dec",
    "title": "Importing and exporting data",
    "section": "Specify the column separator using sep and the decimal sign using dec",
    "text": "Specify the column separator using sep and the decimal sign using dec\nWhile the example file above represents the widespread standard case in which columns are separated by a comma and the dot is used as the decimal sign, many files use other symbols. In Germany, for instance, it is very common to use ; as a separator for columns, and , as a decimal sign instead. Thus, the ‚ÄòGerman version‚Äô of our example from above would look like this:\niso2c;year;Exporte\nAT;2012;53,97\nAT;2013;53,44\nAT;2014;53,38\nSometimes, data.table::fread() detects such cases automatically and adjusts the values for the optional arguments implicitly. But it is always better to explicit and to specify decimal signs and column separators explicitly! This also increases the reading speed of data.table::fread(). To set them explicitly, we use the arguments sep and dec as follows:\n\nexp_data &lt;- data.table::fread(\n  file = file_path,\n  sep = \";\", \n  dec = \",\"\n  )\n\nAfter completing the function call we should always inspect the imported object to make sure everything went well. We might have a look at the first lines:\n\nexp_data &lt;- tibble::as_tibble(exp_data)\nhead(exp_data, n = 2)\n\n# A tibble: 2 √ó 3\n  iso2c  year exports\n  &lt;chr&gt; &lt;int&gt;   &lt;dbl&gt;\n1 AT     2012    54.0\n2 AT     2013    53.4\n\n\nOr use dplyr::glimpse() or str():\n\nstr(exp_data)\n\ntibble [3 √ó 3] (S3: tbl_df/tbl/data.frame)\n $ iso2c  : chr [1:3] \"AT\" \"AT\" \"AT\"\n $ year   : int [1:3] 2012 2013 2014\n $ exports: num [1:3] 54 53.4 53.4\n - attr(*, \".internal.selfref\")=&lt;externalptr&gt;"
  },
  {
    "objectID": "2024Spring/tutorials/importing-exporting-data/index.html#set-the-object-type-of-the-columns-using-colclasses",
    "href": "2024Spring/tutorials/importing-exporting-data/index.html#set-the-object-type-of-the-columns-using-colclasses",
    "title": "Importing and exporting data",
    "section": "Set the object type of the columns using colClasses",
    "text": "Set the object type of the columns using colClasses\nUsually, the automatic type recognition of data.table::fread() works quite well. This means that R chooses the right data type for each column automatically. Sometimes, however, this detection fails and you need to specify the column types manually. But even if the automatic recognition works, there are some good reasons for playing save and specify the column types yourself:\n\nYou will notice more easily if there is a problem with a column, e.g.¬†if a word occurs in a column that consists exclusively of numbers. occurs. If you did not specify this column manually as double, data.table::fread() would simply interpret it silently as a character and you would later wonder later why you cannot calculate an average for the column;\nYour code will be more transparent and easier to read if one immediately knows what kind of data you are importing\nThe import process will be much faster if you provide the column types yourself and the function does not need to guess the types itself.\n\nOne situation where specifying column types yourself is extremely important is when a column contains numerical codes that might contain a leading zero, e.g.¬†when the data contain HS product codes, such as here:\ncommoditycode,complexity\n0101,0.06\n0102,-0.49\n0103,0.51\n0104,-1.12\n0105,-0.17\nAssuming the file is called exp_data_hs.csv and also is stored in data/tidy/, we might try to import it using the default argument values:\n\nfile_path &lt;- here::here(\"data/tidy/exp_data_hs.csv\")\nexp_prod_data &lt;- data.table::fread(file = file_path)\nexp_prod_data &lt;- tibble::as_tibble(exp_prod_data)\nexp_prod_data\n\n\n\n# A tibble: 5 √ó 2\n  commoditycode complexity\n          &lt;int&gt;      &lt;dbl&gt;\n1           101       0.06\n2           102      -0.49\n3           103       0.51\n4           104      -1.12\n5           105      -0.17\n\n\nAs you can see, data.table::fread() interpreted the column commoditycode as double. But since numbers do not have leading zeros, these are removed silently, meaning that R does not issue a warning message. This is dangerous and might come with serious misinterpretations later on. To avoid this, you must choose the column types yourself via the colClasses argument, by simply specifying a vector with the data types:\n\nfile_path &lt;- here::here(\"data/tidy/exp_data_hs.csv\")\nexp_prod_data &lt;- data.table::fread(\n  file = daten_pfad, colClasses = c(\"character\", \"double\")\n  )\ntibble::as_tibble(exp_prod_data)\n\n\n\n# A tibble: 5 √ó 2\n  commoditycode complexity\n  &lt;chr&gt;              &lt;dbl&gt;\n1 0101                0.06\n2 0102               -0.49\n3 0103                0.51\n4 0104               -1.12\n5 0105               -0.17\n\n\nAs you can see, encoding the column commoditycode as character preserves the leading zeros and the correct product codes.\nFor data sets with many columns it is often tedious to specify column types one by one. Here it might be useful to use the function rep(): it saves space if, for instance, 6 subsequent columns are all of type double. In this case you may just write rep(\"double\" , 6)."
  },
  {
    "objectID": "2024Spring/tutorials/importing-exporting-data/index.html#specify-how-many-rows-should-be-readskipped-using-nrows-and-skip",
    "href": "2024Spring/tutorials/importing-exporting-data/index.html#specify-how-many-rows-should-be-readskipped-using-nrows-and-skip",
    "title": "Importing and exporting data",
    "section": "Specify how many rows should be read/skipped using nrows and skip",
    "text": "Specify how many rows should be read/skipped using nrows and skip\nKeep in mind that you can increase the reading speed of data.table::fread() considerably by manually specifying the columns types. At the same time, opening very large data files in R Studio or even a text editor can slow down your computer considerably.\nThus, it is advisable to read in the first 3-5 rows, inspect them, and then read in the whole data set with the right specification for colClasses.\nYou can load only the first \\(n\\) rows by using the argument nrows:\n\nexp_data &lt;- tibble::as_tibble(data.table::fread(\n  file = here::here(\"data/tidy/exp_data.csv\"), \n  nrows = 1)\n  )\nexp_data\n\n\n\n# A tibble: 1 √ó 3\n  iso2c  year exports\n  &lt;chr&gt; &lt;int&gt;   &lt;dbl&gt;\n1 AT     2012    54.0\n\n\nIn other instances, you might also want to skip the first \\(n\\) rows. This is often the case if your file contains some general introductory header, which is placed before the actual data set. Such data with a header might look like this:\nThis is awesome data from 2012-2014\nIt was compiled be Claudius\nHe also added this useless header\niso2c,year,Exporte\nAT,2012,53.97\nAT,2013,53.44\nAT,2014,53.38\n\nIn this case, you definitely want to ignore the first three rows when importing the data set. Otherwise you will get hodgepodge:\n\nexp_data &lt;- data.table::fread(\n  file = here::here(\"data/tidy/exp_data_header.csv\")\n  )\ntibble::as_tibble(exp_data)\n\n\n\n# A tibble: 1 √ó 6\n  V1    It    was   compiled be      Claudius\n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;   \n1 He    also  added this     useless header  \n\n\nTo ignore the first three rows just set skip to 3:\n\nexp_data &lt;- tibble::as_tibble(data.table::fread(\n  file = here::here(\"data/tidy/exp_data_header.csv\"), \n  skip = 3)\n  )\nexp_data\n\n\n\n# A tibble: 3 √ó 3\n  iso2c  year Exporte\n  &lt;chr&gt; &lt;int&gt;   &lt;dbl&gt;\n1 AT     2012    54.0\n2 AT     2013    53.4\n3 AT     2014    53.4\n\n\nAgain, the automatic detection of fread() often works quite well when it comes to the identification of useless headers, but better be prepared to use skip whenever necessary."
  },
  {
    "objectID": "2024Spring/tutorials/importing-exporting-data/index.html#specify-columns-that-should-not-be-read-using-select-and-drop",
    "href": "2024Spring/tutorials/importing-exporting-data/index.html#specify-columns-that-should-not-be-read-using-select-and-drop",
    "title": "Importing and exporting data",
    "section": "Specify columns that should (not) be read using select and drop",
    "text": "Specify columns that should (not) be read using select and drop\nSometimes you only want to read in a certain selection of columns. This can also save a lot of time when working with large data sets. In the following example we only want to import the columns year and exports:\n\nexp_data &lt;- data.table::fread(\n  file = here::here(\"data/tidy/exp_data.csv\")\n  nrows = 1, \n  select = c(\"year\", \"Exporte\")\n  )\nexp_data &lt;- tibble::as_tibble(exp_data)\nexp_data\n\n\n\n# A tibble: 2 √ó 2\n   year exports\n  &lt;int&gt;   &lt;dbl&gt;\n1  2012    54.0\n2  2013    53.4\n\n\nIf you want to manually specify column types, you can do so without using colClasses by passing a named vector to select:\n\nexp_data &lt;- data.table::fread(\n  file = here::here(\"data/tidy/exp_data.csv\")\n  nrows = 1, \n  select = c(\"year\"=\"double\", \"exports\"=\"double\")\n  )\nexp_data &lt;- tibble::as_tibble(exp_data)\nexp_data\n\n\n\n# A tibble: 2 √ó 2\n   year exports\n  &lt;dbl&gt;   &lt;dbl&gt;\n1  2012    54.0\n2  2013    53.4\n\n\nAlternatively, we can also specify columns to be ignored via drop:\n\nexp_data &lt;- data.table::fread(\n  file = here::here(\"data/tidy/exp_data.csv\")\n  nrows = 1, \n  drop = \"iso2c\"\n  )\nexp_data &lt;- tibble::as_tibble(exp_data)\nexp_data\n\n\n\n# A tibble: 2 √ó 2\n   year exports\n  &lt;int&gt;   &lt;dbl&gt;\n1  2012    54.0\n2  2013    53.4"
  },
  {
    "objectID": "2024Spring/tutorials/importing-exporting-data/index.html#footnotes",
    "href": "2024Spring/tutorials/importing-exporting-data/index.html#footnotes",
    "title": "Importing and exporting data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYou can also specify alternative arguments, such as cmd when you want to parse the input file using a command line command. But we will not cover such more advanced cases here.‚Ü©Ô∏é"
  },
  {
    "objectID": "2024Spring/tutorials/installation/index.html",
    "href": "2024Spring/tutorials/installation/index.html",
    "title": "Installation of the necessary software",
    "section": "",
    "text": "During this course we will use the following software and services:\n\nR\nR-Studio\nGit\nGithub\nNetlify\n\nYou will need to install the software and register for these services on your own. While we will use one session for joint troubleshooting, it is absolutely necessary that you do your best to install the software on your own before that date. To this end, this document is meant to provide you with all the information needed. If you have questions, please use the Moodle forum. It is very unlikely that you are the only person having a particular problem. Maybe others can already help you out, and if not, all should benefit from the solution we find for your problem together.\nPlease also note that there is a separate tutorial on how to install the packages (a.k.a. R extensions) that we are going to use over the semester. Its best to continue with this tutorial on installing the required R packages directly after you have complete this one."
  },
  {
    "objectID": "2024Spring/tutorials/installation/index.html#install-r",
    "href": "2024Spring/tutorials/installation/index.html#install-r",
    "title": "Installation of the necessary software",
    "section": "Install R",
    "text": "Install R\nThe installation of R is very similar across operating systems (OS). The easiest way is to visit the R Homepage and to download the most recent version for your OS. In case you are using Mac OS and want to use Homebrew, its best to use this formula.\nImportant for Mac user: There are different versions of R for Intel chips, and Apple chips (M1, M2, etc.). It is very important that you install the correct version. If you are not sure whether your Mac contains a chip from Intel or Apple, click on the Apple symbol in the upper left of the screen, then click on About this Mac and you can see which processor your Mac is using in the new window. If you have an Apple chip, always install R for the so called arm64 architecture. Intel chip users must use the x86_64 architecture instead.\n\nOnly Windows: Install RTools\nIf you are using Windows, it is necessary to install RTools, which is required if you want to use packages written by others that are not officially released. To do so, simply visit the following website, download the installer, and install the software:\nWhen asked during the installation process, do not select the box for Add rtools to system PATH, but do select the box for Save version information to registry.\n\n\nOnly Mac: Command Line Developer Tools\nThe Command Line Developer Tools could be thought of as the Mac pendant to RTools. These allow you to build R packages from source (meaning, basically, you can use packages that are in early stages of distribution, or packages that are not released on the official R servers).\nThe easiest way to install them is to open the App Terminal, and then to type\nxcode-select --install\nand press Enter. Then a pop up window will open and allow you to install the software."
  },
  {
    "objectID": "2024Spring/tutorials/installation/index.html#update-r",
    "href": "2024Spring/tutorials/installation/index.html#update-r",
    "title": "Installation of the necessary software",
    "section": "Update R",
    "text": "Update R\nIn case R is already installed on your computer you should make sure that your version is more of less up to date. For our seminar you should use at least R version R 4.3.2. The version you are currently using is shown as soon as you start R.\nPlease note: if you installed R anew in the previous step, you do not need to update it. The information on updating R is mainly relevant for people who have installed R already some time ago.\n\nMacOS users\nFor MacOS users, the easiest route to update R is to just re-install the most current version from the R Homepage. Keep in mind that in this case you might need to re-install all previously installed packages. If you have a lot of packages installed that you want to keep, the following steps facilitates the re-installation process. First, save a list with all the packages you installed yourself. To this end type the following into the R console:1\npackage_overview &lt;- installed.packages()\npackage_names &lt;- as.vector(\n  package_overview[is.na(package_overview[,\"Priority\"]), 1])\nsave(package_names, file=\"r_packages.rda\")\nAfter re-installing R, you then need to load the file you previously saved and identify the missing packages. You can use the following code to do so if you are in the working directory in which you saved the file \"r_packages.rda\":\nload(\"r_packages.rda\")\npackages_new &lt;- installed.packages()\npackages_new_ &lt;- as.vector(packages_new[is.na(packages_new[,\"Priority\"]), 1])\nmissing_packages &lt;- setdiff(package_names, packages_new_)\ninstall.packages(missing_packages)\nupdate.packages()\n\n\nWindows users\nWindows users have a slightly more convenient route available to them: the installr package. It does not require you to re-install your packages. Just type the following code into your R console:2\ninstall.packages(\"installr\")\nlibrary(installr)\nupdateR(TRUE)\nFor more information see the package website.\n\n\nLinux users\nLinux users simply install R via their package manager. A quick search on Google should provide you with the information that are relevant for your particular Linux distribution. Updating is usually straightforward as well: just run the respective command from your package manager."
  },
  {
    "objectID": "2024Spring/tutorials/installation/index.html#r-studio",
    "href": "2024Spring/tutorials/installation/index.html#r-studio",
    "title": "Installation of the necessary software",
    "section": "R-Studio",
    "text": "R-Studio\nInstalling R-Studio is easy. The only thing you should keep in mind that you should install R first, and R-Studio second. So, after installing R got to the R-Studio download page and download the RStudio Desktop version for your OS according to the installation instructions provided.\nIf you are on Mac and you are using Homebrew you may use this formula.\nIf you want to update R-Studio, you just install it again. Please note that the minimal version for this seminar should be RStudio 2023.12.1+402, which is from late January 2024. You can check your version by clicking on RStudio in the upper left part of your screen when R-Studio is open. Then click on About RStudio."
  },
  {
    "objectID": "2024Spring/tutorials/installation/index.html#git",
    "href": "2024Spring/tutorials/installation/index.html#git",
    "title": "Installation of the necessary software",
    "section": "Git",
    "text": "Git\nInstalling Git is straightforward, but the right approach depends on your OS.\n\nMacOS\nOn MacOS you should install Git as part of the Command Line Developer Tools, which themselves are part of XCode (see above). Its easiest to run the following command from your Terminal:3\ngit --version\nIf you get an output such as git version 2.34.1 you already installed you need. If not, you will be asked to install the respective software packages (see above).\n\n\nWindows\nOn Windows you download Git for Windows from the official Webpage, which also provides you with all the relevant instructions.\n\n\nLinux\nOn Linux use you package manager. In most cases the name of the relevant package is git-all, so on Ubuntu, for instance, you would install Git via sudo apt install git-all."
  },
  {
    "objectID": "2024Spring/tutorials/installation/index.html#install-quarto",
    "href": "2024Spring/tutorials/installation/index.html#install-quarto",
    "title": "Installation of the necessary software",
    "section": "Install Quarto",
    "text": "Install Quarto\nQuarto allows you to write text and R code within one document. This is very useful in many instances, and allows you to create a wide variety of nicely looking and practically appealing outputs, including apps, websites, statistical reports, and much more. To install Quarto just follow the instructions from this webpage."
  },
  {
    "objectID": "2024Spring/tutorials/installation/index.html#github",
    "href": "2024Spring/tutorials/installation/index.html#github",
    "title": "Installation of the necessary software",
    "section": "Github",
    "text": "Github\nThis is easy. Just visit https://github.com/ and sign up using your email account."
  },
  {
    "objectID": "2024Spring/tutorials/installation/index.html#netlify",
    "href": "2024Spring/tutorials/installation/index.html#netlify",
    "title": "Installation of the necessary software",
    "section": "Netlify",
    "text": "Netlify\nThis is easy as well. Visit https://www.netlify.com/ and click on Sign up in the upper right of the webpage. You can now either create a Netlify account by clicking on Email and register a new email address, or you can link Netlify to one of the other accounts you might already have. I personally, for instance, linked Netlify to my Github account."
  },
  {
    "objectID": "2024Spring/tutorials/installation/index.html#footnotes",
    "href": "2024Spring/tutorials/installation/index.html#footnotes",
    "title": "Installation of the necessary software",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf you do not yet know what the R console is don‚Äôt worry. You will learn this during the course. But for now it would then be better to update R by just re-installing it.‚Ü©Ô∏é\nIf you do not yet know what the R console is don‚Äôt worry. You will learn this during the course. But for now it would then be better to update R by just re-installing it.‚Ü©Ô∏é\nBy this I mean that you first open the app Terminal and then enter the commend into the window that has opened, and then press Enter.‚Ü©Ô∏é"
  },
  {
    "objectID": "2024Spring/tutorials/installing-packages/index.html",
    "href": "2024Spring/tutorials/installing-packages/index.html",
    "title": "Installing R packages",
    "section": "",
    "text": "After installing R and R-Studio, you still need to install a number of so called R packages. We will learn more about what packages are and how to use them later. Nevertheless, I strongly recommend you to install already all the packages you will need over the following semester already now. This way you make sure that everything is working now, and you save yourself from trouble during the semester. Moreover, installing these packages is necessary to do the exercises provided after each session.\nTo install packages, a stable internet connection is required. Then, proceed as follows:\n\nDownload the script install_packages_script.R and save it in a directory of your choice\nOpen the file install_packages_script.R in R-Studio. To this end, right-click on the file and select Open with, and then choose R-Studio.\nAdjust the first line of the script to the OS you are using. For instance, when you are using a Mac the file should look like this:\n\n\n\n\n\n\n\n\n\n\n\n\nSelect lines 1-52 and click on the button Run (the screenshot only shows the lines 42-52, the previous lines are also selected):\n\n\n\n\n\n\n\nCheck if the package here was installed. You will get the respective message in the console:\n\n\n\n\n\n\nIf you encounter any problems, please make a screenshot and post it in the Moodle forum.\n\nSelect the rest of the scrip and run it as you did with the first lines. If you get the following message everything worked well and all packages were installed successfully:\n\n\n\n\n\n\nIf not, please post the file InstallationLog.txt and a screenshot with an error into the Moodle forum.\nNote: maybe you will see the following message during the installation process (possible multiple times):\n\n\n\n\n\nI recommend to type No and press enter. If, for any reason, the installation process is not successful you might run the installation commands again and try responding with Yes, this might sometimes fix the problem."
  },
  {
    "objectID": "2024Spring/tutorials/installing-packages/index.html#a-common-problem-when-installing-tinytex-on-a-mac",
    "href": "2024Spring/tutorials/installing-packages/index.html#a-common-problem-when-installing-tinytex-on-a-mac",
    "title": "Installing R packages",
    "section": "A common problem when installing tinytex on a Mac",
    "text": "A common problem when installing tinytex on a Mac\nThe following hints should be helpful if after the attempted installation of tinytex you see either one of these error messages:\n\n\n\n\n\n\n\n\n\n\nIn this case, execute the following comment in your R console within R-Studio:\n\ntinytex::install_tinytex(force = TRUE)\n\nThen close R-Studio and restart your computer. If test_pdf.qmd still cannot be compiled after this, please open your Mac Terminal (via the app Terminal) and enter the following commands:\nsudo chown -R `whoami`:admin /usr/local/bin\n\n~/Library/TinyTeX/bin/x86_64-darwin/tlmgr path add\nThen install tinytex again as described above, restart your computer, and try to compile test_pdf.qmd again."
  },
  {
    "objectID": "2024Spring/tutorials/mcs/index.html",
    "href": "2024Spring/tutorials/mcs/index.html",
    "title": "Monte Carlo Simulations in R",
    "section": "",
    "text": "This Tutorial explains the concept behind, and the implementation of Monte Carlo Simulations (MCS) in R. To implement MCS, we will make use of one of the following two tools: for-loops or the map-functions from the package purrr. Therefore, the tutorial also contains a general methodological section on these two approaches that you might read independently of the particular applications to MCS below. If you want to read a bit more about the topic of the tutorial, you may have a look at chapter 21 of R for Data Science.\nThis tutorial assumes you are using a typical directory structure as described in the respective tutorial. During this tutorial we will use the following packages:\nlibrary(here)\nlibrary(tidyr)\nlibrary(data.table)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(purrr)\nlibrary(icaeDesign)"
  },
  {
    "objectID": "2024Spring/tutorials/mcs/index.html#for-loops",
    "href": "2024Spring/tutorials/mcs/index.html#for-loops",
    "title": "Monte Carlo Simulations in R",
    "section": "For loops",
    "text": "For loops\nThe idea of a for-loop is to ‚Äòloop over‚Äô an object, an do something for (or on) every element in this object.\nIn general, every for-loop (should) consist of three parts:\n\nThe output container\nThe looping sequence\nThe action body\n\nBelow we is an example loop that loops through a list with three vectors as elements elements, and computes the mean for each element of the list. Before we inspect the loop as such, this is the list we are looping over:\n\nbase_list &lt;- list(\n  \"element_1\" = c(1, 4, 5, 6),\n  \"element_2\" = c(9, 2, 2, 8),\n  \"element_3\" = c(4, 3, 0, 7)\n)\n\nAnd this is how the loop looks like:\n\nresult &lt;- rep(NA, length(base_list)) # The output container\nfor (i in seq_along(base_list)) { # The looping sequence\n  result[[i]] &lt;- mean(base_list[[i]]) # The action body\n}\n\nThe first part is actually located outside the for-loop in a strict sense. But for the sake of efficiency, it is very important that you prepare a vector into which you can save the results of your loop. The vector should be of the same length as your loop will have iterations, and it is a good idea to use a vector full of NAs that are then replaced during the actual loop. Thus, the length of the output contains should equal the length of the object over which you are looping.\nThe second part is the looping sequence, and it determines the number of times your loop will iterate the task that is specified in the action body below. In the case above, we want to compute the mean for each element of base_list. In other words: we are looping over each element of base_list and the loop will comprise of three iterations.\nThe looping sequence always starts with the keyword for and an opening bracket. Then you specify a keyword that can be an (almost) arbitrary word. But usually, one uses a single letter, most commonly the letter ‚Äòi‚Äô. This letter will take a different value during each iteration of the loop. The value it takes is specified by the vector that comes after the next keyword in: in the case above, this sequence is created by seq_along(base_list):\n\nseq_along(base_list)\n\n[1] 1 2 3\n\n\nAs you can see it is an index vector, i.e.¬†a vector that starts with 1, only contains subsequent integers, and has so many elements as the object that has been passed as an argument to seq_along().\nIn the case above, this means that in the first iteration of the loop, i takes the value 1. In the second iteration it takes the value 2. And in the third and last iteration it takes the value 3. You could make this visible by writing a loop like this:\n\nfor (i in seq_along(base_list)){\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n\n\nIn principle, the keyword of your loop can take arbitrary values. For instance you could also loop over the names of base_list:\n\nfor (i in names(base_list)){\n  print(i)\n}\n\n[1] \"element_1\"\n[1] \"element_2\"\n[1] \"element_3\"\n\n\nBut this is usually not a very good idea. It is usually best to loop over an index vector of the main object of interest.\nThe third part of the loop is the action body. This is where the interesting code resides in, and where you determine what should be done during each iteration of the loop. Here, the code usually produces one result per iteration that should be allocated to the output contained created in the first step.\nIn the present case, we wanted to compute the mean for each element of the list base_list. Thus, our action body only consists of a call of the function mean, and then saves the result in the initial output container. If we then inspect the output container, we see that all the NAs were replaced by the means of the respective elements of base_list:\n\nresult &lt;- rep(NA, length(base_list)) # The output container\nprint(result) # Only contains NAs\n\n[1] NA NA NA\n\nfor (i in seq_along(base_list)) { # The looping sequence\n  result[[i]] &lt;- mean(base_list[[i]]) # The action body\n}\nprint(result) # NAs were replaced by the means\n\n[1] 4.00 5.25 3.50\n\n\nWhile the loop above was very simple, the basic concept is extremely powerful: the action body of a loop can be of arbitrary complexity, making for loops a very powerful programming tool. But caution: very complex computations take time, and iterating them many times using a for-loop can take a lot of time.\nHere are some general tips for developing for-loops:\n\nBefore writing a long loop, write a short loop that only has two or three iterations. Once you are sure that this reduced loop does what it was meant to be you can extend the looping sequence.\nWhen developing a loop, make sure that everything goes as planned by adding many print() statements into the action body; this is especially useful for your looping keyword i since this makes explicit what you are actually looping over.\nAlways loop over the indices of the object of interest, never over its elements. If you just want to iterate a task, you can loop over the indices of a simple sequence of the desired length. In any case, the looping sequence should be built by using seq_along() or seq_len().\n\nBefore proceeding with the tutorial, it might be a good idea to practice. Here are some suggestions for exercises (you find possible solutions here):\n\nWrite a for-loop that loops over the vector c(1,2,3,4,5) and computes the square root for each element.\nWrite a for loop that draws 10 numbers from a normal distribution with mean 0 and standard deviation 1. You can get a single draw by calling rnorm(1):\n\n\nrnorm(1)\n\n[1] -0.827282\n\n\n\nWrite a for-loop that loops over the columns of the following tibble, and computes the median of the elements in each column:\n\n\nex_tib &lt;- tibble::tibble(\n  \"a\" = rnorm(5, mean = 5, sd = 2),\n  \"b\" = rpois(5, lambda = 3),\n  \"c\" = rcauchy(5, location = 3, scale = 2)\n)\nex_tib\n\n# A tibble: 5 √ó 3\n      a     b     c\n  &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;\n1  6.36     2 4.61 \n2  1.79     1 2.76 \n3  5.42     3 0.994\n4  4.66     8 1.09 \n5  3.01     5 4.38"
  },
  {
    "objectID": "2024Spring/tutorials/mcs/index.html#the-map-functions-from-the-purrr-package",
    "href": "2024Spring/tutorials/mcs/index.html#the-map-functions-from-the-purrr-package",
    "title": "Monte Carlo Simulations in R",
    "section": "The map-functions from the purrr-package",
    "text": "The map-functions from the purrr-package\nThe package purrr provides a number of functions that are designed to facilitate the development of iteration tasks. To this end, they allow you to, first, think about how to accomplish what you want to do for a single element of the object of interest and then, second, simply pass your solution to a function from the map-family and let it take care of the iteration.\nThe map-family is made up of five functions, which only differ by the type of output they produce: map(), which returns output in the form of a list, as well as map_lgl(), map_int(), map_dbl(), and map_chr(), which return output in the form of an atomic vector of type logical, integer, double, and character, respectively.\nAll five functions, however, work very similarly and take the same arguments, which means: once you understood one of them you understood all of them. All take two mandatory arguments: .x and .f. The first argument, .x, specifies a vector, and the second, .f, a function that gets applied to each element of the vector.\nLets consider one of the examples above: take our list base_list and compute the mean for each of its elements. Since base_list is the object over which we want to iterate it is passed to the function via the argument .x, and since we want to compute the mean, we pass the function mean() via the argument .f. In the following case we use purrr::map(), so the result will be a list:\n\npurrr::map(.x = base_list, .f = mean)\n\n$element_1\n[1] 4\n\n$element_2\n[1] 5.25\n\n$element_3\n[1] 3.5\n\n\nIf we would like the result to be, for instance, of type double we simply use purrr::map_dbl() instead:\n\npurrr::map_dbl(.x = base_list, .f = mean)\n\nelement_1 element_2 element_3 \n     4.00      5.25      3.50 \n\n\nSometimes you want to pass a function with optional arguments to .f. The following application, for instance, does not compute the mean if there are NAs in the vectors:\n\ninput_vec &lt;- list(c(1, 4, NA, 2), c(NA, NA, 3, 0), c(9, 8, 3, 4))\npurrr::map_dbl(.x = input_vec, .f = mean)\n\n[1] NA NA  6\n\n\nTo avoid this we need to set the optional argument na.rm of mean() to TRUE:\n\npurrr::map_dbl(.x = input_vec, .f = ~mean(x = .x, na.rm=TRUE))\n\n[1] 2.333333 1.500000 6.000000\n\n\nAs you can see we added a ~ in front of the function name and then passed to the first argument of the function the object over which we want to iterate as .x. Then we can add additional arguments as desired.\nIt is now a good idea to practice the use of the map-functions. Note that the exercises are very similar to the ones from the section on for-loops above. This is because for-loops and the map-functions are geared to do the same things just in different ways (again, the solutions can be found here).\n\nCompute the square root for each element of the vector c(1,2,3,4,5) by using a map-function from purrr. In the first case, your solution should take the form of a list, in the second case an atomic vector of type character.\nDraw 10 numbers from a normal distribution with mean 2 and standard deviation 4. Again, use a map-function from purrr¬¥ and return the result  one time as an atomic vector of typedoubleand one time of typecharacter`.\nComputes the median of the elements in each column of the tibble ex_tib as defined above. The result should come in form of a list."
  },
  {
    "objectID": "2024Spring/tutorials/mcs/index.html#the-overall-workflow",
    "href": "2024Spring/tutorials/mcs/index.html#the-overall-workflow",
    "title": "Monte Carlo Simulations in R",
    "section": "The overall workflow",
    "text": "The overall workflow\nConducting a MCS always involves the following steps:\n\nDefine the random process to be analysed\nRepeat the random process many times\nSummarize the simulation results\n\nTechnically, there are two alternative ways of how to implement a MCS in R: using for-loops, or a map-function from the package purrr, as described above. The latter option is clearer and more concise, the former is more flexible and intuitive. Below we use both alternatives, so its your choice of how you are conducting your own experiments.\n\nA simple example\nWe start with a simple example that does not relate to the topic of sampling. Then we consider a more complex example and replicate the example from the lecture slides where we drew a sample from the ball pit.\nThe first example we consider is a MCS of an unfair coin. Assume we want to throw the coin many times to figure our the probability for the coin to show ‚Äòhead‚Äô.\nIn the first step we need to define the random process. In the present case this is the process of throwing a coin that shows ‚Äòhead‚Äô with a certain probability.1 To this end, we define a function that does exactly this:\n\n#' Throwing a coin\nthrow_coin &lt;- function(prob_head){\n  sample(c(\"Head\", \"Tail\"), size = 1, prob = c(prob_head, 1-prob_head))\n}\n\nIn the second case, we repeat the random process. Lets do this 1000 times, assuming that the probability for our unfair coin to show ‚Äòhead‚Äô is set to 80%. Using a for loop this would look like this:\n\niterations &lt;- 1000\nprobability_head &lt;- 0.8\noutput_container &lt;- rep(NA, iterations)\nfor (i in seq_len(iterations)){\n  output_container[i] &lt;- throw_coin(prob_head = probability_head)\n}\n\nIf we used a map-function we would write the following:\n\nmap_output &lt;- map_chr(.x = 1:iterations, ~throw_coin(prob_head = 0.8))\n\nBoth approaches accomplish the same thing. We can now summarize or visualize the results. We could do this by using quantitative indicators, but the most common and usually most illustrative way is to use a histogram. We can do this by using ggplot2::ggplot(), we only need to transform our output container into a tibble:\n\noutput_tib &lt;- tibble::tibble(map_output)\n\nggplot(data = output_tib, aes(x=map_output)) +\n  scale_y_continuous(expand = expansion(add = c(0, 40))) +\n  labs(y = \"Times observed\") +\n  geom_histogram(stat = \"count\") +\n  theme_bw() + theme(axis.title.x = element_blank())\n\n\n\n\n\n\nA more complex example from sampling\nIn this case we want to simulate the act of drawing a sample from an artificial population of a ball pid.\nThis time, the first step involves the notion of a population since it represents the drawing of sample from this population. Thus, in a very first step we need to create such a population. In our case, this is a ball pid with 5000 balls, 65 per cent of which are white and 35 per cent of which are grey:\n\nball_pid_size &lt;- 5000\nball_pid_share_white &lt;- 0.65\nwhite_balls &lt;- as.integer(ball_pid_share_white*ball_pid_size)\ngrey_balls &lt;- ball_pid_size - white_balls\nball_pid_colors &lt;- c(rep(\"white\", white_balls), rep(\"grey\", grey_balls))\n\nball_pid &lt;- tibble::tibble(\n  id = seq(1, ball_pid_size),\n  color = sample(ball_pid_colors) \n)\nhead(ball_pid, 4)\n\n# A tibble: 4 √ó 2\n     id color\n  &lt;int&gt; &lt;chr&gt;\n1     1 white\n2     2 white\n3     3 white\n4     4 white\n\n\nNow we can write a function that formalizes the act of drawing a sample from the ball pid and computing the share of white balls:\n\n#' Function that takes a sample of balls and computes share of white balls\nsample_balls &lt;- function(bowl, sample_size, replace_balls=FALSE){\n  sample_obtained &lt;- sample(x = bowl, size = sample_size, replace = replace_balls)\n  sum(sample_obtained == \"white\") / sample_size\n}\n\nWe now conduct the MCS by iterating the process of drawing such a sample 1000 times. Suppose we want to use our MCS to study the effect of taking samples of different sizes, say 20, 50, or 100. Using a for-loop this could look like this:\n\nn_samples &lt;- 1000\nresults_n20 &lt;- rep(NA, n_samples)\nresults_n50 &lt;- rep(NA, n_samples)\nresults_n100 &lt;- rep(NA, n_samples)\n\nfor (i in seq_len(n_samples)){\n  results_n20[i] &lt;- sample_balls(bowl = ball_pid$color, sample_size = 20)\n  results_n50[i] &lt;- sample_balls(bowl = ball_pid$color, sample_size = 50)\n  results_n100[i] &lt;- sample_balls(bowl = ball_pid$color, sample_size = 100)\n}\n\nresult_table &lt;- tibble(\n  sample_size20 = results_n20,\n  sample_size50 = results_n50,\n  sample_size100 = results_n100\n)\n\nA variant with a map-function would look like this:\n\nresults_n20_map &lt;- purrr::map_dbl(\n  .x = 1:n_samples, \n  .f = ~sample_balls(bowl = ball_pid$color, sample_size = 20))\n\nresults_n50_map &lt;- purrr::map_dbl(\n  .x = 1:n_samples, \n  .f = ~sample_balls(bowl = ball_pid$color, sample_size = 50))\n\nresults_n100_map &lt;- purrr::map_dbl(\n  .x = 1:n_samples, \n  .f = ~sample_balls(bowl = ball_pid$color, sample_size = 100))\n\n\nShould we create a new population for during each iteration? It depends on the question asked. If you are interested in one particular population, you should keep this population fixed over all iteration. However, if you are interested in more general results for a population that itself involves random noise, it might be appropriate the re-generate the population for each iteration of your simulation. In the cases considered here, however, we can treat the population as fixed.\n\nWe can now visualize our results using a histogram:\n\nhist_visualization &lt;- result_table %&gt;%\n  pivot_longer(cols = everything(), \n               names_to = \"Sample size\", \n               values_to = \"Share of white balls\") %&gt;%\n  mutate(\n    `Sample size` = as.integer(\n      stringr::str_remove_all(`Sample size`, \"[^0-9.-]\"))\n    ) %&gt;% \n  ggplot(data = ., aes(x=`Share of white balls`)) +\n  geom_histogram(binwidth = 0.02, fill=\"#00395B\") +\n  scale_y_continuous(expand = expansion(add = c(0, 1))) +\n  scale_x_continuous(labels = percent_format()) +\n  labs(\n    x = \"Share of white balls\", \n    y = \"Number of samples\", \n    title = \"True share: 65%\") +\n  geom_vline(xintercept = 0.65) +\n  facet_wrap(~`Sample size`, scales = \"fixed\") +\n  theme_icae() +\n  theme(\n    panel.grid.minor.x = element_blank(), \n    panel.grid.minor.y = element_blank())\n\n\nhist_visualization\n\n\n\n\nOf course, we could also illustrate the result quantitatively:\n\nresult_table %&gt;%\n  pivot_longer(cols = everything(), \n               names_to = \"Sample size\", \n               values_to = \"Share of white balls\") %&gt;%\n    mutate(\n    `Sample size` = as.integer(\n      stringr::str_remove_all(`Sample size`, \"[^0-9.-]\"))\n    ) %&gt;%\n  group_by(`Sample size`) %&gt;%\n  summarise(\n   `Mean share` = mean(`Share of white balls`),\n    `Standard deviation` = sd(`Share of white balls`)\n  )\n\n# A tibble: 3 √ó 3\n  `Sample size` `Mean share` `Standard deviation`\n          &lt;int&gt;        &lt;dbl&gt;                &lt;dbl&gt;\n1            20        0.650               0.105 \n2            50        0.651               0.0668\n3           100        0.649               0.0468"
  },
  {
    "objectID": "2024Spring/tutorials/mcs/index.html#footnotes",
    "href": "2024Spring/tutorials/mcs/index.html#footnotes",
    "title": "Monte Carlo Simulations in R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn reality such an experiment only makes sense if we do not know this probability, but here we are dealing with this situation only for the purpose of illustration.‚Ü©Ô∏é"
  },
  {
    "objectID": "2024Spring/tutorials/obj-types-i-functions/index.html",
    "href": "2024Spring/tutorials/obj-types-i-functions/index.html",
    "title": "Fundamental object types in R I: Functions",
    "section": "",
    "text": "We already learned that everything in R that exists is an object. You most likely already noted that there are different types of objects: 2, for instance, was a number, but assign was a function.1 As you might have guessed, there are many more types of objects. To understand the fundamental object types in R is an essential prerequisite to master more complicated programming challenges than those we have encountered so far. Thus, this post is among those that will introduce you to the most important object types that you will encounter in R.\nThese data types are summarized in the following figure:\n\n\n\n\n\nThis post will be about functions. Different types of vectors are covered in the upcoming posts."
  },
  {
    "objectID": "2024Spring/tutorials/obj-types-i-functions/index.html#footnotes",
    "href": "2024Spring/tutorials/obj-types-i-functions/index.html#footnotes",
    "title": "Fundamental object types in R I: Functions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn fact, we will learn below that 2 is not really a number, but a vector or length 1. Only in a next step, 2 counts as a ‚Äònumber‚Äô, or, more precisely as a ‚Äòdouble‚Äô.‚Ü©Ô∏é\nUsing return is, strictly speaking, not necessary, but I always use it for the sake of readability and transparency. An interesting debate about whether you should use return or not can be found here.‚Ü©Ô∏é\nOr, as the well-known R developer Hadley Wickham puts it: ‚ÄúYou are always coorpering with at least one other person: future-you.‚Äù‚Ü©Ô∏é"
  },
  {
    "objectID": "2024Spring/tutorials/obj-types-ii-vectors/index.html",
    "href": "2024Spring/tutorials/obj-types-ii-vectors/index.html",
    "title": "Fundamental object types in R II: Vectors",
    "section": "",
    "text": "We already learned that everything in R that exists is an object. You most likely noted that there are different types of objects: 2, for instance, was a number, but assign was a function.1 As you might have guessed, there are many more types of objects. To understand the fundamental object types in R is an essential prerequisite to master more complicated programming challenges than those we have encountered so far. Thus, this post is among those that will introduce you to the most important object types that you will encounter in R.\nThese data types are summarized in the following figure:\n\n\n\n\n\nThis post will be about the most common types of vectors. See the previous post for a treatment of functions, and the upcoming one for more advanced types of vectors, such as factor, matrix, and data.frame."
  },
  {
    "objectID": "2024Spring/tutorials/obj-types-ii-vectors/index.html#atomic-vectors",
    "href": "2024Spring/tutorials/obj-types-ii-vectors/index.html#atomic-vectors",
    "title": "Fundamental object types in R II: Vectors",
    "section": "Atomic vectors",
    "text": "Atomic vectors\nThis makes it easy to classify atomic vectors in more detail: we usually say that the type of atomic vector is the type of the object it encompasses. Four major types of atomic vectors in this sense exist:\n\nlogical (logical values): there are only two relevant logical values: TRUE und FALSE3\ninteger (whole numbers): this type should be self-explanatory. Less intuitive is the rule that in order to define an integer in R you need to type the number followed by the letter L such that R interprets the number as an integer.4 Examples are 1L, -400L or 10L.\n\ndouble (decimal numbers): these should be self-explanatory as well. Examples are 1.5, 0.0, or -500.32.\nWhole and decimal numbers are often summarized in the category numeric. However, the use of numeric is almost always confusing, and many functions show counter-intuitive behavior when this category is used. I recommend you to never use it.\ncharacter (words): these can contain all kinds of tokens and are characterized by the fact that they always start and end with \" (or '). Examples would be \"Hello\", \"500\" or \"1_2_Three\".\n\nAs indicated above, an atomic vector only comprises elements of the same type. In this context, we should mention, however, the at first sight ‚Äòstrange‚Äô data type NA, which denotes a missing value:5 whenever an element of a vector is missing, e.g.¬†when the vector is used to store observations of subjects that have participated in an experiment, and for some subjects the observation is missing, we will use NA.6\n\nTesting and coercing types\nIn the following we will study the different types of atomic vectors and their typical behavior in more detail. But before doing so we should introduce the function typeof(): it helps us to identify the type of an object in the first place. To see how, lets call the function with the object (or the name of the object) we are interested about:\n\ntypeof(2L)\n\n[1] \"integer\"\n\n\n\nx &lt;- 22.0\ntypeof(x)\n\n[1] \"double\"\n\n\nThere is also a family of functions that allows us to test whether an object is actual of a certain type or not. The general syntax here is is.*(). For instance:\n\nx &lt;- 1.0\nis.integer(x)\n\n[1] FALSE\n\n\n\nis.double(x)\n\n[1] TRUE\n\n\nThis function always returns an object of type logical:\n\ny &lt;- is.double(x)\ntypeof(y)\n\n[1] \"logical\"\n\n\nWe can also try to transform objects from one type into another. We call this process ‚Äòcoercion‚Äô an the general syntax is as.*()*. For instance:\n\nx &lt;- \"2\"\nprint(\n  typeof(x)\n)\n\n[1] \"character\"\n\nx &lt;- as.double(x)\nprint(\n  typeof(x)\n)\n\n[1] \"double\"\n\n\nSuch a transformation is, however, not always possible:\n\nas.double(\"Hello\")\n\nWarning: NAs introduced by coercion\n\n\n[1] NA\n\n\nSince R does not know how to turn the word ‚ÄòHello‚Äô into a decimal number, it transforms it into a ‚Äòmissing value‚Äô - NA.\nFor the basic types discussed above there is a logical hierarchy of feasible transformations: logical ‚Üí integer ‚Üí double ‚Üí character, meaning that you can always transform a decimal number into a word, but not vice versa.\n\nTransgression: Why change the types of objects anyway? Data types are extremely important for a programming language because otherwise it would remain unclear how mathematical operations could be applied to different objects such as numbers or words. You will transform objects yourself especially when you want to use a certain operation that is only defined for a certain type of object, and the object you are dealing with has been stored as a different type. This can happen, for example, when you read in data or translate words into numerical values yourself. If unexpected errors occur in your code with cryptic error messages, it is always a good idea to check the types of the objects used and transform them if necessary.\n\n\nx &lt;- 2\ny &lt;- as.character(x)\nprint(y)\n\n[1] \"2\"\n\nz &lt;- as.double(y) # This works\nprint(z)\n\n[1] 2\n\nk &lt;- as.double(\"Hallo\") # This does not work\n\nWarning: NAs introduced by coercion\n\nprint(k)\n\n[1] NA\n\n\nWhen transforming logical values, TRUE counts as 1 and FALSE as 0, a fact that will come in handy later on:\n\nx &lt;- TRUE\nas.integer(x)\n\n[1] 1\n\n\n\ny &lt;- FALSE\nas.integer(y)\n\n[1] 0\n\n\nSince it is not always clear when R issues a warning for transformations that are incompatible with the hierarchy just introduced and when it does not, you should always be cautious!\nMoreover, transformations might change the properties of the transformed objects implicitly in unexpected ways. For instance, a transformation from a decimal number to a whole number can lead to unexpected rounding behavior:\n\nx &lt;- 1.99\nas.integer(x)\n\n[1] 1\n\n\nAnother example is the following:\n\nz &lt;- as.logical(99)\nprint(z)\n\n[1] TRUE\n\n\nSuch implicit changes of the object properties do not necessary come with a warning message, so one should always be careful when transforming objects!\nIn many cases, functions do the necessary transformations of their arguments automatically. In most cases this is very practical:\n\nx &lt;- 1L # Integer\ny &lt;- 2.0 # Double\nz &lt;- x + y\ntypeof(z)\n\n[1] \"double\"\n\n\nBut it can be dangerous in some cases as well.\nWhen adding up logical values they are transformed to numbers:\n\nx &lt;- TRUE\ny &lt;- FALSE\nz &lt;- x + y # TRUE counts as 1, FALSE as 0\nprint(z) \n\n[1] 1\n\n\nThis is useful if you want to know, for instance, how many elements of a vector meet a certain logical criterion:\n\nx &lt;- c(1,2,3,4,5)\nsum(x &gt; 3)\n\n[1] 2\n\n\nIn all these cases it is very important to stay informed about the types of objects you are dealing with. To help you out, the following table contains an overview over the most important transformation and test functions:\n\n\n\nType\nTest\nTransformation\n\n\n\n\nlogical\nis.logical\nas.logical\n\n\ndouble\nis.double\nas.double\n\n\ninteger\nis.integer\nas.integer\n\n\ncharacter\nis.character\nas.character\n\n\nfunction\nis.function\nas.function\n\n\nNA\nis.na\nNA\n\n\nNULL\nis.null\nas.null\n\n\n\nA final remark on scalars: with scalar we usually refer to ‚Äòsingle numbers‚Äô, such as 2. There is no such concept in R: 2 is a vector with one element (or: of length 1). Thus, we do not distinguish the type of a vector with or more than one elements.\nNote: As you might have guessed already, we use the function c() to create longer vectors:\n\nx &lt;- c(1, 2, 3)\nx\n\n[1] 1 2 3\n\n\nWe can also use this function to concatenate vectors:\n\nx &lt;- 1:3 # Shortcut for: x &lt;- c(1, 2, 3)\ny &lt;- 4:6\nz &lt;- c(x, y)\nz\n\n[1] 1 2 3 4 5 6\n\n\nSince atomic vectors can only contain objects of the same type, one might expect the following code, which tries to concatenate objects of different types, to produce an error:\n\nx &lt;- c(1, \"Hallo\")\n\nBut this is not what happens! R transforms the objects according to the hierarchy discussed above:\nlogical ‚Üí integer ‚Üí double ‚Üí character. Due to the absence of errors or warning messages, such operations are a regular source for mistakes.\nNote: The length of a vector corresponds to its numbers of elements. We can ‚Äòmeasure‚Äô its length using the function length():\n\nx =  c(1, 2, 3)\nlen_x &lt;- length(x)\nlen_x\n\n[1] 3\n\n\n\nTransgression: How large can an integer become? In R, objects of type integer are stored as 32-bit files. This means that for each single integer, 32 bits of storage are available on your computer. This implies that really large numbers cannot be stored as integers, simply because the 32 bits are not sufficient:\n\n\nx &lt;- 2147483647L\ntypeof(x)\n\n[1] \"integer\"\n\n\n\ny &lt;- 2147483648L\ntypeof(y)\n\n[1] \"double\"\n\n\n\nAs you can see, the largest number that we can store as 32-bit integer is 2147483647. Larger numbers must be stored as double. The drawback of saving numbers in this type is, however, the risk of a loss of precision. If you want to avoid this you could try to save an integer as a 64 bit integer. This possibility has been added to R later to save large numbers as integers (something that happens faster than you think). To do so we must use the package7 bit64:\n\n\nz &lt;- bit64::as.integer64(2147483648)\nbit64::is.integer64(z)\n\n[1] TRUE\n\n\n\nBecause this is a data type that has been added to R later, several functions do not work with 64-bit integers if the package bit64 is not installed. Moreover, several standard functions return very irritating outputs:\n\n\ntypeof(z)\n\n[1] \"double\"\n\n\n\nFor this reason, and because bit64 is not part of the standard installation of R, you should avoid storing large numbers as integer64 whenever possible. Very large numbers should be stored as double or, when precision is a serious issue, you should scale them down and then save them as integer.\n\n\n\nLogical operations\nThe logical values TRUE and FALSE are often the result of logical operations, such as ‚ÄòIs 2 larger than 1?‚Äô. Such logical operations occur very frequently and its a good idea to familiarize yourself with the logical operators. You can find an overview in the following table:\n\n\n\nOperator\nFunction in R\nExample\n\n\n\n\nlarger\n&gt;\n2&gt;1\n\n\nsmaller\n&lt;\n2&lt;4\n\n\nequal\n==\n4==3\n\n\nlarger or equal\n&gt;=\n8&gt;=8\n\n\nsmaller or equal\n&lt;=\n5&lt;=9\n\n\nnot equal\n!=\n4!=5\n\n\nand\n&\nx&lt;90 & x&gt;55\n\n\nor\n|\nx&lt;90 | x&gt;55\n\n\neither or\nxor()\nxor(2&lt;1, 2&gt;1)\n\n\nnot\n!\n!(x==2)\n\n\nis true\nisTRUE()\nisTRUE(1&gt;2)\n\n\n\nThe result of such logical operations is always a logical value:\n\nx &lt;- 4\ny &lt;- x == 8\ntypeof(y)\n\n[1] \"logical\"\n\n\nYou may also test longer vectors:\n\nx &lt;- 1:3\nx&lt;2\n\n[1]  TRUE FALSE FALSE\n\n\nTests can also be chained:\n\nx &lt;- 1L\nx&gt;2 | x&lt;2 & (is.double(x) & x!=0)\n\n[1] FALSE\n\n\nSince many mathematical operations interpret TRUE as 1, it is easy to check how often a certain condition is met:\n\nx &lt;- 1:50 \nsmaller_20 &lt;- x&lt;20 \nprint(\n  sum(smaller_20) # How many elements are smaller then 20?\n  )\n\n[1] 19\n\nprint(\n  sum(smaller_20/length(x)) # Whats the share of these elements?\n)\n\n[1] 0.38\n\n\n\n\nVectorization\nThe chained operation we just saw is an example for vectorizing an operation. This means that the same operation is applied to many elements, all of which are concatenated as a vector. For instance, if you want to compute the square root of the numbers 5, 6 and 7 you could do:\n\nsqrt(5)\n\n[1] 2.236068\n\nsqrt(6)\n\n[1] 2.44949\n\nsqrt(7)\n\n[1] 2.645751\n\n\nOr you vectorize the operation:\n\nsqrt(c(5,6,7))\n\n[1] 2.236068 2.449490 2.645751\n\n\nVectorizing operations is very useful since it speeds up the computations considerably. Vectorized operations are far more efficient and faster than applying the operation to each element of the vector separately. Thus, whenever you need to apply a certain operation more than once you should always think about using vectorization.8\n\n\nMore on words\nWords are distinguished by the fact that their beginning and their end gets indicated by the symbol ' or \":\n\nx &lt;- \"Hello\"\ntypeof(x)\n\n[1] \"character\"\n\n\n\ny &lt;- 'Bye!'\ntypeof(y)\n\n[1] \"character\"\n\n\nJust as other kinds of atomic vectors, they can by concatenated using c():\n\nz &lt;- c(x, \"und\", y)\nz\n\n[1] \"Hello\" \"und\"   \"Bye!\" \n\n\nA useful function in this context is paste(), which transforms and combines elements of several vectors:\n\nx &lt;- 1:10\ny &lt;- paste(\"Try nb.\", x)\ny\n\n [1] \"Try nb. 1\"  \"Try nb. 2\"  \"Try nb. 3\"  \"Try nb. 4\"  \"Try nb. 5\" \n [6] \"Try nb. 6\"  \"Try nb. 7\"  \"Try nb. 8\"  \"Try nb. 9\"  \"Try nb. 10\"\n\n\nThe function paste() also accepts an optional argument sep, which allows us to specify a token that should be placed between the elements to be combined (the default is sep=\" \"):\n\nday_nr &lt;- 1:10\nx_axis &lt;- paste(\"Day\", day_nr, sep = \": \")\nx_axis\n\n [1] \"Day: 1\"  \"Day: 2\"  \"Day: 3\"  \"Day: 4\"  \"Day: 5\"  \"Day: 6\"  \"Day: 7\" \n [8] \"Day: 8\"  \"Day: 9\"  \"Day: 10\"\n\n\n\n*Note**: Here we have an example of what is called ‚Äòrecycling‚Äô. since the vector c(\"Day\") was shorter than the vector day_nr, c(\"Day\") is simply copied so that the operation with paste() makes sense. Recycling is useful, but sometimes it can be harmful, namely when you think that you are using two vectors of the same length, but this is actually not the case. In such a case recycling leads to the fact that no error message is printed and the fact that the two vectors are not of the same length remains unnoticed An example of this is the following code, in which the intention is clearly to connect all weekdays to numbers and one weekday was simply forgotten:\n\n\ndays &lt;- paste(\"Tag \", 1:7, \":\", sep=\"\")\nday_names &lt;- c(\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\")\npaste(days, day_names)\n\n[1] \"Tag 1: Monday\"    \"Tag 2: Tuesday\"   \"Tag 3: Wednesday\" \"Tag 4: Thursday\" \n[5] \"Tag 5: Friday\"    \"Tag 6: Saturday\"  \"Tag 7: Monday\"   \n\n\n\n\nMissing values and NULL\nAs indicated above, missing values are encoded as NA. This is particularly useful in statistical contexts, where are particular element of a vector cannot simply be removed if it is unavailable.\n\nExample: The vector x contains a logical value that indicates whether a person has correctly answered the question on a questionnaire. If the person did not answer the third question on the questionnaire, this should be indicated by NA. Simply omitting the value makes it impossible to determine afterwards which question the person did not answer.\n\nMost operations that get NA as an input will also give NA as an output, because it is unclear what the result of the operation would be for different values for for the missing value:\n\n5 + NA\n\n[1] NA\n\n\nThe only exception is an operation that yields a certain value completely independent from what you would substitute for NA:\n\nNA | TRUE # Always TRUE, no matter what you substitute for NA\n\n[1] TRUE\n\n\nTo test whether a vector x contains missing values you should always use the function is.na, never x==NA:\n\nx &lt;- c(NA, 5, NA, 10)\nprint(x == NA) # Unclear since not clear whether all NA must stand for the same value\n\n[1] NA NA NA NA\n\nprint(\n  is.na(x)\n)\n\n[1]  TRUE FALSE  TRUE FALSE\n\n\nWhenever an operation yields a value that cannot be defined, the result is not NA but NaN (not a number):\n\n0 / 0\n\n[1] NaN\n\n\nAnother special element is NULL. NULL is in fact a data type in itself (i.e.¬†it is not a vector), but in practice its best thought of as a vector of length zero:\n\nx &lt;- NULL\nlength(x)\n\n[1] 0\n\n\nNULL is frequently used to indicate that something does not exist. An empty vector, for instance, is NULL:\n\nx &lt;- c()\nx\n\nNULL\n\nlength(x)\n\n[1] 0\n\n\nThis is different to a vector with one (or more) missing elements:\n\ny &lt;- NA\nlength(y)\n\n[1] 1\n\n\nWhen you define your own functions, you might use NULL as the default value for optional arguments. We will learn about such more advanced strategies later in this course. For now, its best to think of NULL as an vector of length zero.\n\n\nIndexing and replacement\nWe can extract single elements of a vector using squared brackets:\n\nx &lt;- c(2,4,6)\nx[1]\n\n[1] 2\n\n\nThis also allows us to modify specific elements:\n\nx &lt;- c(2,4,6)\nx[2] &lt;- 99\nx\n\n[1]  2 99  6\n\n\nBut we can also extract more than one element:\n\nx[1:2]\n\n[1]  2 99\n\n\nNegative indices eliminate the respective elements:\n\nx[-1]\n\n[1] 99  6\n\n\nTo get the last element of a vector you might combine this idea with the function length():\n\nx[length(x)]\n\n[1] 6\n\n\n\n\nUseful functions when working with atomic vectors\nHere we shall mention a few functions that are particularly useful in the context of atomic vectors,9 especially when it comes to producing such vectors or to perform arithmetic operations with them.\nCreating atomic vectors:\nA sequence of whole numbers is something that we use very frequently. To create such sequences, the shortcut : comes in handy:\n\nx &lt;- 1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\n\ny &lt;- 10:1\ny\n\n [1] 10  9  8  7  6  5  4  3  2  1\n\n\nTo build more complex sequences we can use seq(), which in its simplest case is equivalent to ::\n\nx &lt;- seq(1, 10)\nprint(x)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nThe function seq(), however, allows for a number of useful optional arguments. For instance, by allows us to control the space between the numbers:\n\ny &lt;- seq(1, 10, by = 0.5)\nprint(y)\n\n [1]  1.0  1.5  2.0  2.5  3.0  3.5  4.0  4.5  5.0  5.5  6.0  6.5  7.0  7.5  8.0\n[16]  8.5  9.0  9.5 10.0\n\n\nIf we want to specify the desired length of the resulting vector and let R choose the necessary space between the elements, we may use length.out:\n\nz &lt;- seq(2, 8, length.out = 4)\nprint(z)\n\n[1] 2 4 6 8\n\n\nAnd if we want to create a vector with the length as another vector, the argument along.with comes in handy. This is often used for creating index vectors.10 In such a case we do not have to specify the index numbers directly:\n\nz_index &lt;- seq(along.with = z)\nprint(z_index)\n\n[1] 1 2 3 4\n\n\nAnother common task is to repeat a certain vector. This can be done with rep():\n\nx &lt;- rep(NA, 5)\nprint(x)\n\n[1] NA NA NA NA NA\n\n\nOperations\nThere are a number of operations that we use very frequently together with vectors. Often we are interested in the length of a vector. For this we can use the function length():\n\nx &lt;- c(1,2,3,4)\nlength(x)\n\n[1] 4\n\n\nIf we are looking for the largest and smallest value of a vector we can use min() and max():\n\nmin(x)\n\n[1] 1\n\n\n\nmax(x)\n\n[1] 4\n\n\nBoth functions (and many more similar functions) have the optional argument na.rm, which can be either TRUE or FALSE. In the case of TRUE, all NA values are removed before the operation gets applied:\n\ny &lt;- c(1,2,3,4,NA)\nmin(y)\n\n[1] NA\n\n\n\nmin(y, na.rm = TRUE)\n\n[1] 1\n\n\nThe mean or the variance/standard deviation of the elements can be computed with mean(), var(), and sd(), all of which have also the optional argumentna.rm:\n\nmean(x)\n\n[1] 2.5\n\n\n\nvar(y)\n\n[1] NA\n\n\n\nvar(y, na.rm = T)\n\n[1] 1.666667\n\n\nFinally, we often want to compute the sum or the product of all the elements of the vector. Here the functions sum() and prod() are useful:\n\nsum(x)\n\n[1] 10\n\n\n\nprod(y, na.rm = T)\n\n[1] 24"
  },
  {
    "objectID": "2024Spring/tutorials/obj-types-ii-vectors/index.html#lists",
    "href": "2024Spring/tutorials/obj-types-ii-vectors/index.html#lists",
    "title": "Fundamental object types in R II: Vectors",
    "section": "Lists",
    "text": "Lists\nIn contrast to atomic vectors, lists can contain objects of different types. We create lists via the function list():\n\nl_1 &lt;- list(\n  \"a\",\n  c(1,2,3),\n  FALSE\n)\ntypeof(l_1)\n\n[1] \"list\"\n\n\n\nl_1\n\n[[1]]\n[1] \"a\"\n\n[[2]]\n[1] 1 2 3\n\n[[3]]\n[1] FALSE\n\n\nLists can become very complex. The function str() (short for ‚Äústructure‚Äù) helps us to get a quick overview over a list and its elements:\n\nstr(l_1)\n\nList of 3\n $ : chr \"a\"\n $ : num [1:3] 1 2 3\n $ : logi FALSE\n\n\nWe can name the elements of lists:11\n\nl_2 &lt;- list(\n  \"first_element\" = \"a\",\n  \"second_element\" = c(1,2,3),\n  \"third_element\" = FALSE\n)\n\nWe can retrieve the names of all elements of the list with names():\n\nnames(l_2)\n\n[1] \"first_element\"  \"second_element\" \"third_element\" \n\n\nThere are two very important differences in the handling of vectors and lists:\n\nVectorization does not work for lists\nIndexing works differently\n\nThe first issue can be illustrated easily:\n\nvec_expl &lt;- c(1,2,3)\nlist_expl &lt;- list(1,2,3)\nsqrt(vec_expl)\n\n[1] 1.000000 1.414214 1.732051\n\n\nBut:\n\nsqrt(list_expl)\n\nError in sqrt(list_expl): non-numeric argument to mathematical function\n\n\nThe second issue is due to the more complex structure of lists. For vectors we extracted single elements via [. For lists, there is a difference between [ and [[. The former always returns a list:\n\nl_1[2]\n\n[[1]]\n[1] 1 2 3\n\n\nThe second then returns a vector and is more similar to the behavior of [ in the context of atomic vectors:\n\nl_1[[2]]\n\n[1] 1 2 3\n\n\nTo extract an element of this vector we can chain the brackets:\n\nl_1[[2]][3]\n\n[1] 3\n\n\nWe can also extract elements by their name:\n\nl_2[[1]]\n\n[1] \"a\"\n\n\n\nl_2[[\"first_element\"]]\n\n[1] \"a\"\n\n\nLists are fundamental to many more complex structures that we will encounter later. They are more flexible than atomic vectors, but this flexibility also makes them more difficult to use and less efficient for tasks where this flexibility is not needed. As a rule of thumb, whenever you can represent something as an atomic vector, you should do so. You should always have a good reason for using lists!"
  },
  {
    "objectID": "2024Spring/tutorials/obj-types-ii-vectors/index.html#footnotes",
    "href": "2024Spring/tutorials/obj-types-ii-vectors/index.html#footnotes",
    "title": "Fundamental object types in R II: Vectors",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn fact, we will learn below that 2 is not really a number, but a vector or length 1. Only in a next step, 2 counts as a ‚Äònumber‚Äô, or, more precisely as a ‚Äòdouble‚Äô.‚Ü©Ô∏é\nThe only object type that is of relevance to us aside these two is NULL. We will learn about it during the end of this post.‚Ü©Ô∏é\nWhile you can abbreviate the two with T and F, respectively, I recommend against using these sometimes ambiguous abbreviations.‚Ü©Ô∏é\nThis syntax has historical reasons: when the type integer was introduced in R, the developers were guided by the type long integer of the programming language C. In C the suffix for such an integer was ‚Äòl‚Äô or ‚ÄòL‚Äô. The R developers just transferred this practice into R, only they did not use ‚Äòi‚Äô to avoid a possible confusion between ‚Äòl‚Äô and ‚Äòi‚Äô, which look very similar in many fonts (the suffix ‚Äòi‚Äô in R is used for the imaginary component of complex numbers).‚Ü©Ô∏é\nIn principle there are different kinds of missing values, such as NA_integer_ or NA_character_, but they are irrelevant in practice: any NA value in an atomic vector automatically ‚Äòmimics‚Äô the type of the atomic vector.‚Ü©Ô∏é\nNULL on the other hand, is used to represent an absent vector, not an absent element of a vector. We will come back to NULL during the end of the post.‚Ü©Ô∏é\nIf you are not sure what a package is, recap the last chapter of the post on first steps in R.‚Ü©Ô∏é\nWe learn more about this later in the course when delving into the topic of iteration.‚Ü©Ô∏é\nFor many common tasks there is already a predefined function in R. The easiest way to find them is by googling‚Ü©Ô∏é\nAn index vector x to any vector y with N elements contains the integers from 1 to N. The nth value of x thus corresponds to the index of the nth value of y.‚Ü©Ô∏é\nWe can actually also do this with vectors, but it is more common in the context of lists.‚Ü©Ô∏é"
  },
  {
    "objectID": "2024Spring/tutorials/obj-types-iii-adv/index.html",
    "href": "2024Spring/tutorials/obj-types-iii-adv/index.html",
    "title": "Fundamental object types in R III: Factors and data frames",
    "section": "",
    "text": "In the previous posts you learned about the most important fundamental data types in R. The types we will learn about below and not less important, but less fundamental. This means they are built by taking one of the base types we encountered before, and ‚Äòadding some features‚Äô. These features change the behavior of the type, e.g.m how it is printed or how it is affected by certain function calls, but also what kind of operations it allows.1\nThis process of ‚Äòadding features‚Äô is usually done by adding ‚Äòattributes‚Äô to an object. In principle, you can add attributes to any objects without much effect by using the attr() function:\n\nx &lt;- 2.0\nattr(x, \"Mood\") &lt;- \"Haha!\"\n\nTo retrieve attributes use attributes():\n\nattributes(x)\n\n$Mood\n[1] \"Haha!\"\n\n\nSometimes, adding attributes of a particular name have more relevant implications. One useful way to use attributes, for instance, is to name the single elements of vectors, something that changes the way the objects are printed and something that we already discussed in the context of lists:\n\ny &lt;- c(1, 2, 3)\nattr(y, \"names\") &lt;- c(\"First\", \"Second\", \"Third\")\ny\n\n First Second  Third \n     1      2      3 \n\n\n\nattributes(y)\n\n$names\n[1] \"First\"  \"Second\" \"Third\" \n\n\nNow we can call elements by their name:\n\ny[\"Second\"]\n\nSecond \n     2 \n\n\nBut things become really interesting if you add an attribute called class: this really transforms the data types into a new, less fundamental type. In fact, this is how the types we discuss below, are created: smart people added, among other things, a class attribute to a more fundamental data type (integer in the case of factors and list in the case of data.frames). The art of writing new classes is part of object oriented programming, an advanced concept that we do not cover in this course (and, to be honest, one of the areas where R is not particularly well designed).\nOne implication of this ‚Äòless fundamental‚Äô nature of the objects we encounter below is that typeof() usually returns the base type. For instance, below we will learn about the factor, a type that is built upon integer. If we call typeof() on a factor, it will return the fundamental type, i.e.¬†integer:\n\nxx &lt;- factor(c(1,2))\ntypeof(xx)\n\n[1] \"integer\"\n\n\nFortunately, the standard test functions (is.*()) usually work, so you can use is.factor():\n\nis.factor(xx)\n\n[1] TRUE\n\n\nAlternatively, you can always inspect that attributes of the object to find out about its class:\n\nattributes(xx)\n\n$levels\n[1] \"1\" \"2\"\n\n$class\n[1] \"factor\"\n\n\nAll this can be confusing at first, so it is important to keep it in mind. Once you wrapped your head upon this, many confusing behaviors suddenly start to make sense, e.g.¬†that mutating factors within a data.frame can result in whole numbers, a phenomenon we will discuss in the context of data wrangling later."
  },
  {
    "objectID": "2024Spring/tutorials/obj-types-iii-adv/index.html#footnotes",
    "href": "2024Spring/tutorials/obj-types-iii-adv/index.html#footnotes",
    "title": "Fundamental object types in R III: Factors and data frames",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn fact, some new types allow you to do less than the original type, i.e.¬†here the new features are restrictions. The tibble we will encounter below is such an example.‚Ü©Ô∏é\nIf you read the section on attributes above: matrices are objects that were given a new attribute dim.‚Ü©Ô∏é\nThis is another piece of evidence for the very confusing class concept and object-orientated style of R. See this chapter for more details, in case you are interested.‚Ü©Ô∏é"
  },
  {
    "objectID": "2024Spring/tutorials/setting-up-an-r-project/index.html",
    "href": "2024Spring/tutorials/setting-up-an-r-project/index.html",
    "title": "Setting up an R project",
    "section": "",
    "text": "This post is about how you set up an adequate project environment. By this I mean the folders you should create, and how you should save your files. The structure introduced here will help you to keep your project structured and to keep an overview about your work, but also to make it easier to share your project with others.\nIn all, whenever you start a new programming project you should set up the infrastructure described below. Such project could be a term paper, a research endeavor, or just the code to create some visualizations. Later you might find that some aspects of the infrastructure below feel like a bit of an overkill, especially for very small undertakings. But especially in the beginning its better to be save than sorry and to set up the whole project as described below.\nIn all, setting up a good working environment includes the following steps:\n\nFind a good place for the project on your computer.\nCreate a directory with an R project\nCreate the relevant sub-directories\n\nThen you should always familiarize yourself with how to use the here-package with your project.\nThere are some additional steps one might to take, such as initiating a Git repository or setting up a renv environment . Moreover, for larger projects you might also want to add a README.md. But for now the steps mentioned above are sufficient. But before going through them one by one, we need to clarify two important technical concepts:\n\nthe concept of a working directory and\nthe distinction between absolute and relative paths"
  },
  {
    "objectID": "2024Spring/tutorials/setting-up-an-r-project/index.html#footnotes",
    "href": "2024Spring/tutorials/setting-up-an-r-project/index.html#footnotes",
    "title": "Setting up an R project",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWe could also have created a folder in the previous step and then chosen this folder here via Existing directory. This is useful if you want to add an R project file to an already existing project, but the approach of creating a new directory is more general and should be your default approach.‚Ü©Ô∏é\nWith R Markdown you can write texts directly in R. This allows you to keep statistical analysis and the description of the results in one document. This homepage, for example, was also written entirely in R Markdown. You will learn how to use R-Markdown soon.‚Ü©Ô∏é"
  },
  {
    "objectID": "2024Spring/tutorials/using-exercises/index.html",
    "href": "2024Spring/tutorials/using-exercises/index.html",
    "title": "Using exercises",
    "section": "",
    "text": "When learning a programming language, applying the new concepts regularly is absolutely essential. Without regular practice it is hard to impossible to remember everything you need to actually enjoy working with R.\nTherefore, I prepared a small set of exercises for each session that I recommend you to do after the session. This will help you to remember what you have learned and to find out what you did not understand well. I then urge you to post your problems on Moodle, to ask your colleagues and to help each other out. This will be a great boost to your learning progress: explaining something to others is not only great in a normative sense, it also helps you to get a deeper understanding of the concepts yourself.\nIn this short post I quickly explain how you can use the exercises that I have prepared for you. For those of you interested in the underlying mechanics: all exercises were prepared using the package learnr together with the gradethis package, and are distributed in the package DataScienceExercises.\nTo use the exercises you must have installed the packages learnr, gradethis and DataScienceExercises. If you followed the instructions in the tutorial on installing R packages this should be the case. If for some reasons you need to install them, you can do this via:\n\npack_names &lt;- c(\n  \"rstudio/learnr\",\n  \"rstudio/gradethis\",\n  \"graebnerc/DataScienceExercises\"\n)\nremotes::install_github(\n  repo = pack_names, upgrade = \"always\")\n\nNote that this requires a previous installation of the package remotes:\n\ninstall.packages(\"remotes\")\n\nSince I update the exercises according to your feedback, and add new exercises over the semester, I strongly recommend you to update the package DataScienceExercises each time before you start practicing. To do so you need an internet connection. If you just want to do the exercises without updating the package, an internet connection is not required: the exercises themselves also work offline.\nTo update the package, simply type the following into the console and press Enter:\n\nremotes::install_github(\n  repo = \"graebnerc/DataScienceExercises\", upgrade = \"always\")\n\nThis should update your package version to the most recent release.\nIf you want to start an exercise you first need to figure out the name of the exercise sheet. This is provided in the Material section of the course webpage. Then you call execute the following code via the console in R Studio, replacing ‚ÄòEX_NAME‚Äô with the name of the exercise sheet:\n\nlearnr::run_tutorial(\n  name = \"EX_NAME\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))\n\nThe first exercise sheet, for instance, is called Basics. Thus, to call it execute the following:\n\nlearnr::run_tutorial(\n  name = \"Basics\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))\n\nLastly, if you encounter a bug or a mistake, or have an idea for a good exercise, please let me know via the issue tracker of the DataScienceExercises package or via Moodle. Thank you!"
  },
  {
    "objectID": "2024Spring/tutorials/visualization/index.html",
    "href": "2024Spring/tutorials/visualization/index.html",
    "title": "Visualization",
    "section": "",
    "text": "Packages used\n\nlibrary(DataScienceExercises)\nlibrary(ggplot2)\n\n\n\nDeveloping a ggplot - the general workflow\nMake a shortcut to the data and inspect it:\n\ngdp_data &lt;- DataScienceExercises::gdplifexp2007\nhead(gdp_data, 3)\n\n        country continent lifeExp        pop gdpPercap\n1         China      Asia  72.961 1318683096  4959.115\n2         India      Asia  64.698 1110396331  2452.210\n3 United States  Americas  78.242  301139947 42951.653\n\n\nPlots in ggplot2 are created layer by layer. We now go through each step that, in the end, will produce the following plot:\n\n\n\n\n\nWe start by creating the basic ggplot2 object, which is best thought of as a fancy list. To this end we use the function ggplot2::ggplot()\n\ngdp_plot &lt;- ggplot2::ggplot()\ntypeof(gdp_plot)\n\n[1] \"list\"\n\n\nWhen we call this list, the plot described by it gets rendered:\n\ngdp_plot\n\n\n\n\nOf, course, there is no plot since the list is basically empty. All the specifications in the ggplot2::ggplot() function are best thought of as default values. In our case we fist specify the data set we use for our plot:\n\ngdp_plot &lt;- ggplot2::ggplot(\n  data = gdp_data\n)\n\nBut this alone does not do anything good. We also need to inform ggplot2 on how it should map the variables from the data set onto the plot. In a first step, lets clarify that the variable gdpPercap should be mapped on the x-axis and the variable lifeExp on the y-axis.\nThis is done via the argument mapping and the function ggplot2::aes(), which takes as arguments the aesthetics of the plot and the variable names that should be plotted on them:\n\ngdp_plot &lt;- ggplot2::ggplot(\n  data = gdp_data, \n  mapping = ggplot2::aes(\n    x = gdpPercap,\n    y = lifeExp\n  )\n)\ngdp_plot\n\n\n\n\nThis looks better. Note that ggplot2 chooses a default range for the axes based on the range of the variables in the underlying data set:\n\nmin(gdp_data$lifeExp); max(gdp_data$lifeExp)\n\n[1] 39.613\n\n\n[1] 82.603\n\nmin(gdp_data$gdpPercap); max(gdp_data$gdpPercap)\n\n[1] 277.5519\n\n\n[1] 49357.19\n\n\nWe now want to add an additional layer with data points on our plot. Poits are so called geom: a certain geometrical object representing data points. The function to add points is called ggplot2::geom_point() amd we literally just add it to our plot:\n\ngdp_plot &lt;- gdp_plot + geom_point()\ngdp_plot\n\n\n\n\nThis already reveals much of the general workflow involved in creating a plot: define a raw object and add and refine layers. Looking at the plot above, one thing that is missing is that the dots are filled in different colors, representing the continents of the countries, and the size of the dots represent the population size of the countries.\nTo achieve this we need to map the variable continent from the data set to the aesthetic color in the plot, and the variable pop to the aesthetic size:\n\ngdp_plot &lt;- ggplot2::ggplot(\n  data = gdp_data, \n  mapping = ggplot2::aes(\n    x = gdpPercap,\n    y = lifeExp,\n    size = pop, \n    color = continent\n    )\n  ) +\n  ggplot2::geom_point()\ngdp_plot\n\n\n\n\nWhat is not so nice is that the points are partly overlapping and bigger points might conceal smaller points below them. To address this problem we might make the plots a bit transparent. Since this is not a mapping from a variable from the data set to an aesthetic, but a general setting that should apply to all points equally, we do not specify it via the argument aes, but via the parameter responsible for transparency directly. This parameter is called alpha and we can set it for the affected geom directly:\n\ngdp_plot &lt;- ggplot2::ggplot(\n  data = gdp_data, \n  mapping = ggplot2::aes(\n    x = gdpPercap,\n    y = lifeExp,\n    size = pop, \n    color = continent\n    )\n  ) +\n  ggplot2::geom_point(alpha=0.5)\ngdp_plot\n\n\n\n\nBut now there is the danger for points to ‚Äòmelt into each other‚Äô. Better have their circle in black, and only color their interior. We can do so by replacing color in the aesthetics with fill, and set the color explicitly to 'black'. However, this distinction between circle color and fill color is not available for all kind of point shapes. You need to search the internet for a shape that supports this distinction. If you looked, for instance, here you found that they shape with index 21 allows this:\n\ngdp_plot &lt;- ggplot2::ggplot(\n  data = gdp_data, \n  mapping = ggplot2::aes(\n    x = gdpPercap,\n    y = lifeExp,\n    size = pop, \n    fill = continent\n    )\n  ) +\n  ggplot2::geom_point(\n    shape=21, color=\"black\", alpha=0.5)\ngdp_plot\n\n\n\n\nProgress cannot be denied! Now lets fix the labels and annotations of the plot. Here, the function ggplot2::labs() comes in handy. It accepts arguments such as title, subtitle, captio, and several more. The help() function gives further information about the possibilities.\nIn our case we want to add a title, specify the x and y axis, and add a caption:\n\ngdp_plot &lt;- gdp_plot +\n  ggplot2::labs(\n    title = \"Life expectancy and income per capita\", \n    caption = \"Note: size of bubbles represents population. Data: Gapminder\",\n    x = \"GDP per capita (int. Dollar)\",\n    y = \"Life expectancy in years\"\n  )\ngdp_plot\n\n\n\n\nSo far, so good. The x-axis is a bit clumsy, though. It would be better to scale the number down so that it shows 1000 dollars. The scale properties of the axes can be defined by the functions scale_*_**(), where the first * should be replaced by the aesthetic we want to adjust, and the second by a keyword indicating whether the variable is discrete or continuous, or whether we want to provide fully manual specifications. In our case we are interested in changing the x-axis, which represents a continuous variable (GDP). Thus we call scale_x_continuous(). Since we want to change the labels on the axis we specify the argument labels. To scale the labels we make use of a function from the scales-package: scales::number_format(). And to make this clear on the axis we add the suffix ‚Äòk‚Äô:\n\ngdp_plot &lt;- gdp_plot +\n  ggplot2::scale_x_continuous(\n    labels = scales::number_format(scale = 0.001, suffix = \"k\")\n    )\ngdp_plot\n\n\n\n\nNow lets turn to the legends. First of all we want to remove the legend for the bubble size since, first, the mapping of the bubble size is not straightforward to understand and, second, we already indicated that the bubble size represents population in the caption of the plot. There are several ways to to this: either we use the scale_*_*() function we already encountered with the argument guide=\"none\":\n\ngdp_plot + ggplot2::scale_size_continuous(guide = \"none\")\n\nOr we use a function that allows us to specify all kinds of legend properties: ggplot2::guides(). Here we take the aesthetic name as an argument and set it to ¬¥‚Äúnone‚Äù`:\n\ngdp_plot &lt;- gdp_plot + ggplot2::guides(size = \"none\")\ngdp_plot\n\n\n\n\nThe advantage of using ggplot2::scale_size_continuous() would be that we could strech the limits a bit to make the differences more straightforward to see:\n\ngdp_plot &lt;- gdp_plot + \n  ggplot2::scale_size_continuous(\n    guide = \"none\", \n    range = c(0.1, 24)\n    )\n\nNow we want to put the remaining legend to the bottom of the plot. Again, there are several ways to achieve this, but for such specific changes the function ggplot2::theme() is usually a good option. It allows us to change almost everything on a plot. The argument to place legends at the bottom is legend.position and already hints at the internal logic of theme(), which you might explore through the help() function yourself:\n\ngdp_plot &lt;- gdp_plot +\n  ggplot2::theme(legend.position = \"bottom\")\ngdp_plot\n\n\n\n\nSince the theme() function is so extensive there are also many pre-defined themes for plots, which are best explored in the internet. A good default one is the black-and-white theme, which we can use via ggplot2::theme_bw():\n\ngdp_plot &lt;- gdp_plot +\n  ggplot2::theme_bw()\ngdp_plot\n\n\n\n\nOups, while everything looks nicer, some of our previous changes, such as moving the legend to the bottom and removing its title were overwritten! It, thus, makes always sense to first call the default theme, and then make further changes via ggplot::theme().\nOf course, we can then also make further adjustments to the theme, e.g.¬† by removing the panel of the plot. Removing elements of the plot via ggplot2::theme() requires us to set these elements via the function ggplot2::element_blank():\n\ngdp_plot &lt;- gdp_plot +\n  ggplot2::theme_bw() +\n  theme(\n    legend.position = \"bottom\",\n    panel.border = ggplot2::element_blank()\n  )\ngdp_plot\n\n\n\n\nHm, but it would indeed be a bit nicer to keep the axis lines of the x- and y-axis. Lets do this by specifying them explicitly via ggplot2::element_line(), which again allows for endless specification details:\n\ngdp_plot &lt;- gdp_plot +\n  ggplot2::theme(\n    axis.line = ggplot2::element_line(colour = \"grey\"))\ngdp_plot\n\n\n\n\nIts time to get picky! The ticks of the values should have the same color as the axis lines!!!\n\ngdp_plot &lt;- gdp_plot +\n  ggplot2::theme(\n    axis.ticks = ggplot2::element_line(colour = \"grey\"))\ngdp_plot\n\n\n\n\nOkay, you should get the general idea. What is more worrisome, to be honest, is the ugly title of the legend. Away with it!\n\ngdp_plot &lt;- gdp_plot +\n  ggplot2::theme(legend.title = ggplot2::element_blank())\ngdp_plot\n\n\n\n\nSo, the only thing that distinguishes our plot from the initial example is the color pallette. There are many different pallettes available, you can search for your favorite one in the internet. Here we use one provided by the package RColorBrewer, which can be used for the fill-aesthetic direclty:\n\ngdp_plot &lt;- gdp_plot +\n  ggplot2::scale_fill_brewer(palette = \"Dark2\")\ngdp_plot\n\n\n\n\nThats it! This was, of course, only a tiny glimpse on what you can achieve using ggplot2, but it should suffice for the start. Moreover, what is more important, you learned about the general workflow when developing a plot: start with creating a list with ¬¥ggplot2::ggplot()` and then adjust your plot layer by layer until you are satisfied.\nHere is the whole code we used for the figure:\n\ngdp_plot &lt;- ggplot2::ggplot(\n  data = gdp_data, \n  mapping = ggplot2::aes(\n    x = gdpPercap,\n    y = lifeExp,\n    size = pop, \n    fill = continent\n  )\n) +\n  ggplot2::geom_point(\n    shape=21, color=\"black\", alpha=0.5) +\n  ggplot2::labs(\n    title = \"Life expectancy and income per capita\", \n    caption = \"Note: size of bubbles represents population. Data: Gapminder\",\n    x = \"GDP per capita (int. Dollar)\",\n    y = \"Life expectancy in years\"\n  ) +\n  ggplot2::scale_x_continuous(\n    labels = scales::number_format(scale = 0.001, suffix = \"k\")\n  ) + \n  ggplot2::scale_size_continuous(\n    guide = \"none\", \n    range = c(0.1, 24)\n  ) +\n  ggplot2::scale_fill_brewer(\n    palette = \"Dark2\"\n    ) +\n  ggplot2::theme_bw() +\n  ggplot2::theme(\n    legend.position = \"bottom\",\n    legend.title = ggplot2::element_blank(),\n    panel.border = ggplot2::element_blank(),\n    axis.line = ggplot2::element_line(colour = \"grey\"),\n    axis.ticks = ggplot2::element_line(colour = \"grey\")\n  )\n\nOf course, for simple exploratory analysis, you do not need so many details as we just did, but for publication purposes its good to know how far you can get!\nAnother great thing is that the syntax remains largely the same, no matter whether you want to make a scatter plot as above, or a line graph or a histogram. All that changes is the particular geom_*() function used.\n\n\nAn alternativ line plot\nTo illustrate the similarities of the code used for a different plot type, we will now use a data set that is very similar to the one used previously, only this time we have observations for GDP per capita and life expectancy for several years, aggregated for the different continents. The data set is gain made available via the package DataScienceExercises:\n\ngdp_data_agg &lt;- DataScienceExercises::aggGDPlifexp\n\nAgain, we first inspect the data to get a feeling about the variables that are present:\n\nhead(gdp_data_agg, 3)\n\n# A tibble: 3 √ó 5\n  continent  year lifeExp      pop gdpPercap\n  &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 Africa     1952    39.1 4570010.     1253.\n2 Africa     1957    41.3 5093033.     1385.\n3 Africa     1962    43.3 5702247.     1598.\n\n\nLets plot the dynamics of GDP per capita over time for the different continents. We can now simply copy-paste a lot of the code we have used before. Lets start with the uncontroversial beginning and just replace the name of the data set and the variable names:\n\ngdp_dyn_plot &lt;- ggplot2::ggplot(\n  data = gdp_data_agg, # &lt;- Replaced \n  mapping = ggplot2::aes(\n    x = year, # &lt;- Replaced \n    y = gdpPercap, # &lt;- Replaced \n    color = continent#, \n    #fill = continent # &lt;- Not necessary \n  )\n) +\n  ggplot2::geom_point() \ngdp_dyn_plot\n\n\n\n\nThis is not so bad! But it would be nice to add an additional geom that connects the dots with lines. No problem, simply add ggplot2::geom_line() to the plot:\n\ngdp_dyn_plot &lt;- gdp_dyn_plot +\n  geom_line()\ngdp_dyn_plot\n\n\n\n\nMuch of the code above only requires slight adjustments: the scaling of the x-axis should now be applied to the y-axis so we change ggplot2::scale_x_continuous() into ggplot2::scale_y_continuous(). Moreover, colors should change not for the fill but the color aesthetic, so ggplot2::scale_fill_brewer() becomes ggplot2::scale_color_brewer():\n\ngdp_dyn_plot &lt;- gdp_dyn_plot +\n  ggplot2::scale_y_continuous(\n    labels = scales::number_format(scale = 0.001, suffix = \"k\")\n  ) + \n  ggplot2::scale_color_brewer(\n    palette = \"Dark2\"\n    )\ngdp_dyn_plot\n\n\n\n\nAside from this, we can pretty much re-use almost the entire code from above with which we adjusted the legend, the labels, as well as the overall theme, only we can be so bold to remove the title of the x-axis via axis.title.x = ggplot2::element_blank(). Moreover, since we do not map the population size, ggplot2::scale_size_continuous() can now be removed, resulting in:\n\ngdp_dyn_plot &lt;- gdp_dyn_plot +\n  labs(\n    title = \"The divergence of income per capita\", \n    caption = \"Note: country data averaged over continants. Data: Gapminder\",\n    y = \"GDP per capita (int. Dollar)\"\n  ) +\n  ggplot2::theme_bw() +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = ggplot2::element_blank(),\n    panel.border = ggplot2::element_blank(),\n    axis.line = ggplot2::element_line(colour = \"grey\"),\n    axis.ticks = ggplot2::element_line(colour = \"grey\"),\n    axis.title.x = ggplot2::element_blank()\n  )\ngdp_dyn_plot\n\n\n\n\nAgain, a very nice plot - and much faster to complete than the first one, thanks to the amazingly consistent syntax of ggplot2:)\n\n\nSaving your plot\nYou can save your plot using the function ggplot2::ggsave(). The function saves, by default, the last plot you created, but it is better to specify the plot you want to save directly. Other important arguments are the file name (which also determines the format), and the size:\n\nggplot2::ggsave(\n  plot = gdp_plot, \n  filename = \"gdp_plot.pdf\", \n  width = 6, height = 4.2)"
  },
  {
    "objectID": "2024Spring/exercises/multiple-regression/index.html",
    "href": "2024Spring/exercises/multiple-regression/index.html",
    "title": "Exercises on multiple linear regression",
    "section": "",
    "text": "Read in the data set coffee_data.csv.\nIt contains the following variables:\n\nCoffeePrice: The world market price for coffee from Brazil in EUR per kilo\nCoffeeDemand: The demand for coffee from Brazil in tons\nCoffeeSeller: The kind of coffee company: Standard or FairTrade\n\nIn the following, treat CoffeeDemand as the dependent variable, and CoffeePrice and CoffeeSeller as the independent variables.\nEstimate a parallel slopes model, and an interaction model. Which of the models would you prefer?\nYou should justify your choice using two main arguments.\n\n\n\nRead in the data set ice_data.csv. What kind of relationships could you reasonably study in a linear regression framework (without further data transformation).\n\n\n\nThe solutions to both exercises can be found here."
  },
  {
    "objectID": "2024Spring/exercises/multiple-regression/index.html#studying-coffee-data",
    "href": "2024Spring/exercises/multiple-regression/index.html#studying-coffee-data",
    "title": "Exercises on multiple linear regression",
    "section": "",
    "text": "Read in the data set coffee_data.csv.\nIt contains the following variables:\n\nCoffeePrice: The world market price for coffee from Brazil in EUR per kilo\nCoffeeDemand: The demand for coffee from Brazil in tons\nCoffeeSeller: The kind of coffee company: Standard or FairTrade\n\nIn the following, treat CoffeeDemand as the dependent variable, and CoffeePrice and CoffeeSeller as the independent variables.\nEstimate a parallel slopes model, and an interaction model. Which of the models would you prefer?\nYou should justify your choice using two main arguments."
  },
  {
    "objectID": "2024Spring/exercises/multiple-regression/index.html#exploring-feasible-model-specifications",
    "href": "2024Spring/exercises/multiple-regression/index.html#exploring-feasible-model-specifications",
    "title": "Exercises on multiple linear regression",
    "section": "",
    "text": "Read in the data set ice_data.csv. What kind of relationships could you reasonably study in a linear regression framework (without further data transformation)."
  },
  {
    "objectID": "2024Spring/exercises/multiple-regression/index.html#solutions",
    "href": "2024Spring/exercises/multiple-regression/index.html#solutions",
    "title": "Exercises on multiple linear regression",
    "section": "",
    "text": "The solutions to both exercises can be found here."
  },
  {
    "objectID": "2024Spring/exercises/obj-types-exercises/index.html",
    "href": "2024Spring/exercises/obj-types-exercises/index.html",
    "title": "Basic object types: exercises",
    "section": "",
    "text": "Task 1\nCreate a vector containing the numbers 2, 5, 2.4 and 11.\n\nWhat is the type of this vector?\nReplace the second element with 5.9.\nAdd the elements 3 and 1 to the beginning, and the elements \"8.0\" and \"9.2\" to the end of the vector.\nTransform this vector into the type integer. What happens?\n\n\n\nTask 2\n\nWhat type is the following vector: \"2\", \"Hello\", 4.0, and TRUE\nWhat hierarchy is underlying this?\n\n\n\nTask 3\n\nCreate a vector with the numbers from -8 to 9 (step size: 0.5)\nCompute the square root of each element of the first vector using vectorisation. Anything that draws your attention?\n\n\n\nTask 4\nCreate a list that has three named elements: \"A\", \"B\", and \"C\"\n\nThe element \"A\" should contain the square root of the numbers form -2 to 8 (step size: 1)\nThe element \"B\" should contain the log of numbers between 2 and 4 (step size: 0.5)\nThe element \"C\" should contain letters from a1 to g7 (hint: use the pre-defined vector letters and the function paste())\n\nLink to the solutions"
  },
  {
    "objectID": "2024Spring/exercises/quarto-exercises/index.html",
    "href": "2024Spring/exercises/quarto-exercises/index.html",
    "title": "Quarto exercises",
    "section": "",
    "text": "Create a new Quarto document where you set the title, date, and the author explicitly. Write a sample text that comprises‚Ä¶\n\n‚Ä¶at least one level 1 heading\n‚Ä¶at least two level 2 headings\n‚Ä¶a YAML part that specifies that R code remains hidden by default\n‚Ä¶one R chunk where both the output and the code is printed in the final document\n‚Ä¶one R chunk that produces a simply ggplot object and where the code producing the plot is hidden\n\nThen do the following:\n\nKnit the document to html with a floating table of contents and a special theme.\nMake the document available via Netlify Drop and add the possibility to download the underlying Rmd file. Note: For Netlify Drop to work, the html file must be called index.html!\nKnit the document to PDF and make sure that it includes a table of contents.\n\nA sample solution for the Rmd file can be found here (the Netlify version is here)."
  }
]